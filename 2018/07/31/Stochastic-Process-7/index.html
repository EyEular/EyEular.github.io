<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    <title>Stochastic-Process (Conjugacy &amp; Bayesian) | EyEular</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Probability">
    <meta name="description" content="Beta-Binomial DistributionDefinition (Beta Distribution)An r.v. $X$ is said to have Beta distribution with parameters $a$ and $b$, if its PDF is f(x) = \frac{1}{\beta(a,b)}x^{a-1}(1-x)^{b-1},0">
<meta name="keywords" content="Probability">
<meta property="og:type" content="article">
<meta property="og:title" content="Stochastic-Process (Conjugacy &amp; Bayesian)">
<meta property="og:url" content="http://yoursite.com/2018/07/31/Stochastic-Process-7/index.html">
<meta property="og:site_name" content="EyEular">
<meta property="og:description" content="Beta-Binomial DistributionDefinition (Beta Distribution)An r.v. $X$ is said to have Beta distribution with parameters $a$ and $b$, if its PDF is f(x) = \frac{1}{\beta(a,b)}x^{a-1}(1-x)^{b-1},0">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://yoursite.com/2018/07/31/Stochastic-Process-7/sp7img1.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/31/Stochastic-Process-7/sp7img2.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/31/Stochastic-Process-7/sp7img3.jpg">
<meta property="og:updated_time" content="2018-08-03T05:40:01.666Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Stochastic-Process (Conjugacy &amp; Bayesian)">
<meta name="twitter:description" content="Beta-Binomial DistributionDefinition (Beta Distribution)An r.v. $X$ is said to have Beta distribution with parameters $a$ and $b$, if its PDF is f(x) = \frac{1}{\beta(a,b)}x^{a-1}(1-x)^{b-1},0">
<meta name="twitter:image" content="http://yoursite.com/2018/07/31/Stochastic-Process-7/sp7img1.jpg">
    
        <link rel="alternate" type="application/atom+xml" title="EyEular" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/E.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Eulring</h5>
          <a href="mailto:bianjy@shanghaitech.edu.cn" title="bianjy@shanghaitech.edu.cn" class="mail">bianjy@shanghaitech.edu.cn</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-rebel"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-codepen"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-diamond"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/EyEular" target="_blank" >
                <i class="icon icon-lg icon-gitlab"></i>
                gayhub
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/links"  >
                <i class="icon icon-lg icon-gg"></i>
                Links
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/custom"  >
                <i class="icon icon-lg icon-eye"></i>
                About me
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Stochastic-Process (Conjugacy &amp; Bayesian)</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Stochastic-Process (Conjugacy &amp; Bayesian)</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-07-31T02:35:18.000Z" itemprop="datePublished" class="page-time">
  2018-07-31
</time>


            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Beta-Binomial-Distribution"><span class="post-toc-number">1.</span> <span class="post-toc-text">Beta-Binomial Distribution</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Definition-Beta-Distribution"><span class="post-toc-number">1.0.1.</span> <span class="post-toc-text">Definition (Beta Distribution)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Beta-Integral"><span class="post-toc-number">1.0.2.</span> <span class="post-toc-text">Beta Integral</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Bayes’-billiards"><span class="post-toc-number">1.0.3.</span> <span class="post-toc-text">Bayes’ billiards</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Beta-Binomial-Conjugacy"><span class="post-toc-number">1.0.4.</span> <span class="post-toc-text">Beta-Binomial Conjugacy</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Mean-vs-Bayesian-Average"><span class="post-toc-number">1.0.5.</span> <span class="post-toc-text">Mean vs Bayesian Average</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Dirichlet-Multinomial-Distribution"><span class="post-toc-number">2.</span> <span class="post-toc-text">Dirichlet-Multinomial Distribution</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Theorem-Multinomial-Joint-PMF"><span class="post-toc-number">2.0.1.</span> <span class="post-toc-text">Theorem (Multinomial Joint PMF)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Theorem-Multinomial-Marginals"><span class="post-toc-number">2.0.2.</span> <span class="post-toc-text">Theorem (Multinomial Marginals)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Theorem-Multinomial-Lumping"><span class="post-toc-number">2.0.3.</span> <span class="post-toc-text">Theorem (Multinomial Lumping)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Theorem-Multinomial-Conditioning"><span class="post-toc-number">2.0.4.</span> <span class="post-toc-text">Theorem (Multinomial Conditioning)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Theorem-Covariance-in-A-Multinomial"><span class="post-toc-number">2.0.5.</span> <span class="post-toc-text">Theorem (Covariance in A Multinomial)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Definition-Dirichlet-Distribution"><span class="post-toc-number">2.0.6.</span> <span class="post-toc-text">Definition (Dirichlet Distribution)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Dirichlet-Multinomial-Conjugacy"><span class="post-toc-number">2.0.7.</span> <span class="post-toc-text">Dirichlet-Multinomial Conjugacy</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Bayesian-Average"><span class="post-toc-number">3.</span> <span class="post-toc-text">Bayesian Average</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Multinomial-Distribution"><span class="post-toc-number">3.0.0.0.1.</span> <span class="post-toc-text">Multinomial Distribution</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Dirichlet-Distribution-Prior"><span class="post-toc-number">3.0.0.0.2.</span> <span class="post-toc-text">Dirichlet Distribution: Prior</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Expected-Average"><span class="post-toc-number">3.0.0.0.3.</span> <span class="post-toc-text">Expected Average</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Bayesian-Average-Rating"><span class="post-toc-number">3.0.1.</span> <span class="post-toc-text">Bayesian Average Rating</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Gamma-Distribution"><span class="post-toc-number">4.</span> <span class="post-toc-text">Gamma Distribution</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Definition-Gamma-Function"><span class="post-toc-number">4.0.1.</span> <span class="post-toc-text">Definition (Gamma Function)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Property-of-Gamma-Function"><span class="post-toc-number">4.0.2.</span> <span class="post-toc-text">Property of Gamma Function</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Definition-Gamma-Distribution"><span class="post-toc-number">4.0.3.</span> <span class="post-toc-text">Definition (Gamma Distribution)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#PDF-of-Gamma-distribution"><span class="post-toc-number">4.0.4.</span> <span class="post-toc-text">PDF of Gamma distribution</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Moments-of-Gamma-Distribution"><span class="post-toc-number">4.0.5.</span> <span class="post-toc-text">Moments of Gamma Distribution</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Theorem-Gamma-Convolution-of-Exponential"><span class="post-toc-number">4.0.6.</span> <span class="post-toc-text">Theorem (Gamma: Convolution of Exponential)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Beta-Gamma-Connection"><span class="post-toc-number">4.0.7.</span> <span class="post-toc-text">Beta-Gamma Connection</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Binomial-amp-Poisson-amp-Gamma"><span class="post-toc-number">4.0.8.</span> <span class="post-toc-text">Binomial &amp; Poisson &amp; Gamma</span></a></li></ol></li></ol></li></ol>
        </nav>
    </aside>
    
<article id="post-Stochastic-Process-7"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Stochastic-Process (Conjugacy & Bayesian)</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-07-31 10:35:18" datetime="2018-07-31T02:35:18.000Z"  itemprop="datePublished">2018-07-31</time>

            


            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h1 id="Beta-Binomial-Distribution"><a href="#Beta-Binomial-Distribution" class="headerlink" title="Beta-Binomial Distribution"></a>Beta-Binomial Distribution</h1><h3 id="Definition-Beta-Distribution"><a href="#Definition-Beta-Distribution" class="headerlink" title="Definition (Beta Distribution)"></a>Definition (Beta Distribution)</h3><p>An r.v. $X$ is said to have <strong>Beta distribution</strong> with parameters $a$ and $b$, if its PDF is</p>
<script type="math/tex; mode=display">f(x) = \frac{1}{\beta(a,b)}x^{a-1}(1-x)^{b-1},0<x<1</script><p>where $\beta(a,b)$ is constant to make PDF integrate to 1, We write this as $X\sim Beta(a,b)$</p>
<p>By varying the values of $a$ and $b$, we get PDFs with a variety of shapes<br><img src="/2018/07/31/Stochastic-Process-7/sp7img1.jpg" align="justify"></p>
<p><em>Beta Distribution is the generalization of uniform distribution while $a=b=1$</em></p>
<p>The Beta is a flexible family of continuous distributions on (0,1), and has many stories. One is Beta r.v. often used to represent an unknown probability. <strong>we can use Beta to put probabilities on unknown probabilities</strong> If a parameter $p$ satisfies $0&lt;p&lt;1$, we can assume the prior distribution of $p$ is Beta(a,b)</p>
<h3 id="Beta-Integral"><a href="#Beta-Integral" class="headerlink" title="Beta Integral"></a>Beta Integral</h3><p>One inportant issue to analyse the Beta Distribution is the Integral</p>
<script type="math/tex; mode=display">\beta(a,b) = \int_0^1 x^{a-1}(1-x)^{b-1}dx</script><h3 id="Bayes’-billiards"><a href="#Bayes’-billiards" class="headerlink" title="Bayes’ billiards"></a>Bayes’ billiards</h3><p> It’s hard to get the reuslt directly from calculus, the left and right sides of the above formulation can be connected by one event $P(X=k)$</p>
<script type="math/tex; mode=display">\int_0^1 \left( \begin{array}{c} n\\k \end{array} \right) x^k(1-x)^{n-k}dx = \frac{1}{n+1}</script><p><strong>Left side Story :</strong> Having $n+1$ balls , $n$ white and $1$ gray. Randomly throw each ball onto the interval $[0,1]$, so the position of balls are i.i.d. $Unif(0,1)$. Let $X$ be the number of white balls to the left of the gray ball.</p>
<p>To get the probability of the event $X=k$, we use LOTP. Conditioning on the position of gray ball, call it $B$, Conditional on $B=p$, the number of the white ball landing to the left of $p$ has $Bin(n,p)$ distribution, The PDF of $B$ is $f(p) =1$ since $B\sim Unif(0,1)$</p>
<script type="math/tex; mode=display">P(X=k) = \int_0^1 P(X=k|B=p)f(p)dp = \int_0^1 \left( \begin{array}{c} n\\k \end{array} \right) p^k(1-k)^{n-k}dp</script><p><strong>Right side Story :</strong> Having $n+1$ balls, all white, randomly throw onto unit interval; then choose one ball at random and paint it gray. Again, let $X$ be the number of white balls to the left of gray ball. By symmetry, any one of the $n+1$ balls is equally likely to be painted gray, then</p>
<script type="math/tex; mode=display">P(X=k) = \frac{1}{n+1}</script><p>$X$ has the same distribution, then</p>
<script type="math/tex; mode=display">\int_0^1 \left( \begin{array}{c} n\\k \end{array} \right) p^k (1-p)^{n-k}dp= \frac{1}{n+1}</script><p>Using the result, we are capable to calculate the $\beta(a,b)$ by substituting $a-1$ for $k$ and $b-1$ for $n-k$</p>
<script type="math/tex; mode=display">\beta(a,b) = \frac{1}{(a+b-1) \left( \begin{array}{c} a+b-2\\a-1 \end{array} \right)} = \frac{(a-1)!(b-1)!}{(a+b-1)!}</script><p>For a r.v. $X\sim Beta(a,b)$, The Expectation</p>
<script type="math/tex; mode=display">\begin{align}
E(X) &= \int_0^1 xf(x)dx= \int_0^1 x\cdot \frac{x^{a-1}(1-x)^{b-1}}{\beta(a,b)}dx=\frac{1}{\beta(a,b)}\int_0^1 x^a(1-x)^{b-1}dx \\
&= \frac{1}{\beta(a,b)}\cdot \beta(a+1,b) = \frac{\frac{a!(b-1)!}{(a+b)!}}{\frac{(a-1)!(b-1)!}{(a+b-1)!}} = \frac{a}{a+b}
\end{align}</script><h3 id="Beta-Binomial-Conjugacy"><a href="#Beta-Binomial-Conjugacy" class="headerlink" title="Beta-Binomial Conjugacy"></a>Beta-Binomial Conjugacy</h3><p> Now let’s see the connection between Beta distribution and Binomial distribution, the relation we call it Conjugacy.</p>
<p>We have a coin lands head with p. $p$, and we dont know what %p% is. Our goal is to infer the value of $p$ after observing the outcomes of n tosses of the coin.<br><strong>Bayesian Inference</strong></p>
<ul>
<li>Treat all unknown probability $p$ as r.v. and give $p$ a distribution</li>
<li>Above is called <strong>prior distribution</strong>, it reflects out uncertainty about the ture value of $p$ before observing</li>
<li>After experiment and data are gathered, prior distribution is updated using Baye’s rule,; This yields the <strong>posterior distribution</strong>, which reflects the new beliefs about $p$</li>
<li>Specifically<ul>
<li><strong>prior distribution</strong> $f(p)$</li>
<li><strong>posterior distribution</strong> $f(p|X=n)$</li>
</ul>
</li>
</ul>
<p>Suppose the prior distribution on $p$ is Beta distribution. Let $p\sim Beta(a,b)$ for known constants $a$ and $b$, $X$ be the number of heads in $n$ tosses of the coin. Conditional on knowing ture value of $p$ then</p>
<script type="math/tex; mode=display">X|p \sim Bin(n,p)</script><p>We use the Bayes rule. Letting $f(p)$ be the prior distribution and $f(p|X=k)$ be the posterior distribution after observing $k$ heads</p>
<script type="math/tex; mode=display">f(p|X=k) = \frac{P(X=k|p)f(p)}{P(X=k)}=\frac{\left( \begin{array}{c} n\\k \end{array} \right) p^k (1-p)^{n-k}\cdot \frac{1}{\beta(a,b)}p^{a-1}(1-p)^{b-1}}{P(X=k)}</script><p>The denominator $P(X=k)$ is the marginal PMF of $X$, is given by</p>
<script type="math/tex; mode=display">P(X=k) = \int_0^1 P(X=k|p) f(p)dp = \int_0^1 \left( \begin{array}{c} n\\k \end{array} \right) p^k(1-p)^{n-k}f(p)dp</script><p>If $a=b=1$ , $P(X=k) = 1/(n+1)$, but it not seem easy to find $P(X=k)$ in general , Are we stuck ?</p>
<p>Actually, is much easier than it appears at first, the conditional PDF $f(p|X=k)$ is a function of $p$, so everything doesn’t depend on $p$ is just a constant. After dropping constants gives</p>
<script type="math/tex; mode=display">f(p|X=k) \propto p^{a+k-1}(1-p)^{b+n-k-1}</script><p>which is the $Beta(a+k,b+n-k)$ PDF.Therefore the posterior distribution of $p$ is</p>
<script type="math/tex; mode=display">p|X = k\sim Beta(a+k,b+n-k)</script><p>The posterior distribution of $p$ after observing $X=k$ is still a Beta distribution!</p>
<p>We say <em>Beta is the Conjugate prior of the Binomial</em></p>
<ul>
<li>We add the observed successes $k$ to the first parameter</li>
<li>We add the observed successes $k-n$ to the second parameter</li>
<li>$a$ and $b$ have a concrete interpretation in this context<ul>
<li>$a$ as the number of prior successes in earlier experiments</li>
<li>$b$ as the number of prior failures in earlier experiments</li>
</ul>
</li>
</ul>
<h3 id="Mean-vs-Bayesian-Average"><a href="#Mean-vs-Bayesian-Average" class="headerlink" title="Mean vs Bayesian Average"></a>Mean vs Bayesian Average</h3><ul>
<li>Mean: $\frac{k}{n}$</li>
<li>Bayesian Average: $E(p|X=k) = \frac{a+k}{a+b+n}$</li>
</ul>
<hr>
<h1 id="Dirichlet-Multinomial-Distribution"><a href="#Dirichlet-Multinomial-Distribution" class="headerlink" title="Dirichlet-Multinomial Distribution"></a>Dirichlet-Multinomial Distribution</h1><p>$n$ objects are independently placed into one of $k$ categories, with probability of $p_j$ to category j, and $\sum_{j=1}^k p_j = 1$. Let $X_i$ be the number of objects in category $i$, $X_1 + … + X_n = n$. Then $X = (X_1,…,X_k)$ is said to have <strong>Multinomial distribution</strong> with parameters $n$ and $\mathbf{p} = (p_1,…,p_k)$, write as $\mathbf{X} \sim Mult_k(n,\mathbf{p})$</p>
<h3 id="Theorem-Multinomial-Joint-PMF"><a href="#Theorem-Multinomial-Joint-PMF" class="headerlink" title="Theorem (Multinomial Joint PMF)"></a>Theorem (Multinomial Joint PMF)</h3><p>If $\mathbf{X}\sim Mult_k(n,\mathbf{p})$, then the joint PMF of $\mathbf{X}$ is</p>
<script type="math/tex; mode=display">P(X_1=n_1,...,X_k=n_k) = \frac{n!}{n_1!n_2!...n_k!}\cdot p_1^{n_1}p_2^{n_2}\dotsb p_k^{n_k}</script><h3 id="Theorem-Multinomial-Marginals"><a href="#Theorem-Multinomial-Marginals" class="headerlink" title="Theorem (Multinomial Marginals)"></a>Theorem (Multinomial Marginals)</h3><p>If $\mathbf{X}\sim Mult_k(n,\mathbf{p})$, then $X_j \sim Bin(n,p_j)$</p>
<h3 id="Theorem-Multinomial-Lumping"><a href="#Theorem-Multinomial-Lumping" class="headerlink" title="Theorem (Multinomial Lumping)"></a>Theorem (Multinomial Lumping)</h3><p>If $\mathbf{X}\sim Mult_k(n,\mathbf{p})$, then for distinct $i$ and $j$, $X_i+X_j\sim Bin(n,p_i+p_j)$</p>
<script type="math/tex; mode=display">(X_1+X_2,X_3,...,X_k)\sim Mult_k(n,((p_1+p_2),p_3,...,p_n))</script><p><img src="/2018/07/31/Stochastic-Process-7/sp7img2.jpg" style=" width:500px;"></p>
<h3 id="Theorem-Multinomial-Conditioning"><a href="#Theorem-Multinomial-Conditioning" class="headerlink" title="Theorem (Multinomial Conditioning)"></a>Theorem (Multinomial Conditioning)</h3><p>If $\mathbf{X}\sim Mult_k(n,\mathbf{p})$, then</p>
<script type="math/tex; mode=display">(X_2,...,X_k)|X_1=n_1\sim Mult_k(n-n_1,(p_2^{\prime},...,p_k^{\prime}))</script><p>where $p_j^{\prime} = p_j/(p_2+\dotsb +p_k)$</p>
<h3 id="Theorem-Covariance-in-A-Multinomial"><a href="#Theorem-Covariance-in-A-Multinomial" class="headerlink" title="Theorem (Covariance in A Multinomial)"></a>Theorem (Covariance in A Multinomial)</h3><p>Let $X_1,…,X_k\sim Mult_k(n,\mathbf{p})$, where $\mathbf{p} = (p_1,…,p_k)$.</p>
<script type="math/tex; mode=display">Cov(X_i,X_j) = -np_ip_j</script><h3 id="Definition-Dirichlet-Distribution"><a href="#Definition-Dirichlet-Distribution" class="headerlink" title="Definition (Dirichlet Distribution)"></a>Definition (Dirichlet Distribution)</h3><p>Dirichlet distribution is parameterized by a vector $\mathbf{\alpha}$ of positive real numbers. The PDF is:</p>
<script type="math/tex; mode=display">f(p_1,p_2,...,p_k;\alpha_1,\alpha_2,...,\alpha_k)=\frac{\Gamma(\sum_{i=1}^k\alpha_i)}{\prod_{i=1}^k\Gamma(\alpha_i)}\prod_{i=1}^kp_i^{\alpha_i-1}</script><p>where $p_1 + … + p_k = 1$</p>
<h3 id="Dirichlet-Multinomial-Conjugacy"><a href="#Dirichlet-Multinomial-Conjugacy" class="headerlink" title="Dirichlet-Multinomial Conjugacy"></a>Dirichlet-Multinomial Conjugacy</h3><p>Assume we already have the Multinomial distribution $\mathbf{X}\sim Mult_k(n,\mathbf{p})$. The prior distribution of $\mathbf{p}=(p_1,…,p_k)$ is a Dirichlet distribution, i.e. $\mathbf{p}\sim Dir(\alpha)$. Denote $\mathbf{X} = (X_1,…,X_k)$, then</p>
<script type="math/tex; mode=display">\mathbf{X}|\mathbf{p}\sim Mult_k(n,\mathbf{p})</script><p>Let $f(\mathbf{p})$ to be the prior distribution of $\mathbf{p}$. The observations of the experiment is $\mathbf{N} = (n_1,…,n_k)$ then</p>
<script type="math/tex; mode=display">\begin{align}
f(\mathbf{p}|\mathbf{X}=\mathbf{N}) &= \frac{P(\mathbf{X}=\mathbf{N}|\mathbf{p})f(\mathbf{p})}{P(\mathbf{X}=\mathbf{N})} \\
&= \frac{\frac{n!}{n_1!\dotsb n_k!}p_1^{n_1}\dotsb p_k^{n_k}\cdot \frac{\Gamma(\sum_{i=1}^k \alpha_i)}{\prod_{i=1}^k \Gamma(\alpha_i)}\prod_{i=1}^k p_i^{\alpha_i -1}}{P(\mathbf{X}= \mathbf{N})} \\
&\propto p_1^{n_1+\alpha_1 - 1}\dotsb p_k^{n_k+\alpha_k - 1} \\
&\sim Dir(\mathbf{\alpha} + \mathbf{N})
\end{align}</script><p>Thus we can see that</p>
<script type="math/tex; mode=display">\text{prior}\ Dir(\mathbf{\alpha}) \rightarrow \text{posterior}\ Dir(\mathbf{\alpha} + \mathbf{N})</script><script type="math/tex; mode=display">\alpha_i \rightarrow \alpha_i + n_i</script><p>We can prove that</p>
<script type="math/tex; mode=display">E[p_i|\mathbf{X} = \mathbf{N}] = \frac{\alpha_i + n_i}{\sum_{i=1}^k(\alpha_i + n_i)}</script><hr>
<h1 id="Bayesian-Average"><a href="#Bayesian-Average" class="headerlink" title="Bayesian Average"></a>Bayesian Average</h1><p>One application for Bayesian Average is in <strong>Rating System</strong>, usually the customers will rate the movies in 5 star.</p>
<p>This will rose a problem, which One to Choose</p>
<ul>
<li>$5$ Average rating movie A by $1$ voter</li>
<li>$4.9998$ Average rating movie B by $1400010123$ voter (of course this One)</li>
</ul>
<p>To use the Bayesian estimation to compute the posterior probability for star ratings, we must use a <strong>joint distribution</strong>, the random variable is a categorical distribution with probability follows:</p>
<script type="math/tex; mode=display">p_1+p_2+p_3+p_4+p_5 = 1</script><h5 id="Multinomial-Distribution"><a href="#Multinomial-Distribution" class="headerlink" title="Multinomial Distribution"></a>Multinomial Distribution</h5><p>Let $O$ be the event of movie rating, we compute the posterior probability with $N$ observations for five categories with corresponding numbers $K_1,K_2,K_3,K_4,K_5$ as follows:</p>
<script type="math/tex; mode=display">Pr(O|p_1,p_2,p_3,p_4,p_5)\propto p_1^{K_1}p_2^{K_2}p_3^{K_3}p_4^{K_4}p_5^{K_5}</script><p>where $K_1+…+K_5 = N$</p>
<h5 id="Dirichlet-Distribution-Prior"><a href="#Dirichlet-Distribution-Prior" class="headerlink" title="Dirichlet Distribution: Prior"></a>Dirichlet Distribution: Prior</h5><script type="math/tex; mode=display">Pr(p_1,p_2,p_3,p_4,p_5|O) \propto \prod_{j=1}^5 p_j^{K_j+\alpha_j^0 - 1}</script><p>After considering the new votes we can update the distribution of the $\mathbf{p}$ by</p>
<script type="math/tex; mode=display">\alpha_j^1 = K_j +\alpha_k^0</script><h5 id="Expected-Average"><a href="#Expected-Average" class="headerlink" title="Expected Average"></a>Expected Average</h5><p>What we need is the average rating given posterior in the shape of our Dirichlet distribution:</p>
<script type="math/tex; mode=display">E(p_1+2p_2+3p_3+4p_4+5p_5|O) = \sum_{i=1}^5 iE(p_i|O)</script><p>According to</p>
<script type="math/tex; mode=display">E(p_i|O) = \frac{\alpha_i^1}{\sum_{j=1}^5 \alpha_j^1}</script><p>We have</p>
<script type="math/tex; mode=display">\sum_{i=1}^5 iE(p_i|O) = \frac{\sum_{i=1}^5 i\alpha_i^0 + \sum_{i=1}^5 i K_i}{\sum_{j=1}^5 \alpha_j^0 +N}</script><h3 id="Bayesian-Average-Rating"><a href="#Bayesian-Average-Rating" class="headerlink" title="Bayesian Average Rating"></a>Bayesian Average Rating</h3><p>The final formulation can be express as</p>
<script type="math/tex; mode=display">\text{Bayes Average Rating} = \frac{C\cdot m +\sum(ratings)}{C+N}</script><ul>
<li>N: The number of ratings</li>
<li>m: a prior for the average of rating scores</li>
<li>C: a prior for the number of rating scores</li>
</ul>
<hr>
<h1 id="Gamma-Distribution"><a href="#Gamma-Distribution" class="headerlink" title="Gamma Distribution"></a>Gamma Distribution</h1><h3 id="Definition-Gamma-Function"><a href="#Definition-Gamma-Function" class="headerlink" title="Definition (Gamma Function)"></a>Definition (Gamma Function)</h3><p>The Gamma function $\Gamma$ is defined by</p>
<script type="math/tex; mode=display">\Gamma(a) = \int_0^{\infty}x^ae^{-x}\frac{dx}{x}</script><p>Earlier Beta distribution can represent an unknown probability of success cause its support is $(0,1)$. The Gamma distribution can represent an unknown rate in a Poisson process because its support is $(0,\infty)$</p>
<h3 id="Property-of-Gamma-Function"><a href="#Property-of-Gamma-Function" class="headerlink" title="Property of Gamma Function"></a>Property of Gamma Function</h3><ul>
<li>$\Gamma(a+1) = a\Gamma(a)$</li>
<li>$\Gamma(n) = (n-1)!$ if $n$ is a integer</li>
</ul>
<h3 id="Definition-Gamma-Distribution"><a href="#Definition-Gamma-Distribution" class="headerlink" title="Definition (Gamma Distribution)"></a>Definition (Gamma Distribution)</h3><p>An r.v. $Y$ is said to have <strong>Gamma distribution</strong> with parameters $a&gt;0, \lambda&gt;0$, if its PDF is</p>
<script type="math/tex; mode=display">f(y) = \frac{1}{\Gamma(a)}(\lambda y)^a e^{-\lambda y} \frac{1}{y}, y>0</script><p>Write $Y\sim Gamma(a,\lambda)$. <strong>Gamma distribution is a generalization of exponential distribution</strong> when $a=1$</p>
<h3 id="PDF-of-Gamma-distribution"><a href="#PDF-of-Gamma-distribution" class="headerlink" title="PDF of Gamma distribution"></a>PDF of Gamma distribution</h3><p><img src="/2018/07/31/Stochastic-Process-7/sp7img3.jpg" align="justify"></p>
<h3 id="Moments-of-Gamma-Distribution"><a href="#Moments-of-Gamma-Distribution" class="headerlink" title="Moments of Gamma Distribution"></a>Moments of Gamma Distribution</h3><script type="math/tex; mode=display">E[X] = \frac{a}{\lambda}, Var(X) = \frac{a}{\lambda^2}</script><h3 id="Theorem-Gamma-Convolution-of-Exponential"><a href="#Theorem-Gamma-Convolution-of-Exponential" class="headerlink" title="Theorem (Gamma: Convolution of Exponential)"></a>Theorem (Gamma: Convolution of Exponential)</h3><p>Let $X_1,…,X_n$ be i.i.d. $Expo(\lambda)$ , Then</p>
<script type="math/tex; mode=display">X_1+\dotsb +X_n \sim Gamma(n,\lambda)</script><h3 id="Beta-Gamma-Connection"><a href="#Beta-Gamma-Connection" class="headerlink" title="Beta-Gamma Connection"></a>Beta-Gamma Connection</h3><p>We have independent Gamma r.v.s $X$ and $Y$ with the same rate $\lambda$</p>
<ul>
<li>$X+Y$ had Gamma distribution</li>
<li>$\frac{X}{X+Y}$ has Beta distribution</li>
</ul>
<h3 id="Binomial-amp-Poisson-amp-Gamma"><a href="#Binomial-amp-Poisson-amp-Gamma" class="headerlink" title="Binomial &amp; Poisson &amp; Gamma"></a>Binomial &amp; Poisson &amp; Gamma</h3><ul>
<li>The PMF of $Poisson(X=k|\lambda)$ is $P(X=k|\lambda) = \frac{\lambda^ke^{-\lambda}}{k!}$</li>
<li>The PDF of $X\sim Gamma(a,1)$ is $f_X(x) = \frac{1}{\Gamma(a)}a^{a-1}e^{-x}$. Given $a=k+1$ we have<script type="math/tex; mode=display">P(X=x|a=k+1,1)=\frac{x^{k+1}}{\Gamma(k+1)}e^{-x}= \frac{x^k}{k!}e^{-x}</script></li>
<li>For a r.v. $X\sim Bin(n,p)$, we have<script type="math/tex; mode=display">P(X\leq k)=\frac{n!}{k!(n-k-1)!}\int_p^1 t^k(1-t)^{n-k-1}dt</script>Let $t=\frac{x}{n}$, then<script type="math/tex; mode=display">P(X\leq k) = \int_{np}^n Bin(X=k|n-1,\frac{x}{n})dx</script>It follows that<script type="math/tex; mode=display">Bin(X\leq k|n,p) = \int_{np}^n Bin(X=k|n-1,\frac{x}{n}dx)</script></li>
<li>Let $\lambda = np$. We fix $\lambda$, and let $n\rightarrow \infty$, then<script type="math/tex; mode=display">Bin(n,p) \rightarrow Posi(\lambda)</script></li>
<li>When $\lambda \rightarrow 0$, we have<script type="math/tex; mode=display">1=\mathop{lim}_{\lambda \rightarrow 0} \int_{\lambda}^{\infty} \frac{\lambda^k e^{-x}}{k!}dx = \int_0^{\infty} \frac{x^ke^{-x}}{k!}dx=\int_0^{\infty} Gamma(k+1,1)dx</script></li>
<li>$1=\int_0^{\infty} \frac{x^ke^{-x}}{k!}dx\Rightarrow k!=\int_0^{\infty}x^k e^{-x}dx$</li>
<li>Because $Pois(X\leq k|\lambda) = \int_{\lambda}^{\infty}\frac{x^k e^{-x}}{k!} dx$ we have<script type="math/tex; mode=display">Pois(X\leq k|\lambda) + \int_0^{\infty} \frac{x^ke^{-x}}{k!}dx = 1</script></li>
</ul>
<p>.</p>

        </div>

        <blockquote class="post-copyright">
    <div class="content">
        

        
        这里可以写作者留言，标签和 hexo 中所有变量及辅助函数等均可调用，示例：<a href="/2018/07/31/Stochastic-Process-7/" target="_blank" rel="external">http://yoursite.com/2018/07/31/Stochastic-Process-7/</a>
        
    </div>
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/E.jpg" alt="Eulring">
            Eulring
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Probability/">Probability</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2018/07/31/Stochastic-Process-7/&title=《Stochastic-Process (Conjugacy & Bayesian)》 — EyEular&pic=http://yoursite.com/img/E.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2018/07/31/Stochastic-Process-7/&title=《Stochastic-Process (Conjugacy & Bayesian)》 — EyEular&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2018/07/31/Stochastic-Process-7/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Stochastic-Process (Conjugacy & Bayesian)》 — EyEular&url=http://yoursite.com/2018/07/31/Stochastic-Process-7/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2018/07/31/Stochastic-Process-7/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2018/08/01/PGM-0/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">PGM-0</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/07/29/Stochastic-Process-6/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Stochastic-Process (Multivariate)</h4>
      </a>
    </div>
  
</nav>



    














</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        thanks~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wepay.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wepay.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Eulring &copy; 2018</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2018/07/31/Stochastic-Process-7/&title=《Stochastic-Process (Conjugacy & Bayesian)》 — EyEular&pic=http://yoursite.com/img/E.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2018/07/31/Stochastic-Process-7/&title=《Stochastic-Process (Conjugacy & Bayesian)》 — EyEular&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2018/07/31/Stochastic-Process-7/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Stochastic-Process (Conjugacy & Bayesian)》 — EyEular&url=http://yoursite.com/2018/07/31/Stochastic-Process-7/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2018/07/31/Stochastic-Process-7/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://yoursite.com/2018/07/31/Stochastic-Process-7/" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>






<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = '(一条消息未读。。)';
            clearTimeout(titleTime);
        } else {
            document.title = 'EyEular';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>
