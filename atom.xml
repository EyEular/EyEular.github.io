<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>EyEular</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-07-30T02:57:52.643Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Eulring</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Stochastic-Process (Multivariate)</title>
    <link href="http://yoursite.com/2018/07/29/Stochastic-Process-6/"/>
    <id>http://yoursite.com/2018/07/29/Stochastic-Process-6/</id>
    <published>2018-07-29T00:41:09.000Z</published>
    <updated>2018-07-30T02:57:52.643Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Discrete-Multivariate-R-V-s"><a href="#Discrete-Multivariate-R-V-s" class="headerlink" title="Discrete Multivariate R.V.s"></a>Discrete Multivariate R.V.s</h1><p><strong>Definition (Joint CDF)</strong> The Joint CDf of r.v.s $X$ and $Y$ is the function $F_{X,Y}$ given by</p><script type="math/tex; mode=display">F_{X,Y}(x,y) = P(X\leq x,Y\leq y)</script><p><strong>Definition (Joint PMF)</strong> The Joint PMF of discrete r.v.s $X$ and $Y$ is the function $p_{X,Y}$ given by</p><script type="math/tex; mode=display">p_{X,Y}(x,y) = P(X=x,Y=y)</script><p><strong>Definition (Marginal PMF)</strong> For discrete r.v.s $X$ and $Y$, Marginal PMF of $X$ is</p><script type="math/tex; mode=display">P(X=x) = \sum_y P(X=x,Y=y)</script><p><strong>Definition (Conditional PMF)</strong> For discrete r.v.s $X$ and $Y$, the Conditional PMF of $X$ given $Y=y$ is</p><script type="math/tex; mode=display">P_{X|Y}(x|y) = P(X=x|Y=y)=\frac{P(X=x,Y=y)}{P(Y=y)}</script><p><strong>Definition (Independence of Discrete R.V.s)</strong> Random variables $X$ and $Y$ are independent if for all x and y</p><script type="math/tex; mode=display">F_{X,Y}(x,y) = F_X(x) F_Y(y)</script><p>for all x and y also equivalent to the condition</p><script type="math/tex; mode=display">P(Y=y|X=x) = P(Y=y)</script><hr><h1 id="Continuous-Multivariate-R-V-s"><a href="#Continuous-Multivariate-R-V-s" class="headerlink" title="Continuous Multivariate R.V.s"></a>Continuous Multivariate R.V.s</h1><p><strong>Definition (Joint PDF)</strong> If $X$ and $Y$ are continuous with joint CDF $F_{X,Y}$ then</p><script type="math/tex; mode=display">f_{X,Y}(x,y) = \frac{\partial^2}{\partial x \partial y} F_{X,Y}(x,y)</script><p><strong>Definition (Marginal PDF)</strong> If $X$ and $Y$ are continuous with joint PDF $f_{X,Y}$ then</p><script type="math/tex; mode=display">f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) dy</script><p><strong>Definition (Conditional PDF)</strong> For continuous r.v.s. $X$ and $Y$ with joint PDF $f_{X,Y}$ the Conditional PDF of $Y$ given $X=x$ is</p><script type="math/tex; mode=display">f_{Y|X}(y|x)= \frac{f_{X,Y}(x,y)}{f_X(x)}</script><p><strong>Definition (Independence of Continuous R.V.s)</strong> Random variables $X$ and $Y$ are independent if for all x and y</p><script type="math/tex; mode=display">F_{X,Y}(x,y) = F_X(x)F_Y(y)</script><p>If $X$ and  $Y$ are continuous with joint PDF $f_{X,Y}$</p><script type="math/tex; mode=display">f_{X,Y}(x,y) = f_X(x) f_Y(y)</script><p><strong>Theorem (2D LOTUS)</strong> Let g be a function from $R^2$ to $R$</p><p>If $X$ and $Y$ are discrete</p><script type="math/tex; mode=display">E(g(X,Y)) = \sum_x \sum_y g(x,y) P(X=x,Y=y)</script><p>If $X$ and $Y$ are continuous</p><script type="math/tex; mode=display">E(g(X,Y)) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x,y) f_{X,Y}(x,y) dxdy</script><h3 id="General-Bayes’-Rule"><a href="#General-Bayes’-Rule" class="headerlink" title="General Bayes’ Rule"></a>General Bayes’ Rule</h3><p><img src="/2018/07/29/Stochastic-Process-6/img1.jpg" align="justify"></p><hr><h1 id="Convariance-and-Correlation"><a href="#Convariance-and-Correlation" class="headerlink" title="Convariance and Correlation"></a>Convariance and Correlation</h1><p><strong>Covariance</strong></p><ul><li>Measure a tendency of two r.v.s $X\&amp;Y$ to go up or down together</li><li>Positive Covariance: $X$ go up, $Y$ tends go up</li><li>Negative Covariance: $X$ go up, $Y$ tends go down</li></ul><p><strong>Definition (Covariance)</strong> The covariance between r.v.s $X$ and $Y$ is</p><script type="math/tex; mode=display">Cov(X,Y) = E((X-EX)(Y-EY))=E(XY)-E(X)E(Y)</script><p><strong>Theorem (Uncorrelated)</strong> If $X$ and $Y$ are independent, then they are Uncorrelated($Cov(X,Y)=0$)</p><h3 id="Properties-of-Covariance"><a href="#Properties-of-Covariance" class="headerlink" title="Properties of Covariance"></a>Properties of Covariance</h3><ul><li>$Cov(X,X) = Var(X)$</li><li>$Cov(X,Y) = Cov(Y,X)$</li><li>$Cov(X,c) = 0$</li><li>$Cov(a\cdot X,Y) = a\cdot Cov(X,Y)$</li><li>$Cov(X+Y,Z) = Cov(X,Z)+Cov(Y,Z)$</li><li>$Cov(X+Y,W+Z) = Cov(X,Z)+Cov(X,W)+Cov(Y,Z)+Cov(Y,W)$</li><li>$Var(X+Y) = Var(X)+Var(Y) + 2Cov(X,Y)$</li><li>For n r.v.s $X_1,\dotsb ,X_n$ <script type="math/tex">Var(X_1+\dotsb +X_n)=Var(X_a)+\dotsb+Var(X_n)+2\sum_{i<j}Cov(X_i,Y_j)</script></li></ul><p><strong>Definition (Correlation)</strong> The Correlation between r.v.s $X$ and $Y$ is</p><script type="math/tex; mode=display">Corr(X,Y) = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}</script><p><em>Shifting and Scaling $X$ and $Y$ has no effect on correlation</em><br><img src="/2018/07/29/Stochastic-Process-6/img2.jpg" align="justify"></p><p><strong>Theorem (Correlation Bounds)</strong> For any r.v.s $X$ and $Y$</p><script type="math/tex; mode=display">-1\leq Corr(X,Y) \leq 1</script><hr><h1 id="Change-of-Variables"><a href="#Change-of-Variables" class="headerlink" title="Change of Variables"></a>Change of Variables</h1><p><strong>Theorem (Change of Variables in One Dimension)</strong> Let $X$ be a continuous r.v. with PDF $f_X$, and let $Y = g(X)$, where $g$ is differentiable and strictly increasing. Then the PDF of $Y$ is given by</p><script type="math/tex; mode=display">f_Y(y) = f_X(x) \left|  \frac{dx}{dy} \right|</script><p>where $x = g^{-1}(y)$</p><p><strong><em>Proof</em></strong>:</p><script type="math/tex; mode=display">F_Y(y) = P(Y\leq y)=P(g(X)\leq y)=P(X\leq g^{-1}(y))=F_X(g^{-1}(y))=F_X(x)</script><p>Then result obtained By the chain rule</p><p><strong>Theorem (Change of Variables)</strong> Let $X = (X_1,…,X_n)$ be a continuous random vector with joint PDF $f_X(x)$ and $Y=g(X)$, $g$ is an invertible function from $R^n$ to $R^n$ then $\frac{\partial \mathbf{x}}{\partial \mathbf{y}}$ form a <strong><em>Jacobian  matrix</em></strong></p><script type="math/tex; mode=display">\frac{\partial \mathbf{x}}{\partial \mathbf{y}} =\left( \begin{array}{cccc}\frac{\partial x_1}{\partial y_1} & \frac{\partial x_1}{\partial y_2} & \dotsb & \frac{\partial x_1}{\partial y_n} \\\vdots & \vdots & & \vdots \\\frac{\partial x_n}{\partial y_1} & \frac{\partial x_n}{\partial y_2} & \dotsb & \frac{\partial x_n}{\partial y_n} \\\end{array} \right)</script><p>Then the joint PDF of $Y$ is</p><script type="math/tex; mode=display">f_Y(y) = f_X(x) \left| \frac{\partial \mathbf{x}}{\partial \mathbf{y}} \right|</script><hr><h1 id="Convolutions"><a href="#Convolutions" class="headerlink" title="Convolutions"></a>Convolutions</h1><p><strong>Theorem (Convolution Sums and Integrals)</strong><br>If $X$ and $Y$ are independent discrete r.v.s, then the PMF of their sum $T = X+Y$ is</p><script type="math/tex; mode=display">\begin{align}  P(T=t) =& \sum_x P(Y = t-x) P(X=x) \\         =& \sum_y P(X= t-y) P(Y=y)\end{align}</script><p>If $X$ and $Y$ are independent continuous r.v.s, then the PMF of their sum $T = X+Y$ is</p><script type="math/tex; mode=display">\begin{align}  f_T(t)  =& \int_{-\infty}^{\infty} f_Y(t-x) f_X(x) dx \\          =& \int_{-\infty}^{\infty} f_X(t-y) f_Y(y) dy\end{align}</script><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Discrete-Multivariate-R-V-s&quot;&gt;&lt;a href=&quot;#Discrete-Multivariate-R-V-s&quot; class=&quot;headerlink&quot; title=&quot;Discrete Multivariate R.V.s&quot;&gt;&lt;/a&gt;Discr
      
    
    </summary>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
  </entry>
  
  <entry>
    <title>Topology-(引论)</title>
    <link href="http://yoursite.com/2018/07/28/Topology-1/"/>
    <id>http://yoursite.com/2018/07/28/Topology-1/</id>
    <published>2018-07-28T12:19:29.000Z</published>
    <updated>2018-07-29T00:40:25.323Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Eular-定理"><a href="#Eular-定理" class="headerlink" title="Eular 定理"></a>Eular 定理</h1><p>对于一个多面体 P，我们定义</p><ul><li>v：定点数</li><li>e：棱边数</li><li>f：面数</li></ul><p>Eular 定理：$v+f-e = 2$</p><p>但是满足这个定理的多面体是有条件的：</p><ul><li>P 的任何两个顶点可以用一串棱相连接<ul><li>反例：中空的立方体</li></ul></li><li>P 上任意由直线段构成的圈，把 P 分割成两片<ul><li>反例：螺帽柱状体</li></ul></li></ul><p>Eular 定理证明：我们首先来看看树形，这个在图论里面常常出现，树有个性质就是 $v-e=1$，我们可以尝试用一棵树 T 来表示一个多面体，表示的方法是，树中的点就是 P 中的点（树 T 中的点囊括了所有 P 的点），树中的边就是 P 中的棱（边只是一部分的棱哦）。</p><p>然后我们来构造 T 的一种对偶，称为 $\Gamma$，$\Gamma$ 也是一颗树后面会证明，只不过这棵树的点由 P 中面的中心点来表示（也就是用来表示面的数量），这样面与面之间的边在多面体中是可以有一个曲折的，可以想象一下。。</p><p>上面采用这个形式只是因为这样构造能囊括所有的面，下面来证明一下这个 $\Gamma$ 是树，而且曲折所在的棱刚好是 T 的边对于 P 中棱的补集：</p><ul><li>连通性：如果 $\Gamma$ 的某两个顶点不能用 $\Gamma$ 内的一串棱连接，则它们必然被一个圈分开。由于 T 不含任何圈，$\Gamma$ 必然联通。</li><li>无圈：如果 $\Gamma$ 有圈，那么就会把顶点分开成两份，T 中的棱想要连接所有顶点就不可避免的要触碰到这个圈，所以 $\Gamma$ 无圈</li><li>$T,\Gamma$ 包含所有棱：假设一条棱没有被用着，这个棱本可以这样被用：棱两侧的面中点相连（$\Gamma$），或者棱两端的点相连（T），但是都没用着，这样 $\Gamma ,T$ 就会在后面相交。。（这是我的数学直觉，书上并没有这个的证明，我自己补的。。。不是很严谨。。。）</li></ul><p>最后我们有 $v(T) - e(T) = 1$, $v(\Gamma) - e(\Gamma) = 1$, 加起来有</p><script type="math/tex; mode=display">v(T) - [e(T)+e(\Gamma)] + v(\Gamma) = 2</script><p>同时，根据构造有</p><script type="math/tex; mode=display">v(T) = v, e(T) + e(\Gamma)+e, v(\Gamma) = f</script><h2 id="其他的证明方式可以用数学归纳法"><a href="#其他的证明方式可以用数学归纳法" class="headerlink" title="其他的证明方式可以用数学归纳法"></a>其他的证明方式可以用数学归纳法</h2><h1 id="拓扑等价"><a href="#拓扑等价" class="headerlink" title="拓扑等价"></a>拓扑等价</h1><p>我们考虑一个正四面体未冲气的气球，我们把它吹胖，吹成了一个圆形。</p><p>这样多面体的点和球面的点之间的对应就是<strong>拓扑等价</strong>或<strong>同胚</strong>的一个例子，确切的说就是一对一的连续满映射</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Eular-定理&quot;&gt;&lt;a href=&quot;#Eular-定理&quot; class=&quot;headerlink&quot; title=&quot;Eular 定理&quot;&gt;&lt;/a&gt;Eular 定理&lt;/h1&gt;&lt;p&gt;对于一个多面体 P，我们定义&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;v：定点数&lt;/li&gt;
&lt;li&gt;e：棱
      
    
    </summary>
    
    
      <category term="Topology" scheme="http://yoursite.com/tags/Topology/"/>
    
  </entry>
  
  <entry>
    <title>Stochastic-Process (Generating Function)</title>
    <link href="http://yoursite.com/2018/07/27/Stochastic-Process-5/"/>
    <id>http://yoursite.com/2018/07/27/Stochastic-Process-5/</id>
    <published>2018-07-27T02:23:34.000Z</published>
    <updated>2018-07-28T09:06:43.720Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Generating-Function"><a href="#Generating-Function" class="headerlink" title="Generating Function"></a>Generating Function</h1><h3 id="Three-kinds-of-generating-functions"><a href="#Three-kinds-of-generating-functions" class="headerlink" title="Three kinds of generating functions"></a>Three kinds of generating functions</h3><ul><li>Probability Generating Function (PGF) : related to Z-transform</li><li>Moment Generating Function (MGF) : related to Laplace transform</li><li>Characteristic Function (CF) : related to Fourier transform</li></ul><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li>PGF: handling non-negative integral random variables</li><li>MGF: handling general random variables</li><li>CF: equally useful with MGF</li></ul><h3 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h3><ul><li>Easy to characterizing the distribution of the sum of independent random variables</li><li>Play a central role in the study of branching processes</li><li>Provide a bridge between complex analysis and probability</li><li>……</li></ul><hr><h1 id="Moment-Generating-Function"><a href="#Moment-Generating-Function" class="headerlink" title="Moment Generating Function"></a>Moment Generating Function</h1><p><strong>Definition (Moment Generating Function)</strong> MGF of an r.v. $X$ is $M(t) = E(e^{tX})$, as a function of $t$ (different t denote different valued moment) <strong><em>and this must finite on some open interval (-a,a) containing 0</em></strong> or dont exist.</p><h3 id="Why-we-need-MGF"><a href="#Why-we-need-MGF" class="headerlink" title="Why we need MGF"></a>Why we need MGF</h3><ul><li>MGF encodes the moments of an r.v.</li><li>MGF of an r.v. Determines its distribution, like CDF and PMF/PDF</li><li>MFG make it easy to find the distribution of a sum of i.r.v.s.</li></ul><p><strong>Theorem (Moments via Derivatives of the MGF)</strong> $E(X^n) = M^{(n)}(0)$<br>Using Taylor expansion of $M(t)$ at 0</p><script type="math/tex; mode=display">M(t) = \sum_{n=0}^{\infty} M^{(n)}(0) \frac{t^n}{n!}</script><p>Using Taylor expansion of $E(X)$</p><script type="math/tex; mode=display">M(t) = E(e^{tX}) = E\left(  \sum_{n=0}^{\infty} X^n \frac{t^n}{n!}  \right)=\sum_{n=0}^{\infty} E(X^n) \frac{t^n}{n!}</script><p>Matching the coefficients of two expansions, we get $E(X^n) = M^{(n)}(0)$</p><h3 id="MGF-of-Distribution"><a href="#MGF-of-Distribution" class="headerlink" title="MGF of Distribution"></a>MGF of Distribution</h3><p><strong>Theorem (MGF Determines the Distribution)</strong> Two r.v. have the same MGF have the same distribution, more strictly, if there is even a tiny interval containing 0 on which the MGF are equal, the the r.v.s must have same distribution.</p><p><strong>Example 1 (Bernoulli MGF)</strong> MGF of $X\sim Bern(p)$<br>$e^{tX}=e^t$ with probability $p$, and $1$ with probability $q$, so $M(t) = E(e^{tX})=pe^t + q$</p><p><strong>Example 2 (Geometric MGF)</strong> MGF of $X\sim Geom(p)$</p><script type="math/tex; mode=display">M(t) = E(e^{tX})=\sum_{k=0}^{\infty} e^{tk}q^kp=p\sum_{k=0}^{\infty} (qe^t)^k=\frac{p}{1-qe^t}</script><p>t in $(-\infty, log(1/p))$</p><p><strong>Example 3 (Uniform MGF)</strong> MGF of $U\sim Unif(a,b)$</p><script type="math/tex; mode=display">M(t) = E(e^{tU}) = \int_a^b e^{tu}\frac{1}{b-a} du = \frac{e^{tb}-e^{ta}}{t(b-a)}</script><p>and $M(0) = 1$</p><p><strong>Example 4 (Binomial MGF)</strong> $Bin(n,p)$</p><script type="math/tex; mode=display">M(t) = (pe^t+q)^n</script><p><strong>Example 5 (Negative Binomial)</strong> $NBin(r,p)$</p><script type="math/tex; mode=display">M(t) = \left(  \frac{p}{1-qe^t}  \right)^r</script><p><strong>Theorem (MGF of Location-Scale Transformation)</strong> If $X$ has MGF $M(t)$, then MGF of $a+bX$ is</p><script type="math/tex; mode=display">E(e^{t(a+bX)})=e^{at}E(e^{btX})=e^{at}M(bt)</script><p><strong>Example 6 (Normal MGF)</strong> MGF of $(X = \mu + \sigma Z) \sim N(\mu,\sigma^2)$</p><script type="math/tex; mode=display">M_Z(t) = E(e^{tZ})=\int_{-\infty}^{\infty}e^{tz}\frac{1}{\sqrt{2\pi}}e^{-z^2/2}dz=e^{t^2/2}</script><p>Use the Theorem above then</p><script type="math/tex; mode=display">M_X(t) = e^{\mu t}M_Z(\sigma t) = e^{\mu t}e^{(\sigma t)^2/2}  = e^{\mu t + \frac{1}{2} \sigma^2 t^2}</script><h3 id="Sum-of-Independent-Distributions"><a href="#Sum-of-Independent-Distributions" class="headerlink" title="Sum of Independent Distributions"></a>Sum of Independent Distributions</h3><p><strong>Theorem (MGF of A Sum of Independent R.V.s)</strong> If $X$ and $Y$ are independent, Then</p><script type="math/tex; mode=display">M_{X+Y} (t) = M_X(t) M_Y(t)</script><p><strong>Example 1 (Sum of Poissons)</strong> $X\sim Pois(\lambda), Y\sim Pois(\mu)$, $X$ and $Y$ are independent. Then $X+Y \sim Pois(\lambda + \mu)$<br>The MGF of $X$ is</p><script type="math/tex; mode=display">E(e^{tX}) = \sum_{k=0}^{\infty}e^{tk}\frac{e^{-\lambda}\lambda^k}{k!}=e^{-\lambda}\sum_{k=0}^{\infty}\frac{(\lambda e^t)^k}{k!}=e^{-\lambda}e^{\lambda e^t}=e^{\lambda(e^t-1)}</script><p>The MGF of $X+Y$ is</p><script type="math/tex; mode=display">E(e^{tX})E(e^{tY}) = e^{\lambda (e^t-1)} e^{\mu (e^t-1)} = e^{(\lambda + \mu)(e^t-1)}</script><p>Which is the $Pois(\lambda + \mu)$, so $X+Y\sum Pois(\lambda+\mu)$</p><p><strong>Example 2 (Sum of Normals)</strong> $X_1\sim N(\mu_1,\sigma_1^2)$ and $X_2 \sim N(\mu_2,\sigma_2^2)$, $X_1+X_2 = ?$<br>MGF of $X_1+X_2$ is</p><script type="math/tex; mode=display">M_{X_1+X_2}(t)=  M_{X_1}(t)M_{X_2}(t)= e^{\mu_1t+\frac{1}{2}\sigma^2_1t^2}\cdot e^{\mu_2 t+\frac{1}{2}\sigma_2^2 t^2}=e^{(\mu_1+\mu_2)t+\frac{1}{2}(\sigma_1^2+\sigma_2^2)t^2}</script><p>Which is the N(\mu_1 + \mu_2, \sigma_2^2 + \sigma_1^2) MGF.</p><hr><h1 id="Probability-Generating-Function"><a href="#Probability-Generating-Function" class="headerlink" title="Probability Generating Function"></a>Probability Generating Function</h1><p><strong>Definition (PGF)</strong> PGF of a nonnegative integer-valued r.v. $X$ with PMF $p_k = P(X=k)$ is the generating function of the PMF, By LOTUS , this is</p><script type="math/tex; mode=display">E(t^X) = \sum_{k=0}^{\infty} p_k t^k</script><p><strong>Example 1 (Generating Dice Probabilities)</strong> Let $X$ be the sum from rolling 6 pair dice, $X_1,…,X_6$ be the individual rolls, what is $P(X=18)$ ?<br>The PGF of $X_1$ is</p><script type="math/tex; mode=display">E(t^{X_1}) = \frac{1}{6}(t+t^2+\dotsb+t^6)</script><p>The PGF of $X$ is</p><script type="math/tex; mode=display">E(t^X) = E(t^{X_1}\dotsb t^{X_6}) = E(t^{X_1})\dotsb E(t^{X_6})=\frac{t^6}{6^6}(1+t+\dotsb +t^5)^6</script><p>The coefficient of $t^{18}$ in the PGF is $P(X=18)$, so</p><script type="math/tex; mode=display">P(X=18) = \frac{3421}{6^6}</script><p><strong>Theorem (PMF \&amp; PGF)</strong></p><script type="math/tex; mode=display">P(X=k) = \frac{g_{X}^{(k)}(0)}{k!}</script><hr><h1 id="Characteristic-Function"><a href="#Characteristic-Function" class="headerlink" title="Characteristic Function"></a>Characteristic Function</h1><p><strong>Definition CF</strong> The Characteristic function of a random variable $X$ is the function $\phi : R \rightarrow C$ defined by</p><script type="math/tex; mode=display">\phi(t) = E(e^{itX}), i = \sqrt{-1}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Generating-Function&quot;&gt;&lt;a href=&quot;#Generating-Function&quot; class=&quot;headerlink&quot; title=&quot;Generating Function&quot;&gt;&lt;/a&gt;Generating Function&lt;/h1&gt;&lt;h3 i
      
    
    </summary>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
  </entry>
  
  <entry>
    <title>Stochastic-Process (Continuous Random Variable)</title>
    <link href="http://yoursite.com/2018/07/25/Stochastic-Process-4/"/>
    <id>http://yoursite.com/2018/07/25/Stochastic-Process-4/</id>
    <published>2018-07-25T12:04:57.000Z</published>
    <updated>2018-07-28T12:05:50.907Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Probability-Density-Function"><a href="#Probability-Density-Function" class="headerlink" title="Probability Density Function"></a>Probability Density Function</h1><p><strong>Definition (Probability Density Function)</strong>: For a continuous r.v. $X$ with CDF $F$, the <strong><em>probability density function (PDF)</em></strong> of $X$ is the derivative $f$ of the $F$</p><script type="math/tex; mode=display">P(a\leq X \leq b) = \int_a^b f_X(x)dx = F(b) - F(a)</script><script type="math/tex; mode=display">P(X\in [x,x+\delta]) \approx f_X(x) \cdot \delta</script><p><strong>Relation between PDF &amp; PMF</strong>: The PDF is the analogous to the PMF in many ways. But, the PDF $f(x)$ is not a probability.</p><p><strong>Relation between PDF &amp; CDF</strong>: Let $X$ be a continuous r.v. with PDF $f$. Then the CDF of $X$ is given by</p><script type="math/tex; mode=display">F(x) = \int_{-\infty}^x f(x) dt</script><p><strong>CDF of Logistic Distribution</strong></p><script type="math/tex; mode=display">F(x) = \frac{e^x}{1+e^x}, x\in R</script><p><strong>CDF of Rayleigh Distribution</strong></p><script type="math/tex; mode=display">F(x) = 1 - e^{-x^2/2}, x>0</script><p><strong>Theorem (Expectation of Continuous R.V.)</strong></p><script type="math/tex; mode=display">E(X) = \int_{-\infty}^{\infty} x f(x) dx</script><p><strong>Theorem (Expectation via Survial Function)</strong> Let $G$ be the survial function of $X$, Then</p><script type="math/tex; mode=display">E(X) = \int_0^{\infty} G(x) dx</script><p><strong>Theorem (LOTUS: Continuous)</strong></p><script type="math/tex; mode=display">E(g(X)) = \int_{-\infty}^{\infty} g(x) f(x) dx</script><hr><h1 id="Uniform-Distribution"><a href="#Uniform-Distribution" class="headerlink" title="Uniform Distribution"></a>Uniform Distribution</h1><p><strong>Definition (Uniform Distribution)</strong> Distribution on the interval$(a,b)$, and its PDF is</p><script type="math/tex; mode=display">f(x) = \left \{  \begin{array}{ll} \frac{1}{b-a} & if\ a<x<b \\ 0 & otherwise \end{array} \right.</script><p>We denote this by $U\sim Unif(a,b)$</p><p><strong>Example</strong>: suppose $X_1,X_2,…,X_n$ are i.i.d $Unif(0,1)$ random variable and let $Y = min(X_1,X_2,…,X_n)$ be their minimum. Find $E(Y)$</p><p>If $0&lt;x&lt;1$, we have $P(X_i \leq x) = x$, it follows that</p><script type="math/tex; mode=display">\begin{align}  P(Y>x)&= P(min (X_1,...,X_n)>x) \\        &= P(X_1>x,...,X_n>x)\\        &= \prod_{i=1}^n P(X_i > x) = (1-x)^n\end{align}</script><p>From above, we use the survial function to calculate the expectation</p><script type="math/tex; mode=display">E(Y) = \int_0^{\infty} P(Y>x) dx = \int_0^1(1-x)^ndx = \int_0^1 x^n dx = \frac{1}{n+1}</script><hr><h1 id="Normal"><a href="#Normal" class="headerlink" title="Normal"></a>Normal</h1><p><strong>Definition (Standard Normal Distribution)</strong> A c.r.v. $Z$ is said to have the standard Normal Distribution if its $PDF$ $\varphi$ is given by:</p><script type="math/tex; mode=display">\varphi(z) = \frac{1}{\sqrt(2\pi)} e^{-z^2/2},-\infty < z < \infty</script><p>We write this as $Z\sim N(0,1)$, and $Z$ has mean 0 and variance 1, the CDF $\phi$ is</p><script type="math/tex; mode=display">\phi(z) = \int_{-\infty}^z \varphi(t) dt = \int_{-\infty}^z \frac{1}{\sqrt{2\pi}}e^{-t^2/2}dt</script><p><strong>Definition (Normal Distribution)</strong> If $Z\sim N(0,1)$ then</p><script type="math/tex; mode=display">X = \mu + \sigma Z</script><p>is said to have the Normal Distribution with mean $\mu$ and variance $\sigma^2$, denote this by $X\sim N(\mu,\sigma^2)$</p><p><strong>Theorem (Normal CDF and PDF)</strong> Let $X\sim N(\mu, \sigma^2)$,<br>CDF of $X$ is</p><script type="math/tex; mode=display">F(x) = \phi(\frac{x-\mu}{\sigma})</script><p>PDF of $X$ is</p><script type="math/tex; mode=display">f(x) = \varphi (\frac{x-\mu}{\sigma})\frac{1}{\sigma}</script><hr><h1 id="Exponential"><a href="#Exponential" class="headerlink" title="Exponential"></a>Exponential</h1><p><strong>Definition (Exponential Distribution)</strong></p><script type="math/tex; mode=display">f(x) = \lambda e ^{-\lambda x}, x>0</script><p>we denote this by $X\sim Expo(\lambda)$. The corresponding CDF is</p><script type="math/tex; mode=display">F(x) = 1-e^{-\lambda x},x>0</script><p><strong>Theorem (Memoryless Property)</strong></p><script type="math/tex; mode=display">P(X\geq s+t | X\geq s) = P(X\geq t)</script><ul><li>If $X$ is a positive continuous random variable with memoryless property, then $X$ has an Exponential distribution</li><li>Geometric Distribution is also Memoryless</li><li>Exponential distribution as the “continuous counterpart” of the Geometric distribution</li></ul><p><strong>Exponential \&amp; Geometric via $\delta$- Steps</strong><br>We devide a unit of time into n pieces, each of size $\delta = \frac{1}{n}$, and the trial occurs every $\delta$ time period and success with probability $\lambda \delta$. Denote $Y$ as the number of trials until first success, $\hat{Y}$ as the time until first success under $Y$.</p><script type="math/tex; mode=display">Y\sim FS(\lambda \delta)</script><p>Thus we have</p><script type="math/tex; mode=display">F(\hat{Y}) = E(Y)\cdot \delta = \frac{1}{\lambda\delta}\cdot \delta=\frac{1}{\lambda}</script><p>And</p><script type="math/tex; mode=display">\begin{array}P(Y>t) &= P\{ all\ trials\ up\ to\ time\ t\ has\ been\ failures \} \\&=P\{ at\ least\ \frac{t}{\delta}\ failures\}\\&=(1-p)^{\frac{t}{\delta}}=(1-\lambda \delta)^{\frac{t}{\delta}}\\&=\left[  (1-\lambda\delta)^{\frac{1}{\lambda\delta}}  \right]^{\lambda t} \xrightarrow{\delta \rightarrow 0} e^{-\lambda t}\end{array}</script><p><strong>Theorem property of Exponential</strong> Given $X_1\sim Expo(\lambda_1)$, $X_2\sim Expo(\lambda_2)$, $X_1 \bot X_2$ ($X_1$ and $X_2$ are independent), then</p><script type="math/tex; mode=display">P(X_1<X_2) = \frac{\lambda_1}{\lambda_1 + \lambda_2}</script><p>It can be solved by $\delta$-step</p><p>Some physical phenomenon follow the Exponential distribution like the radioactive decay.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Probability-Density-Function&quot;&gt;&lt;a href=&quot;#Probability-Density-Function&quot; class=&quot;headerlink&quot; title=&quot;Probability Density Function&quot;&gt;&lt;/a&gt;Pr
      
    
    </summary>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
  </entry>
  
  <entry>
    <title>Generative-Adversarial-Nets</title>
    <link href="http://yoursite.com/2018/07/25/Generative-Adversarial-Nets/"/>
    <id>http://yoursite.com/2018/07/25/Generative-Adversarial-Nets/</id>
    <published>2018-07-25T11:21:44.000Z</published>
    <updated>2018-07-25T11:57:38.016Z</updated>
    
    <content type="html"><![CDATA[<script type="math/tex; mode=display">\mathop{min}_G \mathop{max}_D = E_{}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathop{min}_G \mathop{max}_D = E_{}&lt;/script&gt;
      
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="GAN" scheme="http://yoursite.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>Stochastic-Process （Abbreviate &amp; Notation）</title>
    <link href="http://yoursite.com/2018/07/23/Stochastic-Process-0/"/>
    <id>http://yoursite.com/2018/07/23/Stochastic-Process-0/</id>
    <published>2018-07-23T08:54:34.000Z</published>
    <updated>2018-07-29T03:12:26.199Z</updated>
    
    <content type="html"><![CDATA[<p><strong>r.v.s.</strong>: random variable sequence</p><p><strong>PMF (Probability Mass Function)</strong> $P(X=x)$</p><p><strong>CDF (Cumulative Distribution Function)</strong> $P(X \leq x)$</p><p><strong>PDF (Probability Density Function)</strong> derivate of CDF</p><p><strong>PGF (Probability Generating Function)</strong> $E(t^X) = \sum_{k=0}^{\infty} p_k t^k$</p><p><strong>MGF (Moment Generating Function)</strong> $M(t) = E(e^{tX})$</p><hr><h1 id="Distributions"><a href="#Distributions" class="headerlink" title="Distributions"></a>Distributions</h1><ul><li><strong>Binomial Distribution</strong> $X\sim B(n,p)$: number of success in n trails</li><li><strong>HyperGeometric Distribution</strong> $X\sim HGeom(w,b,n)$: draw n balls between w white and b black</li><li><strong>Geometric Distribution</strong> $X\sim Geom(p)$: number of the Bernoulli trails before success (First Success Distribution)</li><li><strong>Negative Binomial Distribution</strong> $X\sim NBin(r,p)$: number of the Bernoulli trails before $r^{th}$ success</li><li><strong>Poisson Distribution</strong> $X\sim Pois(\lambda)$: number of times an event occurs in an interval of time or space</li><li><strong>Uniform Distribution</strong> $U\sim Unif(a,b)$: Distribution on the interval $(a,b)$</li><li><strong>Standard Normal Distribution</strong> $X\sim N(0,1)$</li><li><strong>Normal Distribution</strong> $X\sim N(\mu,\sigma^2)$</li></ul><p><img src="/2018/07/23/Stochastic-Process-0/img1.jpg" align="justify" style=" width:600px;"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;r.v.s.&lt;/strong&gt;: random variable sequence&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PMF (Probability Mass Function)&lt;/strong&gt; $P(X=x)$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CDF (Cu
      
    
    </summary>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
  </entry>
  
  <entry>
    <title>Stochastic Process (Expectation)</title>
    <link href="http://yoursite.com/2018/07/22/Stochastic-Process-3/"/>
    <id>http://yoursite.com/2018/07/22/Stochastic-Process-3/</id>
    <published>2018-07-22T02:30:26.000Z</published>
    <updated>2018-07-27T12:39:21.846Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="Expectation"><a href="#Expectation" class="headerlink" title="Expectation"></a>Expectation</h1><p><strong>Definition (Expectation of R.V.)</strong></p><script type="math/tex; mode=display">E(X) = \sum_{x}\underbrace{x}_{value} \underbrace{P(X=x)}_{PMF\ at\ x}</script><p><strong>Theorem (Monotonicity)</strong>: $X$ and $Y$ are r.v.s. such that $X&gt;Y$ with probability 1.<br>Then $E(X)\geq E(Y)$</p><p><strong>Theorem (Expectation via Survial Function)</strong>: Let $X$ be a nonnegative r.v. Let $F$ be the CDF of $X$, and define survial function of $X$ named $G$ as $G(x) = 1-F(x) = P(X&gt;x)$, Then</p><script type="math/tex; mode=display">E(x) = \sum_{n=0}^{\infty} G(x)</script><p><strong>Theorem (Low Of The Unconscious Statistician(LOTUS))</strong>: If $X$ is discrete r.v. and $g$ is a function from $R$ to $R$, then</p><script type="math/tex; mode=display">E(g(x)) = \sum_x g(x)P(X=x)</script><h3 id="Propertise-of-Expectation"><a href="#Propertise-of-Expectation" class="headerlink" title="Propertise of Expectation"></a>Propertise of Expectation</h3><ul><li>$E(X+Y) = E(X) + E(Y)$</li><li>$E(cX) = c E(x)$</li><li>If $X$ and $Y$ are independent, $E(XY) = E(X) E(Y)$</li></ul><h3 id="Inequalities-of-Expectation"><a href="#Inequalities-of-Expectation" class="headerlink" title="Inequalities of Expectation"></a>Inequalities of Expectation</h3><ul><li>Cauchy–Bunyakovsky–Schwarz inequality<script type="math/tex; mode=display">E[XY]^2\leq E[X^2] E[Y^2]</script></li><li><a href="https://en.wikipedia.org/wiki/Expected_value#Inequalities" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Expected_value#Inequalities</a> …</li></ul><hr><h1 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h1><p><strong>Definition (Variance and Standard Deviation)</strong> variance of an r.v. $X$ is</p><script type="math/tex; mode=display">Var(X) = E(X-EX)^2</script><p>Square root of the variance is standard deviation (SD):</p><script type="math/tex; mode=display">SD(X)  = \sqrt{Var(X)}</script><h3 id="Propertise-of-Variance"><a href="#Propertise-of-Variance" class="headerlink" title="Propertise of Variance"></a>Propertise of Variance</h3><ul><li>For any r.v. $X$, $Var(X) = E(X^2) - (EX)^2$</li><li>$Var(X + c ) = Var(X)$</li><li>$Var(c X ) = c^2Var(X)$</li><li>If $X$ and $Y$ are independent, then $Var(X+Y) = Var(X) + Var(Y)$</li></ul><hr><h1 id="Geometric-and-Negative-Binomial"><a href="#Geometric-and-Negative-Binomial" class="headerlink" title="Geometric and Negative Binomial"></a>Geometric and Negative Binomial</h1><p><strong>Definition (Geometric Distribution)</strong>: Consider a sequence of independent Bernoulli trials, each with the same success probability $p\in (0,1)$, trails performed until a success occurs. Let $X$ be the number of the failures before the first successful trail. Then $X$ has the Geometric Distributions, denote by $X\sim Geom(p)$</p><p><strong>Theorem (Geometric PMF)</strong>: If $X\sim Geom(p)$, then the PMF of $X$ is</p><script type="math/tex; mode=display">P(X=k) = (1-p)^kp</script><p><strong>Theorem (Memoryless Property)</strong>: If $X\sim Geom(p)$, then for positive integer n</p><script type="math/tex; mode=display">P(X\geq n+k | X \geq k ) = P(X\geq n)</script><p><strong>Definition (First Success Distribution)</strong>: very similay to Geometric $X$, Let it be $Y$, and $X+1 = Y$ …. , we denote it by $FS(p)$</p><p><strong>Definition (Negative Binomial Distribution)</strong>: In a sequence of independent Bernoulli trails with p, if $X$ is the number of failures before $r^{th}$ success, then $X$ is the Negative Binomial Distribution with $r$ and $p$, denoted by $X\sim NBin(r, p)$</p><p><strong>Theorem (Negative Binomial PMF)</strong>: If $X\sim NBin(r,p)$, then the PMF of $X$ is</p><script type="math/tex; mode=display">P(X=n) = \left ( \begin{array}{c} n+r-1 \\ r-1 \end{array}   \right )p^r(1-p)^n</script><p><strong>Theorem (Geometric &amp; Negative Binomial)</strong>: Let $X\sim NBin(r,p)$, and $X_i$ are $i.i.d. Geom(p)$ , Then we have $X= X_1+\dotsb + X_r$</p><hr><h1 id="Indicator-R-V"><a href="#Indicator-R-V" class="headerlink" title="Indicator R.V."></a>Indicator R.V.</h1><p><strong>Definition (Indicator R.V.)</strong></p><script type="math/tex; mode=display">I_A =\left \{  \begin{array}{ll}    1 & if\ A\ occurs \\    0 & otherwise  \end{array}\right .</script><h3 id="Propertise-of-Indicator-R-V"><a href="#Propertise-of-Indicator-R-V" class="headerlink" title="Propertise of Indicator R.V."></a>Propertise of Indicator R.V.</h3><ul><li>$(I_A)^k = I_A$</li><li>$I_{A^c} = 1- I_A$</li><li>$I_{A\cap B} = I_A I_B$</li><li>$I_{A\cup B} = I_A + I_B - I_A I_B$</li></ul><p><strong>Theorem (Bridge between Probability &amp; Expectation)</strong></p><script type="math/tex; mode=display">P(A) = E(I_A)</script><p><strong>Example 1</strong>: Au urn contain R G B three balls, r g b is probability draw a ball from it (r+g+b = 1), whats the expected number of different <strong><em>colors</em></strong> of ball before getting the first R ball ?<br>Let $I_g$ be the $1$ if G is obtained before R, and define the $I_b$ similarly. Then</p><script type="math/tex; mode=display">E(I_g) = P(green\ before\ red) = \frac{g}{g+r}</script><p>since “green before red” means that first non-blue ball is green , so probability is $frac{g}{g+r}$, then, the final result is</p><script type="math/tex; mode=display">E(I_g+I_b) = \frac{g}{g+r} + \frac{b}{b+r}</script><h3 id="Moments-amp-Indicators"><a href="#Moments-amp-Indicators" class="headerlink" title="Moments &amp; Indicators"></a>Moments &amp; Indicators</h3><p>Given n events $A_1,\dotsb, A_n$ and indicators $I_j, j = 1, \dotsb, n$</p><ul><li>$X = \sum_{j=1}^n I_j$: the number of events occur</li><li><script type="math/tex">\left( \begin{array}{c} X \\ 2 \end{array} \right) = \sum_{i<j}I_iI_j</script>: the number of pairs of events that occur</li><li><script type="math/tex">E( \left( \begin{array}{c} X \\ 2 \end{array} \right) ) = \sum_{i<j} P(A_iA_j)</script> .<ul><li>$E(X^2) = 2\sum_{i&lt;j} P(A_iA_j) + E(X)$</li><li>$Var(X) = 2\sum_{i&lt;j} P(A_iA_j) + E(X) - (E(X))^2$</li></ul></li></ul><hr><h1 id="Poisson"><a href="#Poisson" class="headerlink" title="Poisson"></a>Poisson</h1><p><strong>Definition (Poisson Distribution)</strong> $X\sim Pois(\lambda)$</p><script type="math/tex; mode=display">P(X=k) = \frac{e^{-\lambda}\lambda^k}{k!},k=0,1,2,\dotsb</script><h3 id="Property-of-poisson"><a href="#Property-of-poisson" class="headerlink" title="Property of poisson"></a>Property of poisson</h3><ul><li>$E(X) = \lambda$</li><li>$E(X^2)  = \lambda(1+\lambda)$</li><li>$Var(X) = \lambda$</li></ul><p><strong>Poisson Approximation</strong>: Let $A_1,A_2,\dotsb,A_n$ be events with $p_j = P(A_j)$, here $n$ is larger where $p_j$ is small , and $A_j$ is independent or weakly dependent, let <script type="math/tex">X = \sum_{j=1}^n I(A_j)</script> count how many $A_j$ occur. Then $X$ is approximately $Pois(\lambda)$, with $\lambda = \sum_{j=1}^n p_j$</p><p><strong>Theorem（Sum of Independent Poisson)</strong>: If $X\sim Pois(\lambda_1), Y\sim Pois(\lambda_2)$, and $X$ is independent of $Y$, then $X+Y \sim Pois(\lambda_1 + \lambda_2)$</p><p><strong>Theorem（Poisson Approximation to Binomial)</strong>: If $X\sim Bin(n,p)$ and we let $n \rightarrow \infty and p\rightarrow 0$ , such that $\lambda = np$, then the PMF of $X$ converges to the $Pois(\lambda)$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;h1 id=&quot;Expectation&quot;&gt;&lt;a href=&quot;#Expectation&quot; class=&quot;headerlink&quot; title=&quot;Expectation&quot;&gt;&lt;/a&gt;Expectation&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Definition (Expectati
      
    
    </summary>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Math" scheme="http://yoursite.com/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Neural Style</title>
    <link href="http://yoursite.com/2018/07/19/Neural-Style/"/>
    <id>http://yoursite.com/2018/07/19/Neural-Style/</id>
    <published>2018-07-19T02:25:16.000Z</published>
    <updated>2018-07-22T02:31:09.823Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Nerual-Style"><a href="#Nerual-Style" class="headerlink" title="Nerual Style"></a>Nerual Style</h1><p>There are two aspect for a image, one is the <strong>content</strong> of the image, which can be descriped as elements or object in the image, another is the <strong>style</strong> of the image, it might be abstract, and usually revealed by the painting skill or technique.</p><p>Shortly, we have two image, one for style while the other for content. now, we want to combine the style in image1 and the content in image2 together, and it can be achieved from deep neural net work, and we call it <strong>Neural Style</strong>.</p><p>Moreover we simply define the loss function care both style and content</p><script type="math/tex; mode=display">L_{total} = \alpha L_{content}+\beta L_{style}</script><p>Now let’s have a look about what neural network can do here, and analysis the affect of $L_{content}$ and $L_{style}$ independently.</p><p>Suppose we have the content image, and send it to the neural network, it will have the responses in each layer by filters, we also construct a white noisy image, filter it in the same way, and define a loss $L_{content}$ between filtered content and filtered noisy, we take the noisy image as input,and it can update iterativly.</p><p><img src="/2018/07/19/Neural-Style/img1.jpg" alt="reconstruction"></p><p>The image above show the reconstruction result between different layers, and reconstruction from lower layers(a,b,c) is alomost perfect, the style reconstruction may be more realistic in the deeper layer.</p><p>Let’s get familiar with some notion of the formulation first( suppse we are in the $l^{th}$ level of the net ):</p><ul><li><strong>$\vec{p}$</strong>: Original <strong>content</strong> image (input)<ul><li><strong>$P^l$</strong>: Content feature representation in layer $l$ respect to $\vec{p}$</li></ul></li><li><strong>$\vec{a}$</strong>: Original <strong>style</strong> image (input)<ul><li><strong>$A^l$</strong>: Style feature representation in layer $l$ respect to $\vec{a}$</li></ul></li><li><p><strong>$\vec{x}$</strong>: Target image (output)</p><ul><li><strong>$F^l$</strong>: Content feature representation in layer $l$ respect to $\vec{x}$</li><li><strong>$G^l$</strong>: Style feature representation in layer $l$ respect to $\vec{x}$</li><li><strong>$F_{ij}^l$</strong>: Element of $i^{th}$ filter at $j^{th}$ position in layer $l$</li></ul></li><li><p><strong>$N_l$</strong>: The number of the filters in the $l^{th}$ level</p></li><li><strong>$M_l$</strong>: The size of a feature map produced by a filter,usually it equals to $height \times weight$</li></ul><p>The squared-error loss between two content feature representations is:</p><script type="math/tex; mode=display">L_{content}(\vec{p},\vec{x},l) = \frac{1}{2} \sum_{i,j}(F_{ij}^l - P_{ij}^l)^2</script><p>In each layer, build a style representation compute the correlations between the different filter responses, which is called Gram Matrix $G^l\in R^{N_l \times N_l}$, and $G_{ij}^l$ is the inner product between the vectorized feature map between $i$ and $j$ in layer $l$</p><script type="math/tex; mode=display">G_{ij}^l = \sum_k F_{ik}^l F_{jk}^l</script><p>Also we have</p><script type="math/tex; mode=display">A_{ij}^l = \sum_k P_{ik}^l P_{jk}^l</script><p>The contribution of the layer to the total loss is</p><script type="math/tex; mode=display">E_l = \frac{1}{4N_l^2 M_l^2 }\sum_{i,j}(G_{ij}^l - A_{ij}^l)^2</script><p>And the total loss is</p><script type="math/tex; mode=display">L_{style}(\vec{a},\vec{x}) = \sum_{l=0}^L w_lE_l</script><p>Let’s focus more on the detail about the gradient of the loss:</p><p>The derivative of content loss respect to activations in layer l equals</p><script type="math/tex; mode=display">\frac{\partial L_{content}}{\partial F_{ij}^l} =\left \{  \begin{array}{ll}    (F^l - P^l)_{ij} & if\ F_{ij}^l > 0 \\    0 & if\ F_{ij}^l < 0  \end{array}\right .</script><p>The derivative of style loss respect to activations in layer l equals</p><script type="math/tex; mode=display">\frac{\partial E_l}{\partial F_{ij}^l} =\left \{  \begin{array}{ll}    \frac{1}{N_l^2M_l^2}((F^l)^T(G^l - A^l))_{ij}& if\ F_{ij}^l > 0 \\    0 & if\ F_{ij}^l < 0  \end{array}\right .</script><p>The final loss function we want to minimize is</p><script type="math/tex; mode=display">L_{total}(\vec{p},\vec{a},\vec{x}) = \alpha L_{content}(\vec{p},\vec{x}) + \beta L_{style}(\vec{a},\vec{x})</script><hr><h1 id="Fast-Neural-Style"><a href="#Fast-Neural-Style" class="headerlink" title="Fast Neural Style"></a>Fast Neural Style</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/07/19/Neural-Style/img2.jpg" alt="FastNet" title="">                </div>                <div class="image-caption">FastNet</div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Nerual-Style&quot;&gt;&lt;a href=&quot;#Nerual-Style&quot; class=&quot;headerlink&quot; title=&quot;Nerual Style&quot;&gt;&lt;/a&gt;Nerual Style&lt;/h1&gt;&lt;p&gt;There are two aspect for a ima
      
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Stochastic Process (Random Variable)</title>
    <link href="http://yoursite.com/2018/07/07/Stochastic-Process-1/"/>
    <id>http://yoursite.com/2018/07/07/Stochastic-Process-1/</id>
    <published>2018-07-07T00:21:04.000Z</published>
    <updated>2018-07-22T02:55:04.070Z</updated>
    
    <content type="html"><![CDATA[<p>There are some notation occationals</p><p><strong>Definition (Discrete Random Variable)</strong> A variable $X$ is <strong><em>discrete</em></strong> if there is a finite list of value $a_1,a_2,…,a_n$ that $P(X=a_j) = 1$, $P(X=x)&gt;0$ is the <strong><em>support</em></strong> of $X$</p><p><strong>Definition (Probability Mass Function)</strong> <strong><em>The probability mass function (PMF)</em></strong> of a discrete r.v. $X$ is the function $p_X$ given by $p_X(x) = P(X=x)$.</p><h1 id="Bernoulli-amp-Binomial"><a href="#Bernoulli-amp-Binomial" class="headerlink" title="Bernoulli &amp; Binomial"></a>Bernoulli &amp; Binomial</h1><p><strong>Definition (Bernoulli Distribution)</strong> shortly, $P(X=1)=p$ and $P(X=0) = 1 - p$, and write as $X\sim Bern(p)$</p><p><strong>Definition (Indicator Random Variable)</strong> The indicator random variable of an event $A$ is the r.v. equals 1 if $A$ occurs and 0 otherwise, We denote the indicator of $A$ by $I_A$ or $I(A)$. Note $I_A \sim Bern(p)$ with p = P(A)</p><p><strong>Theorem (Binomial PMF)</strong> Binomial Distribution is the repeatation of Bernoulli Distribution. If $X\sim Bin(n, p)$ then the PMF of X is</p><script type="math/tex; mode=display">P(X=k) = \left( \begin{array}{c} n \\ k \end{array} \right) p^k (1-p)^{n-k}</script><h1 id="Hypergeometric"><a href="#Hypergeometric" class="headerlink" title="Hypergeometric"></a>Hypergeometric</h1><p><strong>urn Model</strong> A box is fiiled with $w$ white and $b$ black balls, then drawing n balls</p><ul><li>With replacement: $Bin(n,w/(w+b))$ for the number of white balls</li><li>Without replacement : Hypergeometric distribution $HGeom(w,b,n)$</li></ul><p><strong>Theorem (Hypergeometric PMF)</strong> If $X \sim HGeom(w,b,n)$, then the PMF of $X$ is</p><script type="math/tex; mode=display">P(X=k) = \frac {\left ( \begin{array}{c} w \\ k \end{array} \right ) \left( \begin{array}{c} b \\ n-k \end{array} \right)}  {\left( \begin{array}{c} w+b \\ n \end{array} \right)}</script><p><strong>Zipf Distribution</strong> If $X\sim Zipf(\alpha &gt; 0)$, then PMF of $X$ is:</p><script type="math/tex; mode=display">P(X=k) = \frac{\frac{1}{k^{\alpha + 1}}}  {\sum_{j=1}^{\infty}(\frac{1}{j})^{\alpha + 1}}</script><ul><li>Zipf Distribution can measure the Word Frequency</li></ul><h1 id="Cumulative-Distribution-Functions"><a href="#Cumulative-Distribution-Functions" class="headerlink" title="Cumulative Distribution Functions"></a>Cumulative Distribution Functions</h1><p><strong>Definition (Cumulative Distribution Function)</strong> The <strong><em>cumulative distribution function(CDF)</em></strong> os an r.v. $X$ is the function $F_X$ given by $F_X(x) = P(X\leq x)$</p><p><strong>Theorem (Valid CDFs)</strong> CDF has the following properties</p><ul><li>Increasing: If $x_1 &lt; x_2$, then $F(x_1) &lt; F(x_2)$</li><li>Right-Continuous: $F(a)  = lim_{x\rightarrow a^+} F(x)$</li><li>Convergence to $0$ and $1$: $lim_{x\rightarrow - \infty} F(x) = 0$ and $lim_{x \rightarrow \infty} F(x) = 1$</li></ul><h1 id="Functions-of-Random-Variable"><a href="#Functions-of-Random-Variable" class="headerlink" title="Functions of Random Variable:"></a>Functions of Random Variable:</h1><p><strong>Definition (Function of an r.v.)</strong> An experiment with sample space S, an r.v. $X$, and a function $g$, also the $g(X)$ is the variable that maps $s$ to $g(X(s))$, for all $s\in S$</p><p><strong>Theorem (PMF of $g(X)$)</strong> for all y in the support of $g(X)$</p><script type="math/tex; mode=display">P(g(X) = y) = \sum_{x:g(x)=y} P(X=x)</script><p>The function of r.v. map the sample space into real number, which is easy for us calculate in mathematic.</p><h1 id="Independence-of-R-V-s"><a href="#Independence-of-R-V-s" class="headerlink" title="Independence of R.V.s"></a>Independence of R.V.s</h1><p><strong>Definition (Independence of two R.V.s)</strong> Random variables $X$ and $Y$ are said to be <strong><em>independent</em></strong></p><script type="math/tex; mode=display">P(X\leq x,Y\leq y) = P(X\leq x)P(Y\leq y)</script><p>for all $x,y\in R$,<br>In the discrete case, equivalent to :</p><script type="math/tex; mode=display">P(X=x,Y=y) = P(X=x)P(Y=y)</script><p><strong>Definition (Independence of many R.V.s)</strong> Random variables $X_1,…,X_n$ are independent if</p><script type="math/tex; mode=display">P(X_1 \leq x_1,\dotsb , X_n \leq x_n) = P(X_1 \leq x_1) \dotsb P(X_n \leq x_n)</script><p>for all $x_1,\dotsb,x_n \in R$</p><p><strong>Definition (i.i.d)</strong> We call some r.v. that are independent and have the same distribution <strong><em>independent and identicallly distributed</em></strong> or <strong><em>i.i.d</em></strong> for short</p><ul><li>Independent: r.v.s provide no information about each others</li><li>Identically distributed: r.v.s have the same PMF</li></ul><p><strong>Theorem</strong> If $X\sim Bin(n,p)$ , $Y \sim Bin(m,p)$, and $X$ is independent of $Y$, then $X+Y \sim Bin(n+m,p)$</p><p><strong>Definition (Conditional Independence of two R.V.s)</strong></p><script type="math/tex; mode=display">P(X\leq x, Y \leq y| Z= z) = P(X\leq x |Z =z) P(Y\leq y|Z=z)</script><p>w</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;There are some notation occationals&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Definition (Discrete Random Variable)&lt;/strong&gt; A variable $X$ is &lt;strong&gt;&lt;em&gt;discrete&lt;
      
    
    </summary>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Math" scheme="http://yoursite.com/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Stochastic Process (Conditional Probability)</title>
    <link href="http://yoursite.com/2018/07/06/Stochastic-Process-2/"/>
    <id>http://yoursite.com/2018/07/06/Stochastic-Process-2/</id>
    <published>2018-07-06T00:24:34.000Z</published>
    <updated>2018-07-23T12:01:35.232Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="Defination-of-Conditonal-Probability"><a href="#Defination-of-Conditonal-Probability" class="headerlink" title="Defination of Conditonal Probability"></a>Defination of Conditonal Probability</h1><p><strong>Defination</strong> Two events $A$ and $B$, with $P(B)&gt;0$, the conditional probability of $A$ given $B$ , denoted by $P(A|B)$, is defined as :</p><script type="math/tex; mode=display">P(A|B)=\frac{P(AB)}{P(B)}</script><ul><li>$P(A)$: prior probability</li><li>$P(A|B)$: posterior probability</li></ul><hr><h1 id="Bayes’-Rule-amp-LOTP"><a href="#Bayes’-Rule-amp-LOTP" class="headerlink" title="Bayes’ Rule &amp; LOTP"></a>Bayes’ Rule &amp; LOTP</h1><h3 id="Chain-Rule"><a href="#Chain-Rule" class="headerlink" title="Chain Rule"></a>Chain Rule</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/07/06/Stochastic-Process-2/sp1.jpg" alt="chain rule" title="">                </div>                <div class="image-caption">chain rule</div>            </figure><script type="math/tex; mode=display">P(A_1,...,A_n) = P(A_1)P(A_2|A_1)P(A_3|A_1A_2)...P(A_n|A_1,...,A_{n-1})</script><h3 id="Bayes’-Rule"><a href="#Bayes’-Rule" class="headerlink" title="Bayes’ Rule"></a>Bayes’ Rule</h3><script type="math/tex; mode=display">P(A|B) = \frac{P(B|A)P(A)}{P(B)}</script><h3 id="LOTP-Law-of-Total-Probability"><a href="#LOTP-Law-of-Total-Probability" class="headerlink" title="LOTP (Law of Total Probability)"></a>LOTP (Law of Total Probability)</h3><p><img src="/2018/07/06/Stochastic-Process-2/sp2.jpg" align="center" style=" width:300px;"></p><p><strong>Theorem</strong>: Let $A_1,A_2,…,A_n$ be the partition of the sample space $S$, with $P(A_1)&gt;0$, Then :</p><script type="math/tex; mode=display">P(B) = \sum_i^n P(B|A_i)P(A_i)</script><p><strong>Theorem</strong>: Let $A_1,A_2,…,A_n$ be the partition of the sample space $S$, for any event $B$ such that $P(B) &gt; 0$, we have :</p><script type="math/tex; mode=display">P(A_i|B) = \frac{P(A_i)P(B|A_i)}{P(A_1)P(B|A_1)+\dotsb+P(A_n)P(B|A_n)}</script><hr><h1 id="Conditional-Probabilitiy"><a href="#Conditional-Probabilitiy" class="headerlink" title="Conditional Probabilitiy"></a>Conditional Probabilitiy</h1><p>Conditional Probability is also the probability, so it inherent the property of probability (suppose the sample space is $S$):</p><ul><li>$P(S|E) = 1$ and $P(\emptyset|E) = 0$</li><li>if events $A_1,…$ are disjoint, then $P(\cup_{j=1}^{\infty}A_j|E) = \sum_{j=1}^{\infty}P(A_j|E)$</li><li>$P(A^c|E) = 1 - P(A|E)$</li><li>Inclusion-Exclusion : $P(A\cup B|E) = P(A|E) + P(B|E) - P(A\cap B|E)$</li></ul><h3 id="Bayes’-Rule-with-Extra-Condition"><a href="#Bayes’-Rule-with-Extra-Condition" class="headerlink" title="Bayes’ Rule with Extra Condition:"></a>Bayes’ Rule with Extra Condition:</h3><p><strong>Theorem</strong>: Provided that $P(A\cap E)&gt;0$ and $P(B\cap E)&gt;0$, we have:</p><script type="math/tex; mode=display">P(A|B,E) = \frac{P(B|A,E)P(A|E)}{P(B|E)}</script><h3 id="LOTP-with-Extra-Condition"><a href="#LOTP-with-Extra-Condition" class="headerlink" title="LOTP with Extra Condition:"></a>LOTP with Extra Condition:</h3><p><strong>Theorem</strong>: Let $A_1,A_2,…,A_n$ be the partition of the sample space $S$, with $P(A_i \cap E) &gt;0$, Then:</p><script type="math/tex; mode=display">P(B|E) = \sum_{i=1}^n P(B|A_i,E)P(A_i|E)</script><h3 id="Approaches-for-P-A-B-C"><a href="#Approaches-for-P-A-B-C" class="headerlink" title="Approaches for $P(A|B,C)$"></a>Approaches for $P(A|B,C)$</h3><ul><li><script type="math/tex; mode=display">P(A|B,C) = \frac{P(A,B,C)}{P(B,C)}</script></li><li><script type="math/tex; mode=display">P(A|B,C) = \frac{P(B|A,C)P(A|C)}{P(B|C)}</script></li><li><script type="math/tex; mode=display">P(A|B,C) = \frac{P(C|A,B)P(A|B)}{P(A|C)}</script></li></ul><hr><h1 id="Independence-of-Events"><a href="#Independence-of-Events" class="headerlink" title="Independence of Events"></a>Independence of Events</h1><h3 id="Independence-of-Two-Events"><a href="#Independence-of-Two-Events" class="headerlink" title="Independence of Two Events"></a>Independence of Two Events</h3><p><strong>Defination</strong>: Events $A$ and $B$ are independent if</p><script type="math/tex; mode=display">P(A\cap B) = P(A) P(B)  \Leftrightarrow P(A|B) = P(A) , P(B|A) = P(B)</script><h3 id="Independence-vs-Disjointness"><a href="#Independence-vs-Disjointness" class="headerlink" title="Independence vs Disjointness"></a>Independence vs Disjointness</h3><ul><li>$A,B$ is disjoint : $P(A\cap B) = 0$</li><li>$A,B$ is independent : $P(A) = 0, P(B) = 0$</li></ul><h3 id="Conditional-Independence"><a href="#Conditional-Independence" class="headerlink" title="Conditional Independence"></a>Conditional Independence</h3><p><strong>Defination</strong>: Events $A$ and $B$ are conditionally independent given E if:</p><script type="math/tex; mode=display">P(A\cap B|E) = P(A|E)P(B|E)</script><script type="math/tex; mode=display">Contitional\ Independence \nRightarrow Independence</script><script type="math/tex; mode=display">Independence \nRightarrow Contitional\ Independence</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;h1 id=&quot;Defination-of-Conditonal-Probability&quot;&gt;&lt;a href=&quot;#Defination-of-Conditonal-Probability&quot; class=&quot;headerlink&quot; title=&quot;Defination of C
      
    
    </summary>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Math" scheme="http://yoursite.com/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Robust PCA</title>
    <link href="http://yoursite.com/2018/07/04/Robust-PCA/"/>
    <id>http://yoursite.com/2018/07/04/Robust-PCA/</id>
    <published>2018-07-04T14:47:11.000Z</published>
    <updated>2018-07-25T11:29:24.589Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="Introduction-to-RPCA"><a href="#Introduction-to-RPCA" class="headerlink" title="Introduction to RPCA"></a>Introduction to RPCA</h1><p><br><br>The data we collect usually have the low rank property, but the property will vanished when the data is collected causing the noisy, but we can still decomposite the matrix into low-rank matrix and spares error matrix from the corruped data.</p><script type="math/tex; mode=display">  D=\underbrace{A}_{\text{low rank matrix}}+\underbrace{E}_{\text{sparse matrix}} \notag</script><p>Traditional approach for solving this problem is using PCA (Principal Components Analysis), there are many interpretation to PCA, one relate to rank is despiting the low value singular value as this componets contribute less to the data. Thus, it can be considered as the noisy. So we take the $k^{th}$ largest singular value and drop the rest , this can be represnt as the following formulation :</p><script type="math/tex; mode=display">  \mathop{min}_{A,E} \|E \|_F, \ \ \ \  \text{subject to } \ rank(A)\leq r, D = A + E \notag</script><p>PCA has a shortage that it is not robust to the outliers,  then the RPCA (Robust Principal Components Analysis) came out, RPCA could making the matrix recovery whether the noisy is large or not only if the sparse property is confirmed, the original form of the RPCA can be written as :</p><script type="math/tex; mode=display">  \mathop{min}_{A,E} rank(A) + \|E\|_0, \ \ \ \  \text{subject to } \ D = A + E \notag</script><p>The optimization formulation above is non-convex and is hard to get the solution, we can use the convex relax technology apply on it, then it turn out into the most used and the most efficient from:</p><script type="math/tex; mode=display">  \mathop{min}_{A,E} \|A\|_* + \|E\|_1, \ \ \ \  \text{subject to } \ D = A + E \notag</script><p>$| \cdot |_*$ is the unclear norm, which is the sum of the all singular values : $\sum_i^n\sigma_i$, $l_1$ norm of matrix $| \cdot |_1$ is the sum of absolute value of all the element : $\sum_i^n \sum_j^n |D_{ij}|$ .</p><hr><h1 id="Algorithm-of-RPCA"><a href="#Algorithm-of-RPCA" class="headerlink" title="Algorithm of RPCA"></a>Algorithm of RPCA</h1><p><br><br>Before introducting the Algorithm, we first introducing the two operators</p><h2 id="Singular-Value-Thresholding"><a href="#Singular-Value-Thresholding" class="headerlink" title="Singular Value Thresholding"></a>Singular Value Thresholding</h2><p>The optimal solution to the optimization problem : $\frac{1}{2} | X- Y |_F^2 + \tau |X|_*$ with the variable $X$ is thresholing the singular value of $X$</p><script type="math/tex; mode=display">\begin{align}  \mathcal{D}_{\tau}(X) :=  U \mathcal{D}_{\tau} (\Sigma) V^{\prime} ,  \ \ \mathcal{D}_{\tau}(\Sigma) = diag (  \{  \sigma_i - \tau  \}  )  \notag \\  \mathcal{D}_{\tau}(Y) = \mathop{arg} \mathop{min}_{X} \left \{    \frac{1}{2} \| X- Y \|_F^2 + \tau \|X\|_*  \right \} \notag\end{align}</script><h2 id="Soft-Thresholding"><a href="#Soft-Thresholding" class="headerlink" title="Soft Thresholding"></a>Soft Thresholding</h2><p>As same as the $l_1$ norm in vector, thresholding the absolute value of all the element in $X$.</p><script type="math/tex; mode=display">\begin{align}  \psi_{st}(Y) =  \mathop{arg} \mathop{min}_{X} \left \{    \frac{1}{2} \| X- Y \|_F^2 + \tau \|X\|_1  \right \} \notag\end{align}</script><p>There are various methods to solving the RPCA problem, the most successful one is slove the Augmented Lagrangian function of the original problem which we called ALM algorithm, the Augmented Lagrangian function is:</p><script type="math/tex; mode=display">\begin{align}  L(A,E,Y,\mu) = \|A\|_* + \lambda\|E\|_1+ \langle Y,D-A-E \rangle + \frac{\mu}{2} \| D- A -E \|_F^2 \notag\end{align}</script><p>Usually, we use ADMM to slove the ALM problems :</p><script type="math/tex; mode=display">\begin{align}  A_{k+1} &= SVT_{1/\mu_k}(D-E_k + \mu_k^{-1} Y_k) \notag \\  E_{k+1} &= ST_{\lambda/\mu_k} (D - A_{k+1} + \mu_k^{-1} Y_k) \notag \\  Y_{k+1} &= Y_k + \mu_k ( D - A_{k+1} - E_{k+1} ) \notag\end{align}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;h1 id=&quot;Introduction-to-RPCA&quot;&gt;&lt;a href=&quot;#Introduction-to-RPCA&quot; class=&quot;headerlink&quot; title=&quot;Introduction to RPCA&quot;&gt;&lt;/a&gt;Introduction to RPCA&lt;
      
    
    </summary>
    
    
      <category term="Low-Rank" scheme="http://yoursite.com/tags/Low-Rank/"/>
    
  </entry>
  
</feed>
