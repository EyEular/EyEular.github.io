<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>EyEular</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-11-16T14:26:14.599Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Eulring</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>EM-Algorithm</title>
    <link href="http://yoursite.com/2018/11/16/EM-Algorithm/"/>
    <id>http://yoursite.com/2018/11/16/EM-Algorithm/</id>
    <published>2018-11-16T14:26:14.000Z</published>
    <updated>2018-11-16T14:26:14.599Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Neural machine translation by jointly learning to align and translate</title>
    <link href="http://yoursite.com/2018/11/08/NLP-4/"/>
    <id>http://yoursite.com/2018/11/08/NLP-4/</id>
    <published>2018-11-08T12:33:10.000Z</published>
    <updated>2018-11-08T13:36:19.843Z</updated>
    
    <content type="html"><![CDATA[<h1 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a><strong>seq2seq</strong></h1><p>这篇论文可以看作是 sequence to sequence 论文的升级版，首先我们回顾一下 seq2seq 模型</p><script type="math/tex; mode=display">h_t = f(x_t, h_{t-1})</script><blockquote><p>这里 f 可以是一个 LSTM</p><script type="math/tex; mode=display">c = q(\{ h_1,...,h_{T_x}  \})</script><p>这里 q 的运算可以是取最后一个 hidden state $h_{T_x}$</p></blockquote><p>我们的目标是最大化概率：</p><script type="math/tex; mode=display">p(y) = \prod_{t=1}^T p(y_t|\{ y_1,...,t_{t-1} \}. c)</script><blockquote><p>这里面的 c 对于每一个条件概率都是一样的</p></blockquote><p>在 RNN 中，上面的条件概率可以写成是：</p><script type="math/tex; mode=display">p(y_t|\{ y_1,...,t_{t-1} \}. c) = g(y_{t-1}, s_t, c)</script><blockquote><p>这里面 s 是 RNN 中的 hidden state</p></blockquote><h1 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a><strong>Decoder</strong></h1><p>承接上面的我们先来研究 decoder，把 encoder 放到后面</p><p>在这篇论文中，我嗯的目标函数变成了：</p><script type="math/tex; mode=display">p(y) = \prod_{t=1}^T p(y_t|\{ y_1,...,t_{t-1} \}. c_i)</script><p>条件概率是</p><script type="math/tex; mode=display">p(y_t|\{ y_1,...,t_{t-1} \}. c_i) = g(y_{t-1}, s_t, c_i)</script><p>我们发现这里面的 $c_i$ 对于每一个 RNN 循环都是不同的，$c_i$ 其实是 encoder 每一层的加权</p><script type="math/tex; mode=display">c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j</script><p>权重是通过 softmax 得到的</p><script type="math/tex; mode=display">\alpha_{ij} = \frac{exp(e_{ij})}{\sum_{k=1}^{T_x}exp(e_{ik}) }</script><p>每一层的 encoder 中的 $h_j$ 对于第 i 层的 decoder 的影响可以下面公式来计算</p><script type="math/tex; mode=display">e_{ij} = a(s_{i-1}, h_j)</script><p>论文里面 a 的计算方式为：</p><script type="math/tex; mode=display">a(s_{i-1}, h_j) = v^T_a tanh (W_a s_{i-1} + U_a h_j)</script><h1 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a><strong>Encoder</strong></h1><p>正向做一遍 RNN 得到 $(\overrightarrow{h_1},…,\overrightarrow{h_T} )$</p><p>反向做一遍 RNN 得到 $(\overleftarrow{h_1},…,\overleftarrow{h_T} )$</p><p>最后将两个得到的 hidden state 每个对应的位置拼接起来，就形成了我们想要的结果 ：</p><script type="math/tex; mode=display">h_j =  [\overrightarrow{h_1^T}; \overleftarrow{h_1^T}]^T</script><h1 id="Setting"><a href="#Setting" class="headerlink" title="Setting"></a><strong>Setting</strong></h1><ul><li>使用 SGD 训练，minibatch 是 80 个 sentence</li><li>模型训练完以后，做预测的时候使用 beam search</li></ul><p><img src="/2018/11/08/NLP-4/nlp4img1.jpg" align="justify"></p><p>这是最后将权重可视化以后的结果，高亮区域 (i,j) 表示，输出的 $j^{th}$ 单词的和输入的 $i^{th}$ 单词关系密切</p><h1 id="Rederence"><a href="#Rederence" class="headerlink" title="Rederence"></a><strong>Rederence</strong></h1><p>Bahdanau, D., et al. (2014). “Neural machine translation by jointly learning to align and translate.” arXiv preprint arXiv:1409.0473.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;seq2seq&quot;&gt;&lt;a href=&quot;#seq2seq&quot; class=&quot;headerlink&quot; title=&quot;seq2seq&quot;&gt;&lt;/a&gt;&lt;strong&gt;seq2seq&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;这篇论文可以看作是 sequence to sequence 论文
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Attention is all you need</title>
    <link href="http://yoursite.com/2018/11/01/NLP-3/"/>
    <id>http://yoursite.com/2018/11/01/NLP-3/</id>
    <published>2018-11-01T13:59:13.000Z</published>
    <updated>2018-11-08T12:37:24.529Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Backgrounnd"><a href="#Backgrounnd" class="headerlink" title="Backgrounnd"></a><strong>Backgrounnd</strong></h1><p>传统的处理序列学习的任务，我们通常使用的是 RNN，</p><h1 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a><strong>Structure</strong></h1><h2 id="encoder-decoder-Stacks"><a href="#encoder-decoder-Stacks" class="headerlink" title="encoder-decoder Stacks"></a>encoder-decoder Stacks</h2><p>最常用的序列生成模型用的都是 encoder-decoder 结构，attention 模型也不例外，不过不同于传统的 seq2seq 模型，attention 模型每次都是将所有的输入数据一起做的 encoding。还要指出的是，这里的 attention 模型和 Bahdanau 14 年的论文引用 attention 机制来做 mt 是不一样的，这里，google 将 attention 作为了流的所有的部分，并且抛弃了传统 RNN 一个输入接着一个输入的做法。</p><p>于是，新的 Attention 结构能够进行并行计算了，而且每次运算的复杂度也可以减少，同时维持了精度。</p><p><img src="/2018/11/01/NLP-3/nlp3img1.jpg" width="600px"></p><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><p>Attention 是这篇论文的亮点也是核心所在，从上面的结构我们可以发现，attention 模型的输入是三个，如果这三个都是出自同一个 input 我们称这个 attention 模块为 self-attention</p><p><img src="/2018/11/01/NLP-3/nlp3img2.jpg" align="justify"></p><p><strong>Scaled Dot-product Attention</strong></p><p>结合上面整体的架构和 self-attention 模块，我们来详细的描述一下 Scaled Dot-product 过程的 pipeline：</p><ul><li>总的输入 $X$ 一般是一个 $n \times C$ 的矩阵，这里 n 表示这段话有 n 个词，C 表示这个词的 one-hot vector 的长度（也就是字典的大小）一般所有用神经网络处理文本的输入都是这样的</li><li>对于输入做一个 embedding：$X = XE$ 得到一个 $n \times d_m$ 的向量，这一步，和其他的 RNN 也一样</li><li>用三个不同的需要学习的矩阵 $W^Q(d_m \times d_k), W^K(d_m \times d_k), W^V(d_m \times d_v)$ 再对输入做一个映射，生成三个不同的矩阵 $Q(n\times d_k), K(n\times d_k), V(n\times d_v)$ 到这里也就是上面最左边的图片下面的输入。这三个矩阵 Q K V 其实都是有各自的含义的：<ul><li>Q K 的作用是生成一个 $n \times n$ 的 attention 权重表</li><li>Q 是 query 的缩写，表示我们的询问期望的是哪些词向量</li><li>V 相当于是最原始输入的句子的每个词向量的表达</li></ul></li><li>有了输入，我们可以直接得到 self-attention 模块的计算公式：<script type="math/tex; mode=display">Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{d_k}})V</script><ul><li>当 Q 与 K 做矩阵运算后，底下除了一个系数，这个算是一个归一化的 trick 吧，也是名称 Scaled 的由来</li><li>最后 softmax(.) 的结果就是 $n \times n$ 的 attention 权重表</li></ul></li></ul><p><img src="/2018/11/01/NLP-3/nlp3img4.jpg" align="justify"></p><p>最后借用别人的一张图来概括整个过程</p><p><strong>Multi-Head Attention</strong></p><p>上面介绍的 Scaled Dot-product 是为了引出 Multi-Head Attention 的，Multi-Head Attention 相当于做了 $h$ 次不同的 Scaled Dot-product Attention，然后把这 h 个矩阵拼起来，再做最后一次线性变换</p><p><img src="/2018/11/01/NLP-3/nlp3img6.jpg" align="justify"></p><p>公式为：</p><script type="math/tex; mode=display">\begin{align}  MultiHead(Q, K, V) &= Concat(head_1,...,head_h) W^O \notag \\  head_i &= Attention(XW_i^Q, XW_i^K, XW_i^V) \notag\end{align}</script><blockquote><p>$W_i^Q \in R^{d_m \times d_k}, W_i^K \in R^{d_m \times d_k}, W_i^K \in V^{d_m \times d_v}$</p></blockquote><p>为什么要多次投影呢，从下面一张图可以看到，single attention 只能够 focus 句子的某一部分，而 multi-head attention 的不同 head 能 focus 不同的句子的部分，图中是指 “it” 应该和哪些部分相关</p><p><img src="/2018/11/01/NLP-3/nlp3img5.jpg" align="justify"></p><h2 id="Position-Encoding"><a href="#Position-Encoding" class="headerlink" title="Position Encoding"></a>Position Encoding</h2><p>由于每次，我们直接把所有的词向量全部放入了模型中进行训练，所以这样就丢失了时间上的信息，也就是词与词之间的先后顺序的关联，为了解决这个问题，我们直接在输入上面做一些手脚。比如在最上面的那张 attention 结构图中，像太极一样的符号就是 positional Encoding，具体的公式是：</p><script type="math/tex; mode=display">\begin{align}  PE_{pos, 2i} &= sin(pos / 10000^{2i/d_m}) \notag \\  PE_{pos, 2i+1} &= cos(pos / 10000^{2i/d_m})\end{align}</script><blockquote><p>上面的公式可以生成一个新的 $n\times d_m$ 大小的矩阵（和 input 的大小一样）&lt;/br&gt;<br>生成的矩阵直接和输入做一个叠加 &lt;/br&gt;<br>pos 的取值范围是 $(0, n)$ 表示&lt;/br&gt;<br>i 的取值范围是 $(0, d_m)$</p></blockquote><p><img src="/2018/11/01/NLP-3/nlp3img3.jpg" align="justify"></p><p>上面的图就是生成的 position encoding 的具体的样子，可以发现层于层之间的 encoding 会比较接近，同时如果某两层差序列上的距离差的比较远的话，他们的向量的表示也会比较远，且差距和序列差距呈正相关？最后这些结果会反应在矩阵的投影上</p><h1 id="Trainging"><a href="#Trainging" class="headerlink" title="Trainging"></a><strong>Trainging</strong></h1><p><img src="/2018/11/01/NLP-3/nlp3img7.jpg" align="justify"></p><p><img src="/2018/11/01/NLP-3/nlp3img8.jpg" align="justify"></p><p><img src="/2018/11/01/NLP-3/nlp3img9.jpg" align="justify"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><strong>Reference</strong></h1><p><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">https://jalammar.github.io/illustrated-transformer/</a></p><p><a href="https://qianqianqiao.github.io/2018/10/23/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-is-All-You-Need/" target="_blank" rel="noopener">https://qianqianqiao.github.io/2018/10/23/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Attention-is-All-You-Need/</a></p><p>Vaswani, A., et al. (2017). Attention is all you need. Advances in Neural Information Processing Systems.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Backgrounnd&quot;&gt;&lt;a href=&quot;#Backgrounnd&quot; class=&quot;headerlink&quot; title=&quot;Backgrounnd&quot;&gt;&lt;/a&gt;&lt;strong&gt;Backgrounnd&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;传统的处理序列学习的任务，我们通常
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>GPU-service-config</title>
    <link href="http://yoursite.com/2018/10/15/GPU-service-config/"/>
    <id>http://yoursite.com/2018/10/15/GPU-service-config/</id>
    <published>2018-10-15T10:24:51.000Z</published>
    <updated>2018-10-15T11:19:54.237Z</updated>
    
    <content type="html"><![CDATA[<p>显卡 4 * 1080TI</p><p>下载 runfile 的 cuda 版本，deb 安装对于网络要求比较高，所以暂时忽略</p><p><img src="/2018/10/15/GPU-service-config/gpuimg1.jpg" align="justify"></p><p>cuda已经更新到了 10.0，但是可以在下面这个网站选取之前版本的 cuda。<br><a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a></p><p>然后直接安装 cuda（cuda 里有自带显卡的驱动的）</p><h3 id="nouveau-禁用"><a href="#nouveau-禁用" class="headerlink" title="nouveau 禁用"></a>nouveau 禁用</h3><p>首先我们要禁用 nouveau，下面这条指令可以查看主机中是否有 nouveau 开启<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep nouveau</span><br></pre></td></tr></table></figure></p><p>如果没有输出的话，说明没有开启，有的话，我们要对这个服务进行禁用，于是我们要编辑文件<br><code>/etc/modprobe.d/blacklist-nouveau.conf</code>  这里用的编辑方式是 gedit，如果没有安装的话要先下一个，否则只能用 vim</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/modprobe.d/blacklist-nouveau.conf</span><br></pre></td></tr></table></figure><p>在这个文件后面添加下面两行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset=0</span><br></pre></td></tr></table></figure><p>然后对于 kernel 进行一个更新，使上面的修改生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure><h3 id="cuda-安装"><a href="#cuda-安装" class="headerlink" title="cuda 安装"></a>cuda 安装</h3><p>上面的步骤完成以后，<code>reboot</code> 重启电脑，进入选择用户界面以后直接按 <code>alt</code> + <code>ctrl</code> + <code>f1</code>   进入字符终端界面，在这个界面中，先输入用户名，然后输入密码。然后先禁用所有显卡提供的服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm stop</span><br></pre></td></tr></table></figure></p><p>然后 cd 到 <code>.run</code> 文件目录下直接安装 cuda 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sh cuda_xxxxx_xxxx.run</span><br></pre></td></tr></table></figure><p>然后按照安装的提示来，如果有除了 nvidia 以外的显卡的话，安装的时候提醒你安装 openGL 的时候要选择 no，安装完成以后，如果，都显示的是 <code>installed</code> 而不是 <code>failed</code> 的话，就说明成功了，这个时候可以把显卡的服务打开了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm start</span><br></pre></td></tr></table></figure></p><p>接着重新启动电脑，可以通过<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure></p><p>来查看显卡的信息了，有信息说明显卡安装成功</p><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><p><a href="https://docs.nvidia.com/cuda/archive/9.0/cuda-installation-guide-linux/index.html#runfile-nouveau-ubuntu" target="_blank" rel="noopener">https://docs.nvidia.com/cuda/archive/9.0/cuda-installation-guide-linux/index.html#runfile-nouveau-ubuntu</a></p><p><a href="https://blog.csdn.net/qlulibin/article/details/78714596" target="_blank" rel="noopener">https://blog.csdn.net/qlulibin/article/details/78714596</a></p><p>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;显卡 4 * 1080TI&lt;/p&gt;
&lt;p&gt;下载 runfile 的 cuda 版本，deb 安装对于网络要求比较高，所以暂时忽略&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2018/10/15/GPU-service-config/gpuimg1.jpg&quot; align=&quot;just
      
    
    </summary>
    
    
      <category term="DL" scheme="http://yoursite.com/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>IC-paper-1</title>
    <link href="http://yoursite.com/2018/10/15/IC-paper-1/"/>
    <id>http://yoursite.com/2018/10/15/IC-paper-1/</id>
    <published>2018-10-15T09:00:33.000Z</published>
    <updated>2018-10-27T14:26:13.290Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Show-Attend-and-Tell"><a href="#Show-Attend-and-Tell" class="headerlink" title="Show Attend and Tell"></a>Show Attend and Tell</h1><h3 id="编码-Encoder"><a href="#编码-Encoder" class="headerlink" title="编码 Encoder"></a>编码 Encoder</h3><p>输入是一张图片，输出是 caption，其中 caption 是长度为 C 的 K 维词向量</p><script type="math/tex; mode=display">y = \{ \mathbf{y}_1,...,\mathbf{y}_C \}, \mathbf{y}_i \in R^K</script><p>对于一张图片我们使用卷积神经网络来提取特征，总共提取 L 个特征向量，每一个都是 D 维的，对应这图像中的一部分</p><script type="math/tex; mode=display">a = \{ \mathbf{a}_1,...,\mathbf{a}_L \}, \mathbf{a}_i \in R^D</script><p>从低层的卷积层提取特征</p><h3 id="解码-Decoder"><a href="#解码-Decoder" class="headerlink" title="解码 Decoder"></a>解码 Decoder</h3><p><img src="/2018/10/15/IC-paper-1/icpimg1.jpg" width="400px"></p><p>使用 LSTM 解码</p><p>进行解码的 $\hat{z}_t$ 是通过一个机制 $\phi$ 来计算 $\mathbf{a}_i,(i&lt;L)$ 得出的，每一个 i 对应着图片的不同的区域，对于每个u 区域 $\phi$ 生成一个整数权重 $\alpha_i$，代表用这个区域来聚焦能生成正确的下一个单词的概率。</p><p>RNN 每一次的迭代的值的变化和传递如下所示</p><p>首先对于每个区域我们生成它的价值：</p><script type="math/tex; mode=display">e_{ti} = f_{att} (a_i,h_{t-1})</script><blockquote><p>这里面 t 是 RNN 中的第 t 次迭代，i 表示区域</p></blockquote><p>然后就是生成概率了</p><script type="math/tex; mode=display">\alpha_{ti} = \frac{\exp{(e_{ti})}}{\sum_{k=1}^L \exp{(e_{tk})}}</script><p>最后生成 context 向量 $\hat{z}_t$：</p><script type="math/tex; mode=display">\hat{z}_t = \phi(\{ a_i \}, \{\alpha_i\})</script><p>最初的 $h_0$ 和 $c_0$ 是通过区域特征的均值来取得的</p><script type="math/tex; mode=display">c_0 = f_{init} \left( \frac{1}{L} \sum_i^L a_i \right),h_0 = f_{init} \left( \frac{1}{L} \sum_i^L a_i \right)</script><h3 id="Hard-Attention"><a href="#Hard-Attention" class="headerlink" title="Hard Attention"></a>Hard Attention</h3><p>首先定义一个 one-hot 向量，$s_{t,i}$ 这个向量的第 i 个元素为 1 ，说明，我们对于区域 i 进行了特征的提取，那么这个 one-hot 向量就是由 $\alpha$ 定义的多维分布：</p><script type="math/tex; mode=display">p(s_{t,i} = 1 | s_{j<t},a) = \alpha_{t,i}</script><p>然后 context 向量的生成方式就变成了：</p><script type="math/tex; mode=display">\hat{z}_t =\sum_i s_{t,i}a_i</script><p>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Show-Attend-and-Tell&quot;&gt;&lt;a href=&quot;#Show-Attend-and-Tell&quot; class=&quot;headerlink&quot; title=&quot;Show Attend and Tell&quot;&gt;&lt;/a&gt;Show Attend and Tell&lt;/h1&gt;&lt;
      
    
    </summary>
    
    
      <category term="nlp" scheme="http://yoursite.com/tags/nlp/"/>
    
  </entry>
  
  <entry>
    <title>Image-Caption-2</title>
    <link href="http://yoursite.com/2018/10/10/Image-Caption-2/"/>
    <id>http://yoursite.com/2018/10/10/Image-Caption-2/</id>
    <published>2018-10-10T08:19:00.000Z</published>
    <updated>2018-10-10T08:25:52.914Z</updated>
    
    <content type="html"><![CDATA[<p>Image Caption：给定一张图片，生成和图片的文字描述</p><p>Image Retrieval：给定一个句子和一个图片的数据库，找到和句子最相关的那张图片</p><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Image Caption：给定一张图片，生成和图片的文字描述&lt;/p&gt;
&lt;p&gt;Image Retrieval：给定一个句子和一个图片的数据库，找到和句子最相关的那张图片&lt;/p&gt;
&lt;p&gt;.&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Image-Caption-1</title>
    <link href="http://yoursite.com/2018/10/06/Image-Caption-1/"/>
    <id>http://yoursite.com/2018/10/06/Image-Caption-1/</id>
    <published>2018-10-06T11:32:49.000Z</published>
    <updated>2018-10-08T06:18:52.160Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h1><p>DataSet 分为 Single image generation 的</p><h3 id="Image-Caption"><a href="#Image-Caption" class="headerlink" title="Image Caption"></a>Image Caption</h3><div class="table-container"><table><thead><tr><th style="text-align:left">DataSet</th><th style="text-align:center">Scale</th><th style="text-align:center">categories</th><th style="text-align:center">generations</th></tr></thead><tbody><tr><td style="text-align:left">UIUC Pascal Sentence</td><td style="text-align:center">1000</td><td style="text-align:center">20</td><td style="text-align:center">5</td></tr><tr><td style="text-align:left">Flickr 8k</td><td style="text-align:center">8000</td><td style="text-align:center">-</td><td style="text-align:center">5</td></tr><tr><td style="text-align:left">Flickr 30k</td><td style="text-align:center">8000</td><td style="text-align:center">-</td><td style="text-align:center">5</td></tr><tr><td style="text-align:left">Microsoft CoCo</td><td style="text-align:center">120000</td><td style="text-align:center">91</td><td style="text-align:center">-</td></tr><tr><td style="text-align:left">Abstract Scence Dataset</td><td style="text-align:center">10000</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr><tr><td style="text-align:left">Visual Genome Dataset</td><td style="text-align:center">-</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr><tr><td style="text-align:left">Krause</td><td style="text-align:center">-</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr><tr><td style="text-align:left">Kong</td><td style="text-align:center">-</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr></tbody></table></div><h3 id="Video-Caption"><a href="#Video-Caption" class="headerlink" title="Video Caption"></a>Video Caption</h3><div class="table-container"><table><thead><tr><th style="text-align:left">DataSet</th><th style="text-align:center">Scale</th></tr></thead><tbody><tr><td style="text-align:left">TACoS</td><td style="text-align:center">127</td></tr><tr><td style="text-align:left">YouCook</td><td style="text-align:center">88</td></tr><tr><td style="text-align:left">LSMDC</td><td style="text-align:center">200</td></tr></tbody></table></div><h3 id="Referring-Expression"><a href="#Referring-Expression" class="headerlink" title="Referring Expression"></a>Referring Expression</h3><p>只介绍了两篇论文：</p><p>Modeling Context in Referring Expressions</p><p>Generation and Comprehension of Unambiguous Object Descriptions</p><h1 id="Measure"><a href="#Measure" class="headerlink" title="Measure"></a>Measure</h1><p>首先回忆一下准确率和召回率</p><script type="math/tex; mode=display">P = \frac{TP}{TP+FP}</script><script type="math/tex; mode=display">R = \frac{TP}{TP+FN}</script><p>其中，P/N 是自己的判断，T/F 是真实的对于判断的衡量</p><h3 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h3><p><strong>n-gram based precision</strong></p><p>首先 BLEU 是基于 n-gram 匹配的，也就是对于一个长为 N 的句子，有 $(N-n+1)$ 个 n-gram 组合，提取出这个句子的某个 n-gram 组合，然后计算这个 n-gram 的 precision，一个直观的方法就是计算 n-gram 在目标中也就是 groundtruth（NLP 里面我们称为 reference）是否有出现，然后统计所有的 n-gram 组合。</p><p>这个方法其实是有 bug 的。。。我们先来看一个 unigram（也就是 1-gram）的例子：</p><blockquote><p>Candidate（预测结果）：the the the the the the the.<br><br>Reference 1: The cat is on the mat.<br><br>Reference 2: There is a cat on the mat.</p></blockquote><p>用最简单的方法，7 个 1-gram 都出现在了任意一个 reference 中，于是正确率是 $100\%$，但是，这是明显不合理的。。所以我们要把 n-gram 在 Candidate 中的出现次数也考虑进去，并当作分母。同时，取 1-gram 在所有 reference 中出现的最多的次数 $max(1,2) = 2$，之后 reference 中的统计和 candidate 中的统计取一个最小值作为分子 $min(2,7) = 2$，于是最后的正确率就是 $\frac{2}{7}$。</p><p>下面给出，总的正确率公式，这个方法论文里面给出的公式真的不忍直视。。。。于是找了一种比较好的公式写法</p><script type="math/tex; mode=display">BLEU_n(a,b) = \frac{\sum_{w_n \in a} min \left(  c_a(w_n), \mathop{max}_{j=1,...,|b| c_{b_j}(w_n)}  \right)}{\sum_{w_n \in a} c_a(w_n)}</script><blockquote><p>a：candidate sentence<br><br>b：所有的 reference sentence<br><br>$w_n$：某个 n-gram 组合<br><br>$c_x(y_n)$：在句子 x 中统计 n-gram $y_n$ 出现的次数<br><br>$BLEU_n$ 下面的 n 和 n-gram 中的 n 对应<br><br>BLEU 是 $BLEU_1$ 到 $BLEU_4$ 平均数</p></blockquote><p>单单上面的公式还有是问题的，对于某个 candidate：</p><blockquote><p>Candidate（预测结果）：The cat is on the</p></blockquote><p>这个句子明显是不完整的，但是依然可以计算出是满分。。所以我们要对于短的句子做一个惩罚</p><script type="math/tex; mode=display">BP = \left \{  \begin{array}{lL}    1 & if\ l_c> l_r \\   e^{1-l_r/l_c }& if\ l_c \leq l_r  \end{array}\right .</script><blockquote><p>$l_c$：是 candidate 的长度<br><br>$l_r$：是 reference 中最短句子的长度</p></blockquote><p>我们再对不同的 n-gram 加上一个权值，就是最终的评判公式了：</p><script type="math/tex; mode=display">BLEU = BP \cdot exp \left(  \sum_{n=1}^N w_n \cdot log\ BLEU_n  \right)</script><p><strong>缺点</strong></p><ul><li>对于 n-gram 的出现顺序没有约束</li><li>每一个 n-gram 都被相同对待，没有主次之分</li></ul><h3 id="Rouge"><a href="#Rouge" class="headerlink" title="Rouge"></a>Rouge</h3><p><strong>n-gram based Recall</strong></p><script type="math/tex; mode=display">ROUGE_n(a,b) = \frac{\sum_{j=1}^{|b|} \sum_{w_n \in b_j}  min\left(  c_a(w_n),c_{b_j}(w_n) \right)}{\sum_{j=1}^{|b|} \sum_{w_n \in b_j} c_{b_j}(w_n)}</script><blockquote><p>分母是对于 reference 中所有的 n-gram 的统计<br><br>分子是 candidate 中的 n-gram 与 reference 中的匹配</p></blockquote><h5 id="Rouge-L"><a href="#Rouge-L" class="headerlink" title="Rouge-L"></a>Rouge-L</h5><p>L 即是 LCS(longest common subsequence，最长公共子序列) 的首字母</p><script type="math/tex; mode=display">\begin{align}R_{lcs} &= \frac{LCS(X,Y)}{m} \notag \\P_{lcs} &= \frac{LCS(X,Y)}{n} \notag \\F_{lcs} &= \frac{(1+\beta^2)R_{lcs}P_{lcs}}{R_{lcs}+ \beta^2 P_{lcs}} \notag\end{align}</script><h3 id="METEOR"><a href="#METEOR" class="headerlink" title="METEOR"></a>METEOR</h3><p>Meteor也是来评测机器翻译的，对模型给出的译文与参考译文进行词对齐，计算词汇完全匹配、词干匹配和同义词匹配等各种情况的准确率、召回率和F值。</p><script type="math/tex; mode=display">Metor = (1-Penalty)\cdot F</script><p>首先计算 unigram 情况下的准确率 P 和召回率 R（计算方式与BLEU、ROUGE类似），得到调和均值（F值）</p><script type="math/tex; mode=display">F = \frac{10PR}{R+9P}</script><p>Meteor的特别之处在于，它不希望生成很“碎”的译文：比如参考译文是“A B C D”，模型给出的译文是“B A D C”，虽然每个 unigram 都对应上了，但是会受到很严重的惩罚。惩罚因子的计算方式为</p><script type="math/tex; mode=display">Penalty = \frac{1}{2} \left(  \frac{\# chunks}{\# matched\ unigrams}  \right)^3</script><p>式中的 $#chunks$ 表示匹配上的语块个数，如果模型生成的译文很碎的话，语块个数会非常多；$#unigrams matched$ 表示匹配上的 unigram 个数。所以最终的总的评分公式为：</p><script type="math/tex; mode=display">Meteor = \mathop{max}_{j=1,...,|b|} \left(  \frac{10PR}{R+9P}  \right)   \left(  1-\frac{1}{2} \left( \frac{\# chunks}{\# matched\ unigrams} \right)^3  \right)</script><h3 id="CIDEr"><a href="#CIDEr" class="headerlink" title="CIDEr"></a>CIDEr</h3><p>这个指标将每个句子都看作“文档”，将其表示成 tf-idf 向量的形式，然后计算参考caption与模型生成的caption的余弦相似度</p><script type="math/tex; mode=display">CIDEr_n(a,b) = \frac{1}{|b|}\sum_{j=1}^{|b|} \frac{g^n(a)\cdot g^n(b_j)}{||g^n(a)|| \cdot ||g^n(b_j)||}</script><blockquote><p>在这里，$g^n(x)$ 是句子 x 的所有 n-gram 的 TF-IDF scores 的向量化</p></blockquote><p>最后的总的分数可以写成：</p><script type="math/tex; mode=display">CIDEr(a,b) = \sum_{n=1}^N w_n CIDEr_n(a,b)</script><h3 id="SPICE"><a href="#SPICE" class="headerlink" title="SPICE"></a>SPICE</h3><p>上面讲到的这些衡量方式多数用于机器翻译的，而且依旧存在不足的地方，下图用传统的方式衡量，首先看左边的，其实是描述两张不同的图片，但是他们的描述用传统的方式相似度很大，结果是 FP，又比如右图，我们看到两个描述都是合理的，但是，由于相似度比较低，所以就没有判成正例。。</p><p><img src="/2018/10/06/Image-Caption-1/IC1img1.jpg" align="justify"></p><p>。。。。未完待续</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.cnblogs.com/Determined22/p/6910277.html" target="_blank" rel="noopener">https://www.cnblogs.com/Determined22/p/6910277.html</a></p><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;DataSet&quot;&gt;&lt;a href=&quot;#DataSet&quot; class=&quot;headerlink&quot; title=&quot;DataSet&quot;&gt;&lt;/a&gt;DataSet&lt;/h1&gt;&lt;p&gt;DataSet 分为 Single image generation 的&lt;/p&gt;
&lt;h3 id=&quot;I
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>RL2-MDP</title>
    <link href="http://yoursite.com/2018/10/06/RL-2/"/>
    <id>http://yoursite.com/2018/10/06/RL-2/</id>
    <published>2018-10-06T08:01:06.000Z</published>
    <updated>2018-10-06T14:28:41.904Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Markov-Process"><a href="#Markov-Process" class="headerlink" title="Markov Process"></a>Markov Process</h1><p>在 markov 决策过程中，环境是完全观测到的</p><p>基本上大多数的 RL 问题都是 MDP 的形式</p><p><strong>Definition</strong>: markov process 是 $\langle S,P \rangle$</p><ul><li>S 是一个有限的状态集合</li><li>P 是状态转移矩阵</li></ul><h3 id="Markov-Property"><a href="#Markov-Property" class="headerlink" title="Markov Property"></a>Markov Property</h3><p><strong>_”The Future is independent of the past given the present”_</strong></p><script type="math/tex; mode=display">P[S_{t+1}|S_t] = P[S_{t+1}|S_1,...,S_t]</script><h3 id="Markov-Chain"><a href="#Markov-Chain" class="headerlink" title="Markov Chain"></a>Markov Chain</h3><p><strong>State Transition Matrix</strong></p><script type="math/tex; mode=display">P_{ss^{\prime}} = P[S_{t+1} = s^{\prime} | S_t = s]</script><script type="math/tex; mode=display">P = \left [  \begin{array}{ccc}    P_{11} &\dots& P_{1n} \\    \vdots & & \vdots \\    P_{n1} & \cdots & P_{nn}  \end{array}\right ]</script><blockquote><p>矩阵的每一行的和是 1</p></blockquote><p><img src="/2018/10/06/RL-2/rl2img1.jpg" align="justify"></p><h1 id="Markov-Reward-Process"><a href="#Markov-Reward-Process" class="headerlink" title="Markov Reward Process"></a>Markov Reward Process</h1><p>Markov Reward Process is a Markov chain with values</p><p><strong>Definition</strong>: Markov Reward Process 是一个 $\langle S,P,R,\gamma \rangle$</p><ul><li>S 是一个有限的集合</li><li>P 是状态转移矩阵</li><li>R 是反馈方程 $R_s = E[R_{t+1} | S_t=s]$</li><li>$\gamma$ 是衰减因子</li></ul><h1 id="Markov-Decision-Process"><a href="#Markov-Decision-Process" class="headerlink" title="Markov Decision Process"></a>Markov Decision Process</h1><h1 id="Extensions"><a href="#Extensions" class="headerlink" title="Extensions"></a>Extensions</h1><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Markov-Process&quot;&gt;&lt;a href=&quot;#Markov-Process&quot; class=&quot;headerlink&quot; title=&quot;Markov Process&quot;&gt;&lt;/a&gt;Markov Process&lt;/h1&gt;&lt;p&gt;在 markov 决策过程中，环境是完全观测
      
    
    </summary>
    
    
      <category term="RL" scheme="http://yoursite.com/tags/RL/"/>
    
  </entry>
  
  <entry>
    <title>R-CNN</title>
    <link href="http://yoursite.com/2018/10/05/RCNN/"/>
    <id>http://yoursite.com/2018/10/05/RCNN/</id>
    <published>2018-10-05T02:21:58.000Z</published>
    <updated>2018-10-12T04:48:24.715Z</updated>
    
    <content type="html"><![CDATA[<h1 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h1><p>R-CNN 流程</p><ul><li>对输入图片使用 select search 选择 2000 个区域<ul><li>select search 有区域合并的操作</li></ul></li><li>拉伸缩放图片到固定尺寸（227 * 227）传入 CNN 生成 4096 维的特征向量</li><li>对于特征用 SVM 预测每个类别（C+1，1是背景），通过 IoU 来打分</li><li>预测最大的判别为一类</li><li>最后对这些区域根据极大值抑制来合并和省略</li></ul><p><img src="/2018/10/05/RCNN/rcnnimg2.jpg" align="justify"></p><p>对于每一个类，都训练一个 SVM 分类器，优化的核心是建立一个 loss 方程，对于 SVM 的 loss function 我们要有 predict 的正负样本，以及 groundtruth 的正负样本</p><ul><li>predict：对于每一个区域的对应的类 SVM 直接返回 0/1（负样本或者正样本）</li><li>groundtruth：把所有的框和真实手工标注的框做一个 IoU 的计算，然后根据 IoU 的阈值来生成 data 的负样本与正样本，然后还要进行一次极大值抑制，尽管有些框的 IoU 大于阈值了，但是依旧判为负样本，因为它周围已经有比他更大的了。。</li></ul><p>我们还可以对位置进行一个修正（用修正后的位置来计算 IoU）：输入为深度网络pool5层的4096维特征，输出为 xy 方向的缩放和平移。 训练样本判定为本类的候选框中，和真值重叠面积大于 0.6 的候选框，loss 为真实框和预测框的二范数。这个预测应该是在一次识别操作之后进行的。。</p><p><img src="/2018/10/05/RCNN/rcnnimg1.jpg" align="justify"></p><hr><h1 id="SPPnet"><a href="#SPPnet" class="headerlink" title="SPPnet"></a>SPPnet</h1><p><img src="/2018/10/05/RCNN/rcnnimg3.jpg" align="justify"></p><p>R-CNN 对于每一个 region 图片都进行了卷积，这样效率很低，一个直观的 idea 就是直接做一次卷积生成一个 feature map，然后在这个 feature map 中找到对应的 region，但是这样有一个问题，就是最后我们的全连接层是固定尺寸的，在 R-CNN 中，我们通过 warp 区域来使输入一致，在 SPPnet 中，我们在 feature map 上面，是否也可以 warp 呢 ？答案是不可以的。。。因为在图像进行 warp，伸展以后图像的意义仍然保留了，但是特征图 warp 以后，不经过修正，就失去意义了。。。所以我们要对 feature 重新提取特征。</p><p><img src="/2018/10/05/RCNN/rcnnimg4.jpg" width="500px"></p><p>SPP 全名是 Spatial Pyramid Pooling，借用了图像金字塔的概念，如上图所示，我们将图像分成 $4\times 4$<br>, $2\times 2$, $1\times 1$ 的区域，然后做这些区域的 max-pooling，假设经过卷积我们得到的 feature map 是 $n\times m\times 256$ 的，经过 SPP 以后，就变成了 $21\times 256$ 的了</p><p>SPP 还有要解决的点就是根据 region 在图像中的位置找到，对应在 feature map 中的位置。。<br>计算公式是这样的：$(x, y) = (Sx^{\prime}, Sy^{\prime})$，其中 S 是所有步长的乘积，实际中的公式为：</p><script type="math/tex; mode=display">x^{\prime} = \lfloor x/S \rfloor + 1</script><p><img src="/2018/10/05/RCNN/rcnnimg5.jpg" align="justify"></p><p>论文中用到的 ZF-5 模型，它的 S 就是 $2^4$ 也就是里面的四个 str 2</p><hr><h1 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h1><p>R-CNN 缓慢的原因是因为，对于每一张图片都进行来深度网络的卷积<br>SPPnet 解决 R-CNN 的这个问题，但是 SPPnet 还是有缺陷的，就是和 R-CNN 一样仍然是 multi-stage 的框架</p><p>Fast R-CNN 的优点是：</p><ul><li>更高的探测精度</li><li>在一个 stage 上通过不同任务的 loss 完成训练</li><li>训练可以更新网络的每一层</li><li>feature 的存储不需要放在硬盘上</li></ul><p><img src="/2018/10/05/RCNN/rcnnimg7.jpg" align="justify"></p><p>在 fast R-CNN 中，每一个要训练 ROI 都有一个真实的类别 u（u=0 表示是背景） 和真实的目标区域 v<br>于是 loss function 可以表示为两个 loss 之和：</p><script type="math/tex; mode=display">L(p,u,t^u,v) = L_{cls}(p,u) + \lambda[u\geq 1]L_{loc}(t^u,v)</script><blockquote><ul><li>p 是 softmax 得出的预测结果</li><li>$u\geq 1$ 说明背景的 loss 不计入考虑范围</li></ul></blockquote><h3 id="faster-FC-by-SVD"><a href="#faster-FC-by-SVD" class="headerlink" title="faster FC by SVD"></a>faster FC by SVD</h3><p>位置修正和分类都是全连接层，一次前向传播可以由线性变换表示 $y=Wx$ 复杂度为 $u\times v \times v$</p><p>现在我们对这个变换矩阵做一个奇异值分解，取前 t 大的 特征值保留下来复杂度变为 $(u\times t + t\times v) \times v$</p><p><img src="/2018/10/05/RCNN/rcnnimg6.jpg" width="300px"></p><p>训练的过程中应该不会用 SVD 分解。。</p><h3 id="ROI-Pooling-BP"><a href="#ROI-Pooling-BP" class="headerlink" title="ROI Pooling BP"></a>ROI Pooling BP</h3><p>这是这个文章的计算细节中的难点，我还没完全理解。。以后用到再说。。</p><hr><h1 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h1><p>Faster R-CNN 将特征抽取(feature extraction)，proposal提取，bounding box regression(rect refine)，classification都整合在了一个网络中，faster R-CNN 的整体结构如下所示：</p><p><img src="/2018/10/05/RCNN/rcnnimg9.jpg" align="justify"></p><p><strong>Bounding Box 回归系数</strong></p><p>原始的边框表示为左上角点和长宽 $(O_x,O_y,O_w,O_h)$，目标边框表示为 $(T_x,T_y,T_w,T_h)$，regression 可以看作是一个框与框之间的移动过程，这个过程的参数如下表示，并且这样的表示对于图像的缩放是 robust 的</p><p><img src="/2018/10/05/RCNN/rcnnimg8.jpg" align="justify"></p><h3 id="Faster-R-CNN-Procedure"><a href="#Faster-R-CNN-Procedure" class="headerlink" title="Faster R-CNN Procedure__"></a>Faster R-CNN Procedure__</h3><p><img src="/2018/10/05/RCNN/rcnnimg10.jpg" width="400px"></p><h5 id="Anchor-Generation-Layer"><a href="#Anchor-Generation-Layer" class="headerlink" title="Anchor Generation Layer"></a>Anchor Generation Layer</h5><p>这一层为每个像素点生成 9 个不同大小，不同长宽比的框</p><p><img src="/2018/10/05/RCNN/rcnnimg11.jpg" align="justify"></p><h5 id="Region-Proposal-Layer"><a href="#Region-Proposal-Layer" class="headerlink" title="Region Proposal Layer"></a>Region Proposal Layer</h5><p><strong>Proposal Layer</strong>: 将每一个 anchor 做一个位置修正，同时生成生成这些 anchor 的概率，然后根据极大值抑制对这些 anchor 做一个筛选</p><p><img src="/2018/10/05/RCNN/rcnnimg12.jpg" align="justify"></p><p><strong>Anchor Target Layer</strong>：<br>和 gt 相比较，判断 anchor 是前景还是背景，如果是前景的话，计算出对应的框与它待修正偏移</p><p><strong>Calculating RPN Loss</strong>：loss 等于框的 regression loss 加上 classification loss 这里面的分类是二分类，来判断是前景还是背景</p><p><strong>Proposal Target Layer</strong>：proposal layer 提供了初步筛选的框，这里再进行一次删选，这里的筛选是根据 gt 进行的，对每个标定的 ground true box 区域，与其重叠比例最大的 ancho r记为 正样本 (保证每个 ground true 至少对应一个正样本anchor)</p><p>对上一步剩余的 anchor，如果其与某个标定区域重叠比例大于0.7，记为正样本（每个 ground true box可能会对应多个正样本 anchor。但每个正样本 anchor 只可能对应一个 grand true box）；如果其与任意一个标定的重叠比例都小于0.3，记为负样本</p><h5 id="Classification-Layer"><a href="#Classification-Layer" class="headerlink" title="Classification Layer"></a>Classification Layer</h5><p><img src="/2018/10/05/RCNN/rcnnimg13.jpg" align="justify"></p><p><img src="/2018/10/05/RCNN/rcnnimg14.jpg" align="justify"><br>上面 softmax 出现了两个分支，其中一个是要加入 loss function 的另一个是为了找到 target bounding-box 的。。</p><h3 id="Training-Method"><a href="#Training-Method" class="headerlink" title="Training Method"></a>Training Method</h3><p>源代码里用了一种叫做4-Step Alternating Training的方法</p><ol><li>用ImageNet模型初始化，独立训练一个RPN网络</li><li>仍然用ImageNet模型初始化，但是使用上一步RPN网络产生的proposal作为输入，训练一个Fast-RCNN网络，至此，两个网络每一层的参数完全不共享</li><li>使用第二步的Fast-RCNN网络参数初始化一个新的RPN网络，但是把RPN、Fast-RCNN共享的那些卷积层的learning rate设置为0，也就是不更新，仅仅更新RPN特有的那些网络层，重新训练，此时，两个网络已经共享了所有公共的卷积层</li><li>仍然固定共享的那些网络层，把Fast-RCNN特有的网络层也加入进来，形成一个unified network，继续训练，fine tune Fast-RCNN 特有的网络层，此时，该网络已经实现我们设想的目标，即网络内部预测proposal并实现检测的功能</li></ol><h1 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h1><p><img src="/2018/10/05/RCNN/rcnnimg24.jpg" align="justify"><br><img src="/2018/10/05/RCNN/rcnnimg25.jpg" align="justify"></p><p>再加一个输出，用来做 mask 的 loss，并且把这个 loss 加入到总的 loss 里面</p><p>ROI 和 GT 的 IOU 大于 0.5 就认为是 positive</p><p>loss_mask 只在 positive 的样例上进行定义</p><p>Mask RCNN 相对于 faster RCNN 的一个很大的改进就是 ROI pooling 变成了 ROI align</p><p>我们来看一下 ROI pooling 的问题是什么，下面是一个 ROI pooling 的过程</p><p><img src="/2018/10/05/RCNN/rcnnimg15.jpg" align="justify"></p><blockquote><p>ROI 在原图的区域对应到了 feature map 中的区域，为此，我们要将原图的 ROI 缩减 S 倍，这里 S 是 32，然后对于感知域，要进行 ROI pooling，要得出 pooling 的 subregion，我们要，除以 pooling 的变长，也就是 7，但是这里面的除法结果是要取整的，取完整以后，我们发现一些区域被边缘化了。。。</p></blockquote><p><img src="/2018/10/05/RCNN/rcnnimg16.jpg" align="justify"></p><blockquote><p>ROI align 保留了所有的浮点计算结果，对于完整的 ROI 进行均匀的采样</p></blockquote><p><img src="/2018/10/05/RCNN/rcnnimg17.jpg" width="500px"></p><p>ROI pooling 的 BP 求导公式为：</p><script type="math/tex; mode=display">\frac{\partial L}{\partial x_i} = \sum_r \sum_j [i = i^*(r,j)] \frac{\partial L}{\partial y_{rj}}</script><blockquote><p>$y_{rj}$ 是最后的输出也就是 pooling 得到的最大像素值<br><br>$x_i^*(r,j)$ 表示 $y_{rj}$ 的来源<br>$r$ 表示的是每个做 pooling 的区域<br>$j$ 是 $r$ 中选择的先像素点</p></blockquote><p><img src="/2018/10/05/RCNN/rcnnimg18.jpg" width="530px"></p><p>ROI align 是先进行一次双线性插值（bilinear interpolation）也就是，红色区域最近的四个点通过距离加权得到一个值，得到一个中间层，然后对这个中间层进行 max pooling.</p><p>ROI align 的 BP 求导公式为：</p><script type="math/tex; mode=display">\frac{\partial L}{\partial x_i} = \sum_r \sum_j [d(i, i^*(r,j)) < 1]\cdot (1-\Delta h )(1-\Delta w)\frac{\partial L}{\partial y_{rj}}</script><blockquote><p>$d()$ 操作是计算两点的坐标距离的<br><br>$\Delta h$ 和 $\Delta w$ 表示 $x_i$ 与 $x_i^*(r,j)$ 横纵坐标的差值</p></blockquote><h3 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h3><p><img src="/2018/10/05/RCNN/rcnnimg22.jpg" align="justify"></p><p>FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类</p><p><img src="/2018/10/05/RCNN/rcnnimg23.jpg" align="justify"></p><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p><img src="/2018/10/05/RCNN/rcnnimg19.jpg" align="justify"></p><p><img src="/2018/10/05/RCNN/rcnnimg21.jpg" align="justify"></p><blockquote><p>Backbone architecture 指的是最前面的特征提取的部分</p></blockquote><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://zhuanlan.zhihu.com/p/31426458" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31426458</a><br><a href="https://zhuanlan.zhihu.com/p/23006190" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/23006190</a><br><a href="https://blog.csdn.net/xjz18298268521/article/details/52681966" target="_blank" rel="noopener">https://blog.csdn.net/xjz18298268521/article/details/52681966</a><br><a href="http://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/" target="_blank" rel="noopener">http://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/</a><br><a href="https://ardianumam.wordpress.com/" target="_blank" rel="noopener">https://ardianumam.wordpress.com/</a><br><a href="https://blog.csdn.net/WZZ18191171661/article/details/79453780" target="_blank" rel="noopener">https://blog.csdn.net/WZZ18191171661/article/details/79453780</a><br><a href="http://blog.leanote.com/post/afanti.deng@gmail.com/b5f4f526490b" target="_blank" rel="noopener">http://blog.leanote.com/post/afanti.deng@gmail.com/b5f4f526490b</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;R-CNN&quot;&gt;&lt;a href=&quot;#R-CNN&quot; class=&quot;headerlink&quot; title=&quot;R-CNN&quot;&gt;&lt;/a&gt;R-CNN&lt;/h1&gt;&lt;p&gt;R-CNN 流程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对输入图片使用 select search 选择 2000 个区域&lt;ul
      
    
    </summary>
    
    
      <category term="DL" scheme="http://yoursite.com/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>RL1-introduction</title>
    <link href="http://yoursite.com/2018/10/04/RL-1/"/>
    <id>http://yoursite.com/2018/10/04/RL-1/</id>
    <published>2018-10-04T08:51:19.000Z</published>
    <updated>2018-11-12T01:55:54.047Z</updated>
    
    <content type="html"><![CDATA[<p>RL 和传统的监督学习和无监督学习是有区别的，RL 没有 label 只有 reward</p><p>数据是有时序性的，也就是数据之间并不是独立的</p><p>数据只会对它后面的数据造成影响</p><blockquote><p>比如一个棋局只会对后面的落子有影响，当前位置只会对后面的位置移动产生作用</p></blockquote><p>RL 的方法可以分为</p><ul><li>Model-free RL</li><li>Model-based RL</li></ul><h3 id="Reward"><a href="#Reward" class="headerlink" title="Reward"></a>Reward</h3><p>一个 Reward  $R_t$ 就是一个常数的信号，用来对状态的衡量，或者 agent 在时间 $t$ 做的好坏程度，agent 的目标就是最大化 reward，RL 的基础就是建立在最大化 reward 的假设</p><p>下面是一些 reward 在特定任务下的例子：</p><p><img src="/2018/10/04/RL-1/rlimg1.jpg" width="600"></p><h3 id="State"><a href="#State" class="headerlink" title="State"></a>State</h3><p><img src="/2018/10/04/RL-1/rl1img2.jpg" align="justify"></p><ul><li>History：可以由上面介绍的组成一个序列 $H_t= O_1,R_1,A_1,…,A_{t-1},O_t,R_t$</li><li>State： 其实就是信息，决定着接下来会发生的信息是什么，State 只和 history 有关 $S_t = f(H_t)$<ul><li>Environment State：隐藏在能给出反馈的环境中，一般是看不到的，看到也没用。。</li><li>Agent State：决策者的状态 $S_t^a = f(H_t)$</li><li>Information State：只包含历史中有用信息，例如假设了 Markov 性，inf state 只有之前的状态</li></ul></li></ul><p>Fully Observation Environments：$O_t = S_t^a = S_t^e$</p><p>Partially Observation Environments：间接的观察环境</p><h3 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h3><p>RL 的 agent 一般有如下几个组件构成</p><ul><li>Policy：agent 的行为函数</li><li>Value function：评价 state 或者 action 的好坏</li><li>Model：agent 对于 Environment 的表示</li></ul><p><img src="/2018/10/04/RL-1/rl1img4.jpg" width="600"></p><h5 id="Policy"><a href="#Policy" class="headerlink" title="Policy"></a>Policy</h5><p>policy 是 state 到 action 的映射，是 agent 的行为</p><p>Deterministic Policy：$a = \pi(s)$</p><p>Stochastic policy：$\pi(a|s) = P[A_t = a | S_t = s]$</p><p><img src="/2018/10/04/RL-1/rl1img3.jpg" width="400"></p><h5 id="Value-Function"><a href="#Value-Function" class="headerlink" title="Value Function"></a>Value Function</h5><p>对于未来的预测</p><script type="math/tex; mode=display">v_{pi}(s) = E_{\pi}[R_{t+1} + \gamma R_{t+1} + \gamma^2 R_{t+3}+...|S_t=s]</script><p><img src="/2018/10/04/RL-1/rl1img5.jpg" width="400"></p><h5 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h5><p>model 是用来预测 environment 接下来会做什么</p><p>$\mathcal{P}$ 用来预测接下来的的 state</p><p>$\mathcal{R}$ 用来预测接下来的 reward</p><script type="math/tex; mode=display">\mathcal{P}_{ss^{\prime}} = P[S_{t+1} = S^{\prime}|S_t = s, A_t = a]</script><script type="math/tex; mode=display">\mathcal{R}_s^a  = E[R_{t+1}|S_t = s, A_t = a]</script><p><img src="/2018/10/04/RL-1/rl1img7.jpg" align="justify"></p><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;RL 和传统的监督学习和无监督学习是有区别的，RL 没有 label 只有 reward&lt;/p&gt;
&lt;p&gt;数据是有时序性的，也就是数据之间并不是独立的&lt;/p&gt;
&lt;p&gt;数据只会对它后面的数据造成影响&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;比如一个棋局只会对后面的落子有影响
      
    
    </summary>
    
    
      <category term="RL" scheme="http://yoursite.com/tags/RL/"/>
    
  </entry>
  
  <entry>
    <title>Machine Translation</title>
    <link href="http://yoursite.com/2018/09/25/NLP-2/"/>
    <id>http://yoursite.com/2018/09/25/NLP-2/</id>
    <published>2018-09-25T11:26:50.000Z</published>
    <updated>2018-11-06T15:05:00.449Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Machine-Translation"><a href="#Machine-Translation" class="headerlink" title="Machine Translation"></a>Machine Translation</h1><h3 id="Statistical-Machine-Translation"><a href="#Statistical-Machine-Translation" class="headerlink" title="Statistical Machine Translation"></a>Statistical Machine Translation</h3><p>早期的机器翻译的方法是 SMT，S 代表 statistic 表示统计的意思，然后 14 年的时候，一切都变了。。。</p><h3 id="Neural-Machine-Translation"><a href="#Neural-Machine-Translation" class="headerlink" title="Neural Machine Translation"></a>Neural Machine Translation</h3><p>NMT 降临了，吊打了 SMT，所以 SMT 我就不学啦，哈哈哈</p><hr><h1 id="Seq-to-Seq-model"><a href="#Seq-to-Seq-model" class="headerlink" title="Seq-to-Seq model"></a>Seq-to-Seq model</h1><p>传统的深度神经网络的输入和输出都是固定的，但是在翻译这样的任务中，对于某个长度的句子，它的输出长度是不确定的。。</p><p>seq2seq 模型的出现解决了这个问题</p><p><img src="/2018/09/25/NLP-2/nlp2img1.jpg" align="justify"></p><blockquote><ul><li>上图称为 sequence-to-sequence 模型，有两个 RNN</li><li>待翻译的句子为输入 $x$，翻译的结果称为 $y$</li><li>第一个 RNN 用来将 $x$ 做一个 encoding，类似于将输入生成一个特征</li><li>生成这个特征的结果放到下一个 RNN 中做 Decodeing</li><li>Decoding 的过程相当于做一连串的单词预测</li></ul></blockquote><p><img src="/2018/09/25/NLP-2/nlp2img2.jpg" align="justify"></p><blockquote><ul><li>这是 seq2seq 模型的训练过程</li><li>要注意的是，seq2seq 模型最后的 loss 是根据 gt 和 gt 长度内的 predicts 来比较生成的</li></ul></blockquote><h3 id="Beam-search-decoding"><a href="#Beam-search-decoding" class="headerlink" title="Beam search decoding"></a>Beam search decoding</h3><p><img src="/2018/09/25/NLP-2/nlp2img3.jpg" align="justify"></p><p>对于每一个单词后面一个单词的预测，最简单的方法就是上面的贪心法 (greedy decoding), 每一步直接输出概率最高的，但是其实这并不是一定我们期望的最优解，甚至离最优解的很远，一组输出的概率表示形式如下：</p><script type="math/tex; mode=display">P(y|x) = P(y_1|x) P(y_2|y_1,x) P(y_3|y_2,y_1,x),...,P(y_T|y_{T-1},...,y_1,x)</script><p>我们希望输出的值概率尽可能的大，要想获得最大值，最粗暴有效的方法就是遍历上面的所有取值，但是上面的所有取值的复杂度是 $O(V^T)$，于是我们可以做一个在 greedy 和 optimal 之间做一个折衷，这个方法就叫 Beam Search。<br></p><p><strong>Beam search: On each step of decoder, keep track of the k most probable partial translations</strong></p><p>举个 $k=2$ 的例子</p><p><img src="/2018/09/25/NLP-2/nlp2img4.jpg" align="justify"></p><blockquote><p>每个单词我们生成它最大概率的 2 个，然后每次选取概率最大的两个分支继续进行生成</p></blockquote><p><img src="/2018/09/25/NLP-2/nlp2img5.jpg" align="justify"></p><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Machine-Translation&quot;&gt;&lt;a href=&quot;#Machine-Translation&quot; class=&quot;headerlink&quot; title=&quot;Machine Translation&quot;&gt;&lt;/a&gt;Machine Translation&lt;/h1&gt;&lt;h3 i
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>PGM-CRF</title>
    <link href="http://yoursite.com/2018/09/22/PGM-CRF/"/>
    <id>http://yoursite.com/2018/09/22/PGM-CRF/</id>
    <published>2018-09-22T02:25:18.000Z</published>
    <updated>2018-10-10T07:18:46.477Z</updated>
    
    <content type="html"><![CDATA[<p>CRF 可以看作是 logistics 回归的一个扩展</p><h1 id="Modeling"><a href="#Modeling" class="headerlink" title="Modeling"></a>Modeling</h1><h3 id="Notions"><a href="#Notions" class="headerlink" title="Notions"></a>Notions</h3><ul><li>$\mathbf{X}$: 我们观测到的输入变量</li><li>$\mathbf{Y}$: 我们待预测的输出变量</li><li>$\sum_{\mathbf{y} \setminus y_s}$: 在$y_s$ 给定的情况下，y 中所有其他变量的可能的取值的遍历</li></ul><h3 id="G-amp-D"><a href="#G-amp-D" class="headerlink" title="G &amp; D"></a>G &amp; D</h3><h5 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h5><p>Classification 是分类问题，通过给定的特征向量 $\mathbf{x}$ 我们来估计隐藏在这些数据后面的类别 $y$ 是什么，其中一个简单的方法是假设特征向量里面的变量都是相互独立的，这称为 <strong>_naive Bayes classifier_</strong> 这是基于 x 的联合分布：</p><script type="math/tex; mode=display">p(y|\mathbf{x}) = p(y) \prod_{k=1}^K p(x_k | y)</script><p>上面的公式也是可以写成因子图的表示形式的</p><p>另一个比较常见的模型就是 logistic regression：</p><script type="math/tex; mode=display">p(y|\mathbf{x}) = \frac{1}{Z(\mathbf{x})}  exp \left\{   \sum_{k=1}^K \theta_k f_k (y, \mathbf{x})   \right\}</script><h5 id="Sequence-Models"><a href="#Sequence-Models" class="headerlink" title="Sequence Models"></a>Sequence Models</h5><p>Classifier 只能对于单变量做预测，我们希望能对多变量做预测，为了引出这个模型，我们来讨论一个 NLP 的应用，称为 NER，NER 是用来定义一个词的类别的，比如，china，它的 NER 就是 location，更加具体一些，给定一个句子，我们确定哪些词是组合在一起的，同时对于这些词做一个区分。</p><p>一个直观的 NER 方法是对于单词做独立的区分，这种方法每个单词和它周围的单词是独立的，比如 new york 是一个地名，但是 new york times 它就是一个报纸了。。。一个方法就是把这些输出变量都串起来，形成一个链式的模型，称为 HMM，HMM 有两个独立性假设</p><ul><li>每一个 state $y_t$ 只和前一个 state $y_{t-2}$ 相关</li><li>观测 $x_t$ 由 $y_t$ 导出</li></ul><p>于是，state y 和 观测 x 的联合分布可以写成</p><script type="math/tex; mode=display">p(\mathbf{y},\mathbf{x}) = p(y_1) \prod_{t=2}^ T p(y_t|y_{t-1}) p(x_t|y_t)</script><h5 id="Comparision"><a href="#Comparision" class="headerlink" title="Comparision"></a>Comparision</h5><p>Generative Model</p><ul><li>Naive Bayes</li><li>HMM</li></ul><p>Discriminative Model</p><ul><li>logistic regression</li></ul><p>我们还回忆一下生成模型和判别模型的区别，生成模型中概率的一部分是分给 x 的，所以生成模型最后的联合分布的概率通常很小，就比如 naive bayes，对于判别模型，概率是 0-1 之间的条件，这就符合了逻辑回归呀，在条件概率中，x 只对 y 的概率有影响，但是完全不出现在概率中。之所以不对 $p(x)$ 建模，是因为输入的特征变量之间的相关性太高</p><p><img src="/2018/09/22/PGM-CRF/pgmcrf_img1.jpg" align="justify"></p><h3 id="Linear-Chain-CRFs"><a href="#Linear-Chain-CRFs" class="headerlink" title="Linear Chain CRFs"></a>Linear Chain CRFs</h3><p>我们重写 HMM 模型到一个更加 general 的 case：</p><script type="math/tex; mode=display">p(\mathbf{y}, \mathbf{x}) = \frac{1}{Z}   \prod_{t=1}^T  exp \left \{  \sum_{i,j \in  S} 1_{\{y_t=i\}} 1_{\{y_{t-1}=j\}} + \sum_{i \in S} \sum_{o \in O} \mu_{oi} 1_{\{y_t = i\}} 1_{\{x_t = o\}} \right \}</script><p>当 $\theta_{ij} = log p(y^{\prime} = i | y = j)$ 时，$\mu_{oi} = log p(x=o|y=i)$ 时，就是 HMM 了，写成更一般的简洁一些的形式，即把指数的参数直接写成 feature function 为 $f_k(y_t,y_{t-1},x_t)$ 的形式：</p><script type="math/tex; mode=display">p(\mathbf{y}, \mathbf{x}) = \frac{1}{Z} \prod_{t=1}^T exp \left\{  \sum_{k=1}^K \theta_k f_k (y_t, y_{t-1},x_t)  \right\}</script><p>上面是生成模型，根据 bayes 定理我们把它写成条件概率的判别模型：</p><script type="math/tex; mode=display">p(\mathbf{y}| \mathbf{x}) = \frac{p(\mathbf{y}, \mathbf{x})}{\sum_{\mathbf{y^{\prime}}}} = \frac{\prod_{t=1}^T exp \left\{  \sum_{k=1}^K \theta_k f_k(y_t,y_{t-1},x_t) \right\}}{\sum_{\mathbf{y^{\prime}}} \prod_{t=1}^T  exp \left \{ \sum_{k=1}^K \theta_k f_k(y_t^{\prime}, y_{t-1}^{\prime},x_t)  \right \} }</script><p>上面的条件概率就是 linear-chain CRF，</p><p><strong>Definition：linear-chain CRF</strong></p><script type="math/tex; mode=display">p(\mathbf{y}| \mathbf{x}) = \frac{1}{Z(\mathbf{x})} \prod_{t=1}^T exp \left\{  \sum_{k=1}^K \theta_k f_k(y_t,y_{t-1},\mathbf{x}_t)  \right\}</script><blockquote><ul><li>$Y,X$ 是随机变量</li><li>$\theta$ 是参数向量，总共有 K 个变量</li><li>$f_k(y,y^{\prime},x_t)$ 是 feature function</li></ul></blockquote><h3 id="General-CRFs"><a href="#General-CRFs" class="headerlink" title="General CRFs"></a>General CRFs</h3><p>把 linear-chain CRF 中的 linear-chain factor 用 more general 的 factor 表示就是 General CRFs</p><script type="math/tex; mode=display">p(\mathbf{y}|\mathbf{x}) = \frac{1}{Z(\mathbf{x})} \prod_{\Psi_A \in G} exp \left\{ \sum_{k=1}^{K(A)} \theta_{ak} f_{ak}(\mathbf{y}_a,\mathbf{x}_a) \right\}</script><p>General form 的参数似乎更多，对于 linear-chain，相同的 weight 作用于每一个时间轴上的 $\Psi_t(y_t,y_{t-1},x_t)$，对于 General 的形式，我们将 G 的 factors 分成 $C= \{ C_1,C_2,…,C_p \}$ 每一个 clique $C_p$ 对应这一个 suffcient statistics $\{ f_{pk}(\mathbf{x}_p, \mathbf{y}_p) \}$ 以及参数 $\theta_p \in R^{K(p)}$，于是 CRF 可以写成：</p><script type="math/tex; mode=display">p(\mathbf{y}|\mathbf{x}) = \frac{1}{Z(\mathbf{x})} \prod_{C_p\in C} \prod_{\Psi_c \in C_p} \Psi (\mathbf{x}_c,\mathbf{y}_c; \theta_p)</script><script type="math/tex; mode=display">\Psi (\mathbf{x}_c,\mathbf{y}_c; \theta_p) = exp  \left\{  \sum_{k=1}^{K(p)} \theta_{pk} f_{pk} (\mathbf{x}_c,\mathbf{y}_c)  \right\}</script><h1 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h1><p>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;CRF 可以看作是 logistics 回归的一个扩展&lt;/p&gt;
&lt;h1 id=&quot;Modeling&quot;&gt;&lt;a href=&quot;#Modeling&quot; class=&quot;headerlink&quot; title=&quot;Modeling&quot;&gt;&lt;/a&gt;Modeling&lt;/h1&gt;&lt;h3 id=&quot;Notion
      
    
    </summary>
    
    
      <category term="MATH" scheme="http://yoursite.com/tags/MATH/"/>
    
  </entry>
  
  <entry>
    <title>Information-Theory</title>
    <link href="http://yoursite.com/2018/09/18/Information-Theory/"/>
    <id>http://yoursite.com/2018/09/18/Information-Theory/</id>
    <published>2018-09-18T02:06:08.000Z</published>
    <updated>2018-10-10T07:18:01.436Z</updated>
    
    <content type="html"><![CDATA[<ul><li><strong>信息熵</strong>：编码方案完美时，最短平均编码长度</li><li><strong>交叉熵</strong>：编码方案不一定完美时，平均编码长度</li><li><strong>相对熵</strong>：不同方案之间的差异性的衡量</li></ul><p>信息论引用了熵（entropy）的概念，熵的概念在物理中十分常见，是用来衡量系统的混沌程度的，相应的在信息科学中，熵是用来衡量不确定性的，信息熵的本质是香农信息量 $log \frac{1}{p}$ 的期望</p><p>下面我们就来讲讲这三个熵到底有什么含义</p><p>首先我们通过一个例子来引出什么是信息熵：<br>假设一个箱子里面有4种不同颜色的球（a,b,c,d），A 从其中拿出一个，B 来猜（B 可以向 A 提问），B希望提问的次数越少越好。</p><ul><li><strong>case1</strong>：B 不知道颜色的分布，于是先问 “是否是 a,b”，如果是再问 “是否是 a”，不是改为问 “是否是 c”，猜球的次数为：$H=\frac{1}{4}\times 2+\frac{1}{4}\times 2+\frac{1}{4}\times 2+\frac{1}{4}\times 2=2$</li><li><strong>case2</strong>：B 了解到 a 的比例为 1/2，b 的比例为 1/4，c 和 d 的比例都是 1/8，于是 B 先问 a，再问 b，最后问 c，猜球期望为：$H=\frac{1}{2}\times 1+\frac{1}{4}\times 2+\frac{1}{8}\times 3+\frac{1}{8}\times 3=1.75$</li><li><p><strong>case3</strong>：B 了解到了里面的球全是 a，那么不用猜了：$H=1\times 0=0$</p><p>_假设上面的 B 是足够聪明的，所以他做出策略是最优的_</p></li></ul><hr><h1 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h1><p>通过上面我们发现：针对特定概率为 $p$ 的小球，猜球的次数为 $log_2  \frac{1}{p}$，所以整体的期望为：</p><script type="math/tex; mode=display">\sum_{i=1}^N p_k log_2 \frac{1}{p_k}</script><p>这就是信息熵，case1 的信息熵为 2，case2 的信息熵为 1.75，case3 的信息熵为 0.</p><p><strong>信息熵代表随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大</strong>。<br>上面的熵 case1&gt;case2&gt;case3，在 case1 中，B 对于系统一无所知，在 case2 中，B 知道了系统的分布，但是取了哪个球并不知道，case3 中，B 对于系统完全了解了！所以2是这个系统熵的最大值</p><hr><h1 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h1><p>每个系统都会有一个真实的概率分布，称为真实分布，case1 的真实分布为 $(\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4})$，case2 的真实分布为 $(\frac{1}{2},\frac{1}{4},\frac{1}{8},\frac{1}{8})$,而根据真实分布，我们能够找到一个最优策略，以最小的代价消除系统的不确定性，而这个代价大小就是信息熵，记住，信息熵衡量了系统的不确定性，而我们要消除这个不确定性，所要付出的 [最小努力]（猜题次数、编码长度等）的大小就是信息熵。具体来讲，case1 只需要猜两次就能确定任何一个小球的颜色，case2 只需要猜测1.75次就能确定任何一个小球的颜色</p><p>回到 case2 假设现在是 C 来猜，C 的智商不高，所以仍然使用了 case1 的策略来，相当于认为小球出现的概率是一样的，即分布为 $(\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4})$，这个分布就是非真实分布，最后的信息熵算出来又是 2 了，显然这个策略是不好的比最优策略多了 0.25，那么，当我们使用非最优策略消除系统的不确定性，所需要付出的努力的大小我们该如何去衡量呢？</p><p>这就需要引入 <strong>交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小</strong>。</p><p>交叉熵的公式如下，<strong>其中 $p_k$  表示真实分布，$q_k$ 表示非真实分布</strong></p><script type="math/tex; mode=display">\sum_{i=1}^N p_k log_2 \frac{1}{q_k}</script><p>上面所讲将策略 1 用于 case 2，真实分布 $p_k=(\frac{1}{2},\frac{1}{4},\frac{1}{8},\frac{1}{8})$，非真实分布 $q_k=(\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4})$，交叉熵为 $\frac{1}{2}\times log_2 4+\frac{1}{4}\times log_2 4+\frac{1}{8}\times log_2 4+\frac{1}{8}\times log_2 4=2$ 比最优分布的 $1.75$ 大</p><p>因此，交叉熵越低，策略就越好，最低的也就是真实的信息熵了，此时 $p_k=q_k$，这也是为什么在机器学习中的分类算法中，我们总是最小化交叉熵，因为交叉熵越低，就证明由算法所产生的策略最接近最优策略，也间接证明我们算法所算出的非真实分布越接近真实分布</p><hr><h1 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h1><p>我们如何衡量不同策略之间的差异呢？这里就需要用到相对熵（KL divergence），其用来衡量两个取值为正的函数或者概率分布之间的差异（可以发现相同的话每一项都是 0）：</p><script type="math/tex; mode=display">KL(P||Q) = \sum_x p(x) log \frac{p(x)}{q(x)}</script><blockquote><ul><li>$p(x)$ 是真实分布</li><li>$q(x)$ 是近似分布</li></ul></blockquote><p><strong>相对熵</strong> 可以写成 <strong>交叉熵</strong> 和 <strong>信息熵</strong> 之差。。</p><script type="math/tex; mode=display">KL(p||q) = H(p,q) - H(p) = \sum_{k=1}^N p_k log_2 \frac{p_k}{q_k}</script><hr><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.zhihu.com/question/41252833answer/195901726" target="_blank" rel="noopener">https://www.zhihu.com/question/41252833answer/195901726</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;strong&gt;信息熵&lt;/strong&gt;：编码方案完美时，最短平均编码长度&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;交叉熵&lt;/strong&gt;：编码方案不一定完美时，平均编码长度&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;相对熵&lt;/strong&gt;：不同方案之间的差异性的衡量&lt;/
      
    
    </summary>
    
    
      <category term="MATH" scheme="http://yoursite.com/tags/MATH/"/>
    
  </entry>
  
  <entry>
    <title>MatplotLib-1</title>
    <link href="http://yoursite.com/2018/09/16/MatplotLib-1/"/>
    <id>http://yoursite.com/2018/09/16/MatplotLib-1/</id>
    <published>2018-09-16T08:14:42.000Z</published>
    <updated>2018-09-16T08:14:42.834Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>NLP-</title>
    <link href="http://yoursite.com/2018/09/14/NLP-1/"/>
    <id>http://yoursite.com/2018/09/14/NLP-1/</id>
    <published>2018-09-14T12:01:35.000Z</published>
    <updated>2018-09-25T07:02:56.473Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Language-Model"><a href="#Language-Model" class="headerlink" title="Language Model"></a>Language Model</h1><p>语言模型（Language Model）</p><p>语言模型是用来预测下一个出现的单词会是哪一个的，说的数学一些就是给定一个单词序列 $x^1,x^2,…,x^t$，来计算下一个单词 $x^{t+1}$ 的概率分布：</p><script type="math/tex; mode=display">P(x^{t+1}=w_j|x^1,x^2,...,x^t)</script><blockquote><p>其中 $w_j$ 是单词 j 的词向量</p></blockquote><p>我们将任务做一个简化，我们不去考虑离下一个词太远的词的影响，只考虑下一个词前面的 $n-1$ 个，这称为 <strong>n-gram Language Model</strong></p><p><img src="/2018/09/14/NLP-1/nlp1img1.jpg" style=" width:600px;"></p><p>于是概率可以写成下面的形式了：</p><script type="math/tex; mode=display">\begin{align}P(x^{t+1} | x^t,...,x^{t-n+2}) &= \frac{P(x^{t+1},x^t,...,x^{t-n+2})}{P(x^t,...,x^{t-n+2})} \notag \\&\approx \frac{count(x^{t+1},x^t,...,x^{t-n+2})}{count(x^t,...,x^{t-n+2})}\end{align}</script><blockquote><ul><li>第一行通过 Bayesian 概率转换</li><li>第二行通过统计量来近似概率</li></ul></blockquote><p>假如 n 过大，会导致表格的内存呈指数级上升，所以一般不会超过 5</p><hr><h1 id="fixed-window-Neural-Language-Model"><a href="#fixed-window-Neural-Language-Model" class="headerlink" title="fixed-window Neural Language Model"></a>fixed-window Neural Language Model</h1><p>我们先看一种基于窗口的神经网络的结构</p><p><img src="/2018/09/14/NLP-1/nlp1img2.jpg" align="justify"></p><p><strong>优点</strong></p><ul><li>不存在 n-grim 的稀疏性</li><li>模型的 size 大大减小</li></ul><p><strong>缺点</strong></p><ul><li>窗口尺寸太小</li><li>每一个 $x^i$ 只使用了 $W$ 一行的参数，并没有共享参数</li></ul><hr><h1 id="Recurrent-Neural-Networks-RNN-Language-Model"><a href="#Recurrent-Neural-Networks-RNN-Language-Model" class="headerlink" title="Recurrent Neural Networks (RNN) Language Model"></a>Recurrent Neural Networks (RNN) Language Model</h1><p>我们先来看一看常见的一种 RNN 的结构：</p><p><img src="/2018/09/14/NLP-1/nlp1img4.jpg" align="justify"></p><p>RNN 的核心 Idea 就是复用权重 $W$</p><p>下面是一个用于 Language Model 的 RNN 模型：</p><p><img src="/2018/09/14/NLP-1/nlp1img3.jpg" align="justify"></p><p><strong>RNN 的优点</strong>：</p><ul><li>由于序列之间相连的传递是共享了参数的，所以这个序列可以任意的延长</li><li>模型的大小不会随着输入的增加而增加</li><li>某一步的计算，会考虑之前几步计算的结果</li></ul><p><strong>RNN 的缺点</strong>：</p><ul><li>计算速度比较慢</li><li>很难考虑到之前好几步的信息</li><li>存在梯度消失</li></ul><p>有了模型，接下来介绍这个模型是如何进行优化的，对于这个模型有一点要说明的就是，输出 $\hat{y}^t$ 其实是在给定单词到 $x^t$ 时，下一个单词 $x^{t+1}$ 出现的概率的预测，然后交叉熵来代替目标优化函数：</p><script type="math/tex; mode=display">\begin{align}  J^t(\theta) &= CE(y^t,\hat{y}^t)=  - \sum_{j=1} ^ {|V|} y_j^t \mathop{log} \hat{y}_j^t \notag \\  J(\theta) &= \frac{1}{T} \sum_{t=1}^T J^t(\theta)\end{align}</script><blockquote><p>上面的真实 label $y^t$ 是根据 $x^{t+1}$ 生成的 one-hot vector</p></blockquote><p>这个模型的 BP 是 $\frac{\partial J^t}{\partial W_h} \sum_{i=1}^t \frac{\partial J^t}{\partial W_h}|_i$</p><p>训练所有的数据是庞大且消耗巨大的任务，我们一般会把使用 SGD 也就是每一次拿一个句子进去做梯度下降</p><p>衡量某个模型的好坏的函数是 ：</p><script type="math/tex; mode=display">PP = \prod_{t=1}^T \left(  \frac{1}{\sum_{j=1}^{|V|} y_j^t \hat{y}_j^t} \right)^{1/T}</script><blockquote><p>上面的计算结果越小越好</p></blockquote><h3 id="RNN-Gradient"><a href="#RNN-Gradient" class="headerlink" title="RNN Gradient"></a>RNN Gradient</h3><p>多维变量的链式求导法则：</p><script type="math/tex; mode=display">\frac{d}{dt} f(x(t), y(t)) = \frac{\partial f}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial f}{\partial y} \frac{\partial y}{\partial t}</script><p>RNN 的基本公式可以写成：</p><script type="math/tex; mode=display">\begin{align}  h_t &= W f(h_{t-1}) + W^{hx} x_t \notag \\  \hat{y}_t &= W^S f(h_t) \notag\end{align}</script><p><img src="/2018/09/14/NLP-1/nlp1img6.jpg" style=" width:300px;"></p><p>根据上面这张图，RNN 的梯度为：</p><script type="math/tex; mode=display">\begin{align}  \frac{\partial E}{\partial W} &= \sum_{t=1}^T \frac{\partial E_t}{\partial W} \notag \\  \frac{\partial E_t}{\partial W} &= \sum_{k=1}^t \frac{\partial E_t}{\partial y_t} \frac{\partial y_t}{\partial h_t} \frac{\partial h_t}{\partial h_k} \frac{\partial h_k}{\partial W} \notag \\  \frac{\partial h_t}{\partial h_k} &= \prod_{j=k+1}^t \frac{\partial h_j}{\partial h_{j-1}}\end{align}</script><blockquote><p>$\frac{\partial h_t}{\partial h_k}$ 这一部分可能造成梯度消失</p></blockquote><h3 id="解决-RNN-梯度消失的方法"><a href="#解决-RNN-梯度消失的方法" class="headerlink" title="解决 RNN 梯度消失的方法"></a>解决 RNN 梯度消失的方法</h3><p><strong>clipping trick</strong>：</p><p><img src="/2018/09/14/NLP-1/nlp1img7.jpg" align="justify"></p><p><strong>Initialization + Relus</strong>：</p><ul><li>初始矩阵 $W$ 为单位矩阵</li><li>函数 $f$ 变为 $f(z) = max(z, 0)$</li></ul><p>这些只是一些小的 trick 要从根本上解决，就需要建立新的模型</p><hr><h3 id="GRUS"><a href="#GRUS" class="headerlink" title="GRUS"></a>GRUS</h3><p><img src="/2018/09/14/NLP-1/nlp1img8.jpg" align="justify"></p><hr><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><ul><li>决定哪些信息我们要从 cell state 中删除</li></ul><p><img src="/2018/09/14/NLP-1/nlp1img9.jpg" align="justify"></p><p><img src="/2018/09/14/NLP-1/nlp1img10.jpg" align="justify"></p><p><img src="/2018/09/14/NLP-1/nlp1img11.jpg" align="justify"></p><blockquote><p>上面黄色的区域是有参数需要学习的 layer，粉色的是直接进行的计算操作，计算操作有相乘还有相加等等。。</p></blockquote><h5 id="LSTM-Structure"><a href="#LSTM-Structure" class="headerlink" title="LSTM Structure"></a>LSTM Structure</h5><p><img src="/2018/09/14/NLP-1/nlp1img12.jpg" align="justify"></p><blockquote><ul><li>上面这条线贯穿着整个结构的称为 cell state，传递着最主要的信息</li><li>LSTM 有能力控制这个信息传输的增和删</li></ul></blockquote><p><img src="/2018/09/14/NLP-1/nlp1img13.jpg" align="justify"></p><blockquote><ul><li>确定了哪些信息我们要从 cell state 中删去</li><li>黄色的是 sigmoid 函数，输出在 0-1 之间</li><li>状态 1 表示完全保留 cell state $C_{i-1}$</li><li>状态 0 表示完全抛弃 cell state $C_{i-1}$</li></ul></blockquote><p><img src="/2018/09/14/NLP-1/nlp1img14.jpg" align="justify"></p><blockquote><ul><li>这一步决定了我们要保存哪些数据</li><li>sigmoid 函数决定哪些数据我们要更新</li><li>tanh 层生成了一个新的向量 $\hat{C}_t$ 待用于生成新的 $C_t$</li></ul></blockquote><p><img src="/2018/09/14/NLP-1/nlp1img15.jpg" align="justify"></p><blockquote><ul><li>将删选后的信息 $f_t * C_{t-1}$ 和新生成的信息 $\hat{C}_t$ 做一个相加</li></ul></blockquote><p><img src="/2018/09/14/NLP-1/nlp1img16.jpg" align="justify"></p><blockquote><ul><li>最后我们决定信息的输出</li><li>上面 sigmoid 节点的输出 $o_t$ 和输入 $x_t$ 以及之前输出 $h_{t-1}$ 有关</li><li>最终的输出 $h_t$ 和 $o_t$ 以及 cell state $C_t$ 相关</li><li>$h_t$ 有两个去处，一个是直接输出，还有一个是做为 $h_{t+1}$ 的生成信息 </li></ul></blockquote><hr><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>  <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Language-Model&quot;&gt;&lt;a href=&quot;#Language-Model&quot; class=&quot;headerlink&quot; title=&quot;Language Model&quot;&gt;&lt;/a&gt;Language Model&lt;/h1&gt;&lt;p&gt;语言模型（Language Model）&lt;/
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>PGM-Approximate Inference</title>
    <link href="http://yoursite.com/2018/09/11/PGM-4/"/>
    <id>http://yoursite.com/2018/09/11/PGM-4/</id>
    <published>2018-09-11T00:50:05.000Z</published>
    <updated>2018-10-10T07:18:43.102Z</updated>
    
    <content type="html"><![CDATA[<p>概率的推断就是计算 conditional 和 marginal，之前我们学习了 exact inference 也就是准确的推断概率图概率，我们学习message passing 算法、sum-product、</p><p>inference is answer a query</p><p>Approximate inference 就是对于 inference 的一个数值估计，不一定最后的结果要在 0-1 之内</p><h1 id="Exact-Inference-Revisit"><a href="#Exact-Inference-Revisit" class="headerlink" title="Exact Inference Revisit"></a>Exact Inference Revisit</h1><h3 id="Sum-Product"><a href="#Sum-Product" class="headerlink" title="Sum-Product"></a>Sum-Product</h3><p><img src="/2018/09/11/PGM-4/pgm4img3.jpg" align="justify"></p><p><img src="/2018/09/11/PGM-4/pgm4img1.jpg" align="justify"></p><h3 id="Factor-Graph"><a href="#Factor-Graph" class="headerlink" title="Factor Graph"></a>Factor Graph</h3><p><img src="/2018/09/11/PGM-4/pgm4img4.jpg" align="justify"></p><h3 id="Junction-Tree"><a href="#Junction-Tree" class="headerlink" title="Junction Tree"></a>Junction Tree</h3><p><img src="/2018/09/11/PGM-4/pgm4img2.jpg" align="justify"></p><blockquote><p>在 Junction Tree 中 local Consistency 等价于 global Consistency</p></blockquote><hr><h1 id="Loopy-Belief-Propagation"><a href="#Loopy-Belief-Propagation" class="headerlink" title="Loopy Belief Propagation"></a>Loopy Belief Propagation</h1><p>Junction Tree 虽然可以处理所有的 graph，但是只适用于树形结构，在密集结构中用 Junction Tree 复杂度依然会比较高，假设树变成了 gird，我们不打算用 Junction Tree 算法来计算出这个图的 inference 的精确解。<br><br><img src="/2018/09/11/PGM-4/pgm4img5.jpg" align="justify"></p><h3 id="LBP-The-Algorithm"><a href="#LBP-The-Algorithm" class="headerlink" title="LBP : The Algorithm"></a>LBP : The Algorithm</h3><p>我们在这个图上运行直接做 Belief Propagation，在树形结构上，Belief Propagation 只要来回传递两次就能够得到精确解了，但是在这个图上，我们需要多次的运行 BP ，最终可能会收敛，也有可能会呈现出周期性的数值变化，也就是不收敛。</p><p>一般来讲好的 近似可以通过以下的方式</p><ul><li>在固定的迭代次数后停止</li><li>如果结果没有明显变化，就停止</li><li>如果在数值上没有震荡，并且收敛了，那么通常就是接近真实了</li></ul><p><img src="/2018/09/11/PGM-4/pgm4img6.jpg" align="justify"></p><h3 id="LBP-The-Bethe-Approximation"><a href="#LBP-The-Bethe-Approximation" class="headerlink" title="LBP : The Bethe Approximation"></a>LBP : The Bethe Approximation</h3><p>我们对于 LBP 算法的正确性做一个分析：</p><p>一般来讲，真实的分布 P 是这样子的：</p><script type="math/tex; mode=display">P(X) = \frac{1}{Z} \prod_{f_a \in F} f_a(X_a)</script><p>但是这种分布的计算很困难（$f_a 是 factor graph 的算子$）。。</p><p>于是我们转向另一个分布 Q ，在后面，Q 是我们近似得到的分布，我们希望来评价 Q，也就是 Q 和 P 的相似度，对于某一事件不同概率的衡量，最常用的就是相对熵 KL Divergence ：</p><script type="math/tex; mode=display">KL(Q\Vert P) = \sum_X Q(X) log(\frac{Q(X)}{P(X)})</script><p>相对熵是来衡量两个取值为正的函数或者概率分布之间的差异的，有以下的特性：</p><ul><li>$KL(Q\Vert P) \geq 0$</li><li>$KL(Q\Vert P) = 0$ iff $Q=P$</li></ul><p>相对熵还可以写成 <strong>信息熵</strong> 减去 <strong>交叉熵</strong>：</p><script type="math/tex; mode=display">\begin{align}KL(Q||P) &= \sum_X Q(X)log Q(X) - \sum_X Q(X) log P(X) \\&= -H_Q(X) -E_Q logP(X)\end{align}</script><p>我们把真实分布带入到 $P(X)$ 中，可以得到：</p><script type="math/tex; mode=display">\begin{align}  KL(Q||P) &= -H_Q(X) - E_Q log (\frac{1}{Z} \prod_{f_a \in F} f_a(X_a)) \\  &= -H_Q(X) - E_Q\sum_{f_a \in F}log f_a(X_a) + E_Q log Z\end{align}</script><p>我们定义一下 free-energy 为前两项：</p><script type="math/tex; mode=display">F(P,Q) = -H_Q(X) - \sum_{f_a \in F} E_Q log f_a(X_a)</script><p>对于 Energy Functional：</p><ul><li>$\sum_{f_a \in F} E_Q log f_a(X_a)$ 的计算比较方便。。。</li><li>$H_Q$ 的计算会比较复杂，因为我们需要遍历所有 $X$ 的取值再做计算<br>-</li></ul><p>树形结构的 Energy Functional Tree 是有 closed-forms，也就是说某些 energy functional 是好可以计算的</p><p>当因子图树一颗树的时候 Bathe Approximation 和 Gibbs free energy 是等价的</p><p>我们用一张图来说明一下推导的流程</p><p><img src="/2018/09/11/PGM-4/pgm4img8.jpg" style=" width:600px;"></p><ul><li>首先我们将原图转化成因子图，可以得出图的分布的表示</li><li>我们假设一种分布和原分布进行比较，得出和原分布之间的 energy function</li><li>我们定义这种近似分布为 bathe approximation，这个分布只和 $b_a$ 和 $b_i$ 相关</li><li>我们对 bathe 的 energy function 进行优化，从而得到 $b_a$ 和 $b_i$ 的更新值</li><li>$b_a$ 和 $b_i$ 优化的方式引入到图里面就是在做 BP ！</li></ul><blockquote><p>用 Bathe 来近似原分布相当于在图上做 BP</p></blockquote><p>每一种假设的近似分布都对应这一种更新策略<br>我们先来考虑图 (a) 树形的结构，树形结构的概率图都可以转换成树形结构的因子图，树形结构的因子图的概率可以写成</p><script type="math/tex; mode=display">b(\mathbf{x}) = \prod_a b_a(\mathbf{x}_a) \prod_i b_i(x_i)^{1-d_i}</script><ul><li>$d_i$: degree of point i</li><li>$b_a$: doubleton (pairwise) factor</li><li>$b_i$: singleton factor</li></ul><p>我们会对图 (b) 也使用 $b(\mathbf{x})$ 来近似计算概率，这种近似称为 bethe approximation，若 bethe 近似和 gibbs 分布完全相等，当且仅当因子图是树形的</p><p><img src="/2018/09/11/PGM-4/pgm4img7.jpg" style=" width:600px;"><br><br>下面，我们来求这两个图的 free energy 并进行优化，来求解近似分布 b 从而得到 b 的更新策略，而后要用来从数值优化的形式转化到结构上</p><p><strong>a</strong></p><script type="math/tex; mode=display">H_{tree} = -\sum_a \sum_{x_a} b_a(x_a) log b_a(x_a) + \sum_i (d_i-1) \sum_{x_i} b_i (x_i) log b_a(x_i)</script><script type="math/tex; mode=display">\begin{align}F_{tree} &= \sum_a \sum_{x_a} b_a(x_a) log \left( \frac{b_a(x_a)}{f_a(x_a)}  \right) + \sum_i (1-d_i) \sum_{x_i} b_i(x_i) log b_i (x_i) \notag  \\&= F_{12} + F_{23} + ... + F_{67} + F_{78} - F_1 - F_5 - F_2 - F_6 - F_3 - F_7\end{align}</script><p>$H_{tree}$ 是分布 $b(\mathbf{x})$ 的信息熵，H 的形式应该是根据连续变量的信息熵公式得出的</p><p><strong>b</strong></p><script type="math/tex; mode=display">H_{Bethe} = -\sum_a \sum_{x_a} b_a(x_a) log b_a(x_a) + \sum_i (d_i-1) \sum_{x_i} b_i (x_i) log b_a(x_i)</script><script type="math/tex; mode=display">\begin{align}F_{tree} &= \sum_a \sum_{x_a} b_a(x_a) log \left( \frac{b_a(x_a)}{f_a(x_a)}  \right) + \sum_i (1-d_i) \sum_{x_i} b_i(x_i) log b_i (x_i) \notag  \\&= F_{12} + F_{23} + ... + F_{67} + F_{78} - F_1 - F_5 - 2F_2 - 2F_6 - ... - F_8\end{align}</script><p>free energy 公式想要进行优化，还要有一些约束：</p><ul><li>$\sum_{\mathbf{x}_a} b_a(\mathbf{x}_a) = 1$</li><li>$\sum_i b_i(x_i) = 1$</li><li>$\sum_{\mathbf{x}_a \setminus x_i} b_a(\mathbf{x}_a) = b_i(x_i)$</li></ul><p>最终的优化目标函数变为了:</p><script type="math/tex; mode=display">L = F_{Bethe} + \sum_i \gamma_i \left \{  1 - \sum_{x_i} b_i (x_i)  \right \}  + \sum_a \sum_{i\in N(a)} \sum_{x_i}  \lambda_{ai} (x_i)   \left\{  b_i(x_i) - \sum_{\mathbf{x}_a \setminus x_i} b_a(\mathbf{x}_a)  \right\}</script><p>对目标函数求导得到<br><img src="/2018/09/11/PGM-4/pgm4img10.jpg" style=" width:600px;"><br>上面的 $\lambda_{ai}$ 可以替换成：</p><script type="math/tex; mode=display">\lambda_{ai} = log (m_{i\rightarrow a} (x_i)) = log \prod _{b\in N(i) \setminus a} m_{b\rightarrow i} (x_i)</script><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;概率的推断就是计算 conditional 和 marginal，之前我们学习了 exact inference 也就是准确的推断概率图概率，我们学习message passing 算法、sum-product、&lt;/p&gt;
&lt;p&gt;inference is answer a 
      
    
    </summary>
    
    
      <category term="MATH" scheme="http://yoursite.com/tags/MATH/"/>
    
  </entry>
  
  <entry>
    <title>NLP-Basis</title>
    <link href="http://yoursite.com/2018/09/09/NLP-0/"/>
    <id>http://yoursite.com/2018/09/09/NLP-0/</id>
    <published>2018-09-09T07:50:49.000Z</published>
    <updated>2018-09-21T14:49:38.320Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Word-Vector"><a href="#Word-Vector" class="headerlink" title="Word Vector"></a>Word Vector</h1><p>Word Vector 也就是词向量可以分为两种</p><ul><li>Count Based：这种方法是通过统计完全局的信息最后来做特征提取</li><li>Direct Prediction：这种方法只选取来局部的统计，但是能够直接进行计算</li></ul><p><img src="/2018/09/09/NLP-0/nlp0img5.jpg" align="justify"></p><p>有一种方法能够统一上面两种性质称为 GloVe</p><p>那么我们来介绍一下几种常见的方法</p><ul><li>SVD</li><li>CBOW</li><li>SkipGram</li><li>GloVe</li></ul><p>词向量也就是把单词转换成为向量的表示，这样方便计算机进行计算<br>运算</p><p>首先，英语单词的数量很多有将近 13m，同时我们定义所有的单词集合为 $V$，以及单词的数量为 $|V|$</p><p>最简单的词向量是 <strong>one-hot Vector</strong></p><hr><p>在讲词向量时，我们先来引出共现矩阵 co-occurrence matrix 的概念，我们假设共现矩阵为 X ，其元素 $X_{i,j}$ 表示单词 i 和单词 j 在同一个窗口一起出现的次数的统计，这里的统计是对于某个数据库下的统计。<br>共现矩阵在很多的算法中都会出现，为了让共现矩阵更加完善，我们会作出一下修改和限制，比如，我们会抑制共现矩阵中出现的较大元素让他们 $\leq 100$ ，比如一些常见的单词 ‘the’ ‘he’ 等等造成的统计<br>使用 ramp window 也就是共现矩阵中的元素更新不再是 +1 而是根据离中心词的距离加权考虑</p><hr><h3 id="SVD-Method"><a href="#SVD-Method" class="headerlink" title="SVD Method"></a>SVD Method</h3><p>直接对于共现矩阵做 SVD 分解，分解后选取前 k 大的特征值对应的特征向量来作为词向量</p><p><img src="/2018/09/09/NLP-0/nlp0img1.jpg" align="justify"></p><p>这个方法其实是有很多缺点的</p><ul><li>矩阵是稀疏的，因为很多次是不会一起出现的</li><li>矩阵的维度很大，所以做 SVD 很花费时间</li></ul><hr><h3 id="CBOW-（Continuous-Bag-of-words-Models）"><a href="#CBOW-（Continuous-Bag-of-words-Models）" class="headerlink" title="CBOW （Continuous Bag of words Models）"></a>CBOW （Continuous Bag of words Models）</h3><p>CBOW 其实就是计算以某个单词为中心，固定一个窗口，计算周围单词出现的概率乘积，然后对于这个乘积就是这个事件的概率，与此同时在训练的过程中，我们</p><p>首先我们来看看这个问题的几个参数</p><ul><li>$w_i$ : 在字典 $|V|$ 中的单词 i</li><li>$V (n\times |V|)$ : context 词向量矩阵</li><li>$U (n\times |V|)$ : center 词向量矩阵</li><li>$v_i (n\times 1)$ : V 矩阵的某一列，也就是 $w_i$ 的上下文词向量</li><li>$u_i (n\times 1)$ : U 矩阵的某一列，也就是 $w_i$ 的中心词向量</li><li>$m$ : 窗口的大小</li></ul><h5 id="CBOW-Algorithm"><a href="#CBOW-Algorithm" class="headerlink" title="CBOW Algorithm"></a>CBOW Algorithm</h5><ul><li>对于 context 单词，我们生成 2m 个的 one-hot 向量 $[ x^{(c-m)},…,x^{(c-1)},x^{(c+1)},x^{(c+m)} ]$</li><li>用 context 词向量矩阵乘以 one-hot vector 从而得到 context 单词对应的 context 词向量 $v_i = Vx^i$</li><li>将这些得到的 context 词向量取均值得到 $\hat{v} = \frac{v_{c-m}+…+v_{c+m}}{2m}$</li><li>用 center 词向量矩阵去乘以上面得到的 context 均值词向量矩阵得到：所有单词以中心词向量表示于所有 context 的乘积，结果就是对于每个单词的一个 score : $z = U\hat{v}$</li><li>我们将 score 转换成概率，用 softmax 来实现：$\hat{y} = softmax(z)$</li><li>首先我们是知道真实的分布的也就是中心单词的 one-hot vector ，为 $y$ , 这样我们就可以用各种 loss function 来优化了，一般是 cross entropy 。。</li></ul><p><img src="/2018/09/09/NLP-0/nlp0img2.jpg" align="justify"></p><p>上面这张图 $W$ 相当于 context matrix ，$W^{\prime}$ 相当于 center matrix</p><hr><h3 id="Skip-Gram"><a href="#Skip-Gram" class="headerlink" title="Skip-Gram"></a>Skip-Gram</h3><h5 id="Skip-Gram-Algorithm"><a href="#Skip-Gram-Algorithm" class="headerlink" title="Skip-Gram Algorithm"></a>Skip-Gram Algorithm</h5><ul><li>对于 center 单词，生成它的 one-hot 向量</li><li>然后再获取中心单词的词向量 $v_c = V x$</li><li>用上面的中心词向量乘以 context 词向量矩阵得到一个 $|V|$ 维向量</li><li>对于这一个向量，我们取不同的位置的值做 softmax 预测，从而生成对应的 loss function</li></ul><p><img src="/2018/09/09/NLP-0/nlp0img4.jpg" align="justify"></p><p>上面一张图是 CBOW 和 Skip-Gram 算法之间的比较，总的来说</p><ul><li>CBOW ：根据周围单词，来估计中心单词出现的概率</li><li>Skip-Gram ：根据中心单词，来估计周围单词出现的概率</li></ul><hr><h3 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h3><p>直接写出 Glove 模型的优化函数吧：</p><script type="math/tex; mode=display">J(\theta)  = \frac{1}{2} \sum_{i,j=1}^w f(X_{ij}) (u_i^Tv_j - log X_{ij})^2</script><blockquote><p>对于上面这个公式，f 其实是一个权重函数，$\theta$ 是所有的变量 $U,V$</p></blockquote><hr><h1 id="Dependecy-Parsing"><a href="#Dependecy-Parsing" class="headerlink" title="Dependecy Parsing"></a>Dependecy Parsing</h1><p>如何描述语法，有两种主流观点，其中</p><ul><li>一种是短语结构文法：这种短语语法用固定数量的rule分解句子为短语和单词、分解短语为更短的短语或单词。。。</li><li>一种是依存结构：用单词之间的依存关系来表达语法。如果一个单词修饰另一个单词，则称该单词依赖于另一个单词。</li></ul><p>为什么要引用描述语法呢，因为一个句子，可以看作是几个单词的组合，但是机器要理解的是这些单词传递给人的意思，所以不仅仅是单词的出现，这些单词是如何表达意思的同样重要，因为这些句子可能会有多种意思的表达。。</p><p><img src="/2018/09/09/NLP-0/nlp0img6.jpg" align="justify"></p><p>比如这句活就可能有两个意思，但是确定了句法树，也就是上面的箭头，一个句子的意思就得到了确定。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Word-Vector&quot;&gt;&lt;a href=&quot;#Word-Vector&quot; class=&quot;headerlink&quot; title=&quot;Word Vector&quot;&gt;&lt;/a&gt;Word Vector&lt;/h1&gt;&lt;p&gt;Word Vector 也就是词向量可以分为两种&lt;/p&gt;
&lt;ul&gt;

      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Sparse-Coding</title>
    <link href="http://yoursite.com/2018/09/09/Sparse-Coding/"/>
    <id>http://yoursite.com/2018/09/09/Sparse-Coding/</id>
    <published>2018-09-09T01:21:38.000Z</published>
    <updated>2018-09-09T07:48:19.909Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经学启发"><a href="#神经学启发" class="headerlink" title="神经学启发"></a>神经学启发</h1><p>稀疏编码的概念来自于神经生物学。生物学家提出，哺乳类动物在长期的进化中，生成了能够快速，准确，低代价地表示自然图像的视觉神经方面的能力。我们直观地可以想象，我们的眼睛每看到的一副画面都是上亿像素的，而每一副图像我们都只用很少的代价重建与存储。我们把它叫做稀疏编码，即Sparse Coding。</p><p>从上可以看出稀疏编码的目的是：在大量的数据集中，选取很小部分作为元素来重建新的数据。</p><hr><h1 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h1><p>稀疏编码是一种 unsupervised learning，我们希望找到一组 over-complete 的 基向量 basic vector 来表示我们的数据，也就是数据 $\textbf{x}$ 可以表示为这些基向量的线性组合：</p><script type="math/tex; mode=display">  \textbf{x} = \sum_{i=1}^k a_i \phi_i</script><p>对于基向量的学习，我们一般有一组训练数据，另外，基向量的大小规定为 $\textbf{x}\in R^n$，同时，也是数据的大小。一般来讲，$n$ 维的数据最多只需要 $n$ 个线性不相关的基向量就可以了（使用 PCA），但是就 n 个基向量的话，可能有一个现象就是，没个数据可能都需要接近 n 个基向量来表示，我们希望 稀疏编码 能有一个优势，就是组成数据的基向量个数尽可能的小一些，也就是上面的 $\mathbf{a}$ 是稀疏的。。。</p><p>为了达成这个目的，我们可以增加基向量的个数 $k  &gt; n$，也就是说，一个数据，可能由多种基向量来表示了，在所有的表示中，我们可以尽可能的选取稀疏的表示方法。。</p><p>Sparse Coding 可以分为两个部分，一个是 Training 阶段，一个是 Coding阶段</p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>给定一些列样本数据 $[ x_1,x_2,… x_m]$ 我们希望学到一组基 $[ \phi_1,\phi_2,…,\phi_k  ]$ 来表示前面的数据，训练的 objective function 如下：</p><script type="math/tex; mode=display">\mathop{min}_{a,\phi} \sum_{i=1}^m \left \Vert x_i-\sum_{j=1}^k a_{i,j}\phi_j \right \Vert^2 + \lambda \sum_{i=1}^m \sum_{j=1}^k |a_{i,j}|</script><p>优化的迭代分为两部（都可以用凸优化来求解）</p><ul><li>固定字典 $\phi$ 更新 $a$，这个问题其实就是一个 Lasso 问题</li><li>固定表达 $a$ 更新 $\phi$，这个其实就是一个 QP 问题</li></ul><h3 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h3><p>给定一个新的数据，获得它关于字典的表达，这一步，其实就是上面的优化的第二步</p><script type="math/tex; mode=display">\mathop{min}_{a} \sum_{i=1}^m \left \Vert x_i-\sum_{j=1}^k a_{i,j}\phi_j \right \Vert^2 + \lambda \sum_{i=1}^m \sum_{j=1}^k |a_{i,j}|</script><hr><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cnblogs.com/aixueshuqian/p/3936892.html" target="_blank" rel="noopener">https://www.cnblogs.com/aixueshuqian/p/3936892.html</a><br><a href="https://www.cnblogs.com/caocan702/p/5666175.html" target="_blank" rel="noopener">https://www.cnblogs.com/caocan702/p/5666175.html</a><br>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;神经学启发&quot;&gt;&lt;a href=&quot;#神经学启发&quot; class=&quot;headerlink&quot; title=&quot;神经学启发&quot;&gt;&lt;/a&gt;神经学启发&lt;/h1&gt;&lt;p&gt;稀疏编码的概念来自于神经生物学。生物学家提出，哺乳类动物在长期的进化中，生成了能够快速，准确，低代价地表示自然图像的
      
    
    </summary>
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>PGM-3</title>
    <link href="http://yoursite.com/2018/08/18/PGM-3/"/>
    <id>http://yoursite.com/2018/08/18/PGM-3/</id>
    <published>2018-08-18T13:21:46.000Z</published>
    <updated>2018-10-10T07:18:39.517Z</updated>
    
    <content type="html"><![CDATA[<h1 id="The-Exponential-Family"><a href="#The-Exponential-Family" class="headerlink" title="The Exponential Family"></a>The Exponential Family</h1><p>random variable $\mathbf{X}$ is in the exponential family</p><script type="math/tex; mode=display">\begin{align}P(\mathbf{X}=x;\eta) &= h(x)\mathop{exp}\{ \eta^T\mathbf{T}(x) - A(\eta) \} \\&= \frac{1}{Z(\eta)} h(x) exp \{ \eta^T T(x) \}\end{align}</script><ul><li>$\eta$ :  vector of natural parameters</li><li>$\mathbf{T}$ :  vector of sufficient statistics</li><li>$\mathbf{A}$ : log partition function</li><li>$log Z(\eta) = A(\eta)$</li></ul><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><h5 id="Multivariate-Gaussian"><a href="#Multivariate-Gaussian" class="headerlink" title="Multivariate Gaussian"></a>Multivariate Gaussian</h5><script type="math/tex; mode=display">\begin{align}  P(\mathbf{x};\mu;\Sigma) &=  \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \text{exp}\left(  -\frac{1}{2} (\mathbf{x}-\mu)^T \Sigma^{-1} (\mathbf{x}-\mu) \right) \\  &= \frac{1}{(2\pi)^{p/2}} \text{exp} \left( -\frac{1}{2}(\text{tr } \mathbf{x}^T\Sigma^{-1} \mathbf{x} +\mu^T \Sigma^{-1} \mu - 2 \mu^T \Sigma^{-1} \mathbf{x} +ln |\Sigma| )\right) \\  &=  \underbrace{ \frac{1}{(2\pi)^{p/2}} }_{h(\mathbf{x})} \text{exp} \left( -\frac{1}{2} \underbrace{\text{tr } \Sigma^{-1}\mathbf{x}\mathbf{x}^T}_{\text{vec}(\Sigma^{-1})^T \text{vec}(\mathbf{x}\mathbf{x}^T)} + \mu^T\Sigma^{-1}\mathbf{x} - \underbrace{\frac{1}{2} \mu^T \Sigma^{-1} \mu - \frac{1}{2} \text{ln}|\Sigma|   }_{A(\eta)} \right)\end{align}</script><p>This implies that:</p><ul><li>$\eta = \left( \Sigma^{-1} \mu, -\frac{1}{2} vec (\Sigma^{-1}) \right)$</li><li>$\mathbf{T}(\mathbf{x}) = (\mathbf{x}, vec(\mathbf{x}\mathbf{x}^T))$</li><li>$A(\eta) = \frac{1}{2} (\mu^T \Sigma^{-1} \mu + \text{ln} |\Sigma|)$</li><li>$h(\mathbf{x}) = \frac{1}{(2\pi)^{p/2}}$</li></ul><h5 id="Bernoulli"><a href="#Bernoulli" class="headerlink" title="Bernoulli"></a>Bernoulli</h5><script type="math/tex; mode=display">\begin{align}P(x;p) &= p^x (1-p)^{1-x} \\\text{ln} P(x;p) &= x\text{ln}(p)+(1−x)\text{ln}(1−p) \\ &= x\text{ln}(p)−x\text{ln}(1−p)+\text{ln}(1−p) \\ &= x(\text{ln}(p)−\text{ln}(1−p))+\text{ln}(1−p) \\ &= x\text{ln} (\frac{p}{1-p}) + \text{ln} (1-p) \\ \text{exp} (\text{ln} P(x;p)) &= \text{exp} \left( x\text{ln} (\frac{p}{1-p}) + \text{ln} (1-p)  \right)\end{align}</script><p>This implies that:</p><ul><li>$\eta = \text{ln} (\frac{p}{1-p})$</li><li>$T(x) = x$</li><li>$A(\eta) = -\text{ln}(1-p)$</li><li>$h(x) = 1$</li></ul><h5 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h5><p>the univariate Gaussian, Poisson, gamma, multinomial, linear regression, Ising model, restricted Boltzmann machines, and conditional random fields (CRFs) are all in the exponential family</p><h3 id="Why-Exponential-Family"><a href="#Why-Exponential-Family" class="headerlink" title="Why Exponential Family"></a>Why Exponential Family</h3><h5 id="Moment-generating-property"><a href="#Moment-generating-property" class="headerlink" title="Moment generating property"></a>Moment generating property</h5><script type="math/tex; mode=display">\begin{align}  \int P(x,\eta) dx = \int h(x) e^{\eta^T T(x) - A(\eta)} dx &= 1 \\  \int h(x) e^{\eta^T T(x)} &= Z(\eta)\end{align}</script><p>-</p><script type="math/tex; mode=display">\begin{align}  \frac{dA}{d\eta} &= \frac{d}{d\eta} log (Z(\eta)) = \frac{1}{Z(\eta)} \frac{d}{d\eta} Z(\eta) \\  &= \frac{1}{Z(\eta)} \frac{d}{d\eta} \int h(x) e^{\eta^T T(x)}dx \\  &= \int T(x) \frac{h(x) e^{\eta^T T(x)}}{Z(\eta)} = E[T(x)]\end{align}</script><p> -</p><script type="math/tex; mode=display">\begin{align}\frac{d^2 A}{d^2 \eta} &= \int T^2(x) \frac{h(x) e^{\eta^T T(x)}}{Z(\eta)} dx - \int T(x) \frac{h(x) e^{\eta^T T(x)}}{Z(\eta)} dx \frac{1}{Z(\eta)} \frac{d}{d \eta} Z(\eta) \\&= E[T^2(x)] - E^2[T(x)] \\&= Var[T(x)]\end{align}</script><ul><li><p>$A(\eta)$ is convex  since</p><script type="math/tex; mode=display">\frac{d^2 A(\eta)}{d \eta^2} = Var[T(x)] > 0</script></li><li><p>specific $\eta$ map to mean $\mu$, so we define an invert $\psi (\mu) = \eta$</p></li></ul><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;The-Exponential-Family&quot;&gt;&lt;a href=&quot;#The-Exponential-Family&quot; class=&quot;headerlink&quot; title=&quot;The Exponential Family&quot;&gt;&lt;/a&gt;The Exponential Fami
      
    
    </summary>
    
    
      <category term="MATH" scheme="http://yoursite.com/tags/MATH/"/>
    
  </entry>
  
  <entry>
    <title>PGM-Exact Inference</title>
    <link href="http://yoursite.com/2018/08/14/PGM-2/"/>
    <id>http://yoursite.com/2018/08/14/PGM-2/</id>
    <published>2018-08-14T02:46:32.000Z</published>
    <updated>2018-10-10T07:18:35.794Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="Variable-Elimination"><a href="#Variable-Elimination" class="headerlink" title="Variable Elimination"></a>Variable Elimination</h1><p>某个确定了的概率图，它的推断可以看作是一个关于所有变量的函数，我们要求的是这个函数的具体值是多少，从概率的角度上消除变量，其实就是做这个函数的边缘化 marginalization，<br>我们尽量争取每次计算(消除)的变量比较少，这样总的复杂度不会高。。<br>Elimination 似乎可以适用于所有结构的 graph 。</p><h3 id="Directed-Chain"><a href="#Directed-Chain" class="headerlink" title="Directed Chain"></a>Directed Chain</h3><p>假设我们的图的结构是这样的 $A\rightarrow B\rightarrow C\rightarrow D\rightarrow E$</p><script type="math/tex; mode=display">\begin{align}P(e) &= \sum_{a,b,c,d} p(a,b,c,d) \\    &= \sum_{a,b,c,d} P (a)P (b|a)P (c|b)P (d|c)P (e|d) \\    &=\sum_{d,c,b} P(c|b) P(d|c) P(e|d) \sum_a P(a) P(b|a) \\    &\text{this is an one variable elimination cost } k^2\\    &= \sum_{d,c,b} P(c|b) P(d|c) P(e|d) p(b) \\    &\ \cdots \\    &= \sum_d P(e|d) p(d)\end{align}</script><p>复杂度 Complexity:</p><ul><li>Eliminate 方法: costs $O(k^2 n)$ _这里面的 $k^2$ 表示迭代 k 次，每次计算概率也要 k_</li><li>Naive 方法: cost $O(k^n)$</li></ul><h3 id="Undirected-Chain"><a href="#Undirected-Chain" class="headerlink" title="Undirected Chain"></a>Undirected Chain</h3><p>假设我们的图是这样的无向图 $A - B - C - D - E$</p><script type="math/tex; mode=display">\begin{align}P(e) &= \sum_{a,b,c,d} \frac{1}{Z} \phi(b,a) \phi(c,b) \phi(d,c) \phi(e,d) \\ &\propto \sum_{a,b,c,d} \phi(b,a) \phi(c,b) \phi(d,c) \phi(e,d) \\ &= \sum_{a,b,c,d}  \phi(c,b) \phi(d,c) \phi(e,d)\sum_a \phi(b,a)  \\ &= \sum_{a,b,c,d}  \phi(c,b) \phi(d,c) \phi(e,d) m_a(b)  \\ &\ \cdots \\ &= m_d(e)\end{align}</script><p>这里是无向图，原始的势函数运算成为 m 的结果不是概率，所以这里我们要 normalize 一下:</p><script type="math/tex; mode=display">P(e) =  \frac{m_d(e)}{\sum_e m_d(e)}</script><h3 id="Graph-Elimination"><a href="#Graph-Elimination" class="headerlink" title="Graph Elimination"></a>Graph Elimination</h3><p><img src="/2018/08/14/PGM-2/pgm2img1.jpg" align="justify"><br>我们从一张图来看 Elimination 的每一次过程后，剩下的图的结构</p><ul><li>对于一张 graph 首先我们确认 elimination 的 order</li><li>对于每一个待消除的变量，它会连接一些变量，我们将这些变量两两相连</li><li>消除待消除的变量</li></ul><p><img src="/2018/08/14/PGM-2/pgm2img9.jpg" align="justify"></p><p>我们再来观察每次 Elimination 后，也就是边缘化操作后形成的函数，发现这些函数的变量在一起，刚好能组成这个概率图结构的 cliques 集合，如果我们考虑这些 cliques 组成的树，那么 elimination 操作其实就是在这颗树上进行 message passing。</p><p>Key insight 就是这些 message 其实是可以 reused 的，重复使用是指，当我们要进行多次 querying 的时候，信息的重复使用，所以我们希望设计好的算法，能够在 querying 的过程中保存下来这些信息，于是有了后面的 Sum-Product 算法。</p><h3 id="Complexity-of-Variable-Elimination"><a href="#Complexity-of-Variable-Elimination" class="headerlink" title="Complexity of Variable Elimination"></a>Complexity of Variable Elimination</h3><p>这里 $y$ 未知的，后面操作可能要消除的变量，$x$ 是正在消除的变量，$m$ 是当前要消除的乘子，sum-product 算法分为下面两部</p><ul><li>Sum:<script type="math/tex; mode=display">m_x(y_1,...,y_k) = \sum_x m^{\prime}_x (x,y_1,...,y_k)</script></li><li>Product:<script type="math/tex; mode=display">m_x^{\prime} (x,y_1,...,y_k) = \prod_{i=1}^k m_i(x,y_{c_i})</script></li></ul><p></p><p>乘起来就是一次 Elimination 的复杂度： $k\cdot  | Var(X) |\cdot \prod_i |Var(Y_{C_i})|$<br>也就是当前变量的状态乘上，乘子也就是对应的 clique 的所有变量的状态叉乘</p><p>我们发现整个算法的复杂度取决于最大的最大的 clique，我们称这个 clique 的变量数量 k 为 <strong>Tree-width</strong> , 同时要注意的是，不同的 elimination order 的 Tree-Width 是不同的，找到最优的 order 是 np-hard 问题。。。</p><hr><p></p><h1 id="Belief-Propagation"><a href="#Belief-Propagation" class="headerlink" title="Belief Propagation"></a>Belief Propagation</h1><p>asd</p><ul><li>Trees<ul><li>Two-pass Algorithm</li></ul></li><li>Factor Trees<ul><li>Message Passing on Factor Graph</li></ul></li><li>Non-Trees (General Graph)<ul><li>Junction Tree Algorithm</li></ul></li></ul><p>概率图中有向图模型其实是无向图的一种特例，从有向图到无向图的转换关系如下</p><ul><li><p>Undirected Tree:</p><script type="math/tex; mode=display">p(x) = \frac{1}{Z}\left( \prod_{i\in V} \psi(x_i) \prod_{(i,j)\in E} \psi (x_i,x_j) \right)</script></li><li><p>Directed Tree:</p><script type="math/tex; mode=display">p(x)  = p(x_r) \prod_{(i,j)\in E} p(x_i|x_j)</script></li><li><p>Equivalence:</p><script type="math/tex; mode=display">\psi (x_r) = p(x_r);\ \psi(x_i,x_j)=p(x_j|x_i);\ Z=1,\psi(x_i) = 1</script></li></ul><h3 id="Trees"><a href="#Trees" class="headerlink" title="Trees"></a>Trees</h3><p>Elimination 操作可以看作是 message passing.</p><p>令 $m_{ji}(x_i)$ 当作是从 i 那里变量消除后生成的乘子，同时，这就是 $x_i$ 的函数:</p><script type="math/tex; mode=display">m_{ji}(x_i) = \sum_{x_j} \left( \psi(x_j)\psi(x_i,x_j) \prod_{k\in N(j)\setminus i} m_{kj}(x_j) \right)</script><p>上面的公式可以理解为：从 $i$ 到 $j$ 的信息，只和传递信息箭头相反的范围内的那些节点相关</p><p>对于某个节点所对应的概率，我们可以这样表示：</p><script type="math/tex; mode=display">p(x_i)\propto \psi(x_i) \prod_{e\in N(i)} m_{ei}(x_i)</script><p>可以看到计算 $p(x_i)$ 的时候， $m_{ij}(x_i)$ 会被重复的使用, 所以我们可以存储 $m$ 的值</p><p>树的 Elimination 来做 querying 算法的复杂度是 $O(NC)$ (where N=nodes, C=complexity of one complete passing/clique bottleneck). 但是使用了 two path 算法（因为是无向图所以每条边有两个方向）以后，复杂度就变成了: 2C, or $O(C)$</p><p><strong>belief propagation is only valid on trees</strong></p><h3 id="Factor-Trees"><a href="#Factor-Trees" class="headerlink" title="Factor Trees"></a>Factor Trees</h3><p><br>首先，我们定义一个变换，这个变换把一个图变成了一个新的图，变换后的图称为 <strong>Factor Graph</strong>,如果变换后刚好是一颗树，那么我们也可以称之为 Factor Tree。 在新的 Factor Graph 中，每一个 factor (clique) 在图中表示一个节点 f, 下面是一个例子,  其中的一个性质就是 $f$ 节点只和 $x$ 节点相连，也就是说，x 的某个变量把它和其他变量的关系都托付给了 f 节点。</p><p><img src="/2018/08/14/PGM-2/pgm2img2.jpg" align="justify"></p><p>对于一个图，可能有好几种变换方式，我们希望变换后的结果就是一个树，和下面的 Example 3 一样。</p><p><img src="/2018/08/14/PGM-2/pgm2img3.jpg" align="justify"></p><p>另外变换后的图其实是一个二分图（bipartite），二分图每一侧都是一种类型的节点，所以信息传递策略于传统的方法有些不同。。有两种信息的传递方式</p><p><img src="/2018/08/14/PGM-2/pgm2img4.jpg" align="justify"></p><ul><li>$\nu$ : from variables to factors（左图）<script type="math/tex; mode=display">\nu_{is}(x_i) = \prod_{t\in N(i)\setminus s} \mu_{ti}(x_i)</script></li><li>$\mu$ : from factors to variables（右图）<script type="math/tex; mode=display">\mu_{si}(x_i) = \sum_{x_{N(s)}\setminus i}\left( f_s(x_{N(s)}) \prod_{j\in N(s)\setminus i} \nu_{js}(x_j)\right)</script><ul><li><strong>_上面的 $\sum$ 操作是遍历变量的赋值，$\sum$ 操作下面的 x 可以看作是一个向量，遍历向量里面所有的赋值._</strong></li></ul></li></ul><p>Factor Tree 算法只能够处理一些长得像树的概率图</p><h3 id="Junction-Trees"><a href="#Junction-Trees" class="headerlink" title="Junction Trees"></a>Junction Trees</h3><p>Junction tree data-structure for exact inference on general graphs</p><p><strong>Algorithm</strong></p><ul><li>Moralization</li><li>Triangulation</li><li>Junction tree</li><li>Message Propagation</li></ul><h5 id="Moral-Graph"><a href="#Moral-Graph" class="headerlink" title="Moral Graph"></a>Moral Graph</h5><p>因为我们要处理的是广泛结构的概率图模型，所以我们先把 BN 纳入到 MRF 的框架里面，这一步骤叫做 Moralization，我们知道 BN 中的 factor 是某些父变量对于指定变量的条件概率，我们不管哪些是条件变量，我们就把他们看成是一个整体的函数，我们的终极目的是生成一个 clique，clique 有要求是全联通的，于是我们就将这个变量的父节点两两配对相连，这样就形成了一个 clique，原来的 factor 就变成了势函数 potential。</p><p>在这里我们得到一个启发，就是增加一条边后，原本的 graph 是新的 graph 的一种特殊情况。</p><p><img src="/2018/08/14/PGM-2/pgm2img5.jpg" align="justify"></p><h5 id="Triangulation"><a href="#Triangulation" class="headerlink" title="Triangulation"></a>Triangulation</h5><p>对于三角化的操作，我们可以先看后面两个操作的介绍再回来，因为这是为了解决后面问题的而诞生的一个步骤</p><p>问题就是 Local Consistency 不能导出 Global Consistency，只有在三角化后的图中</p><p>三角化以后的图是没有大于 4 个节点以上的环的， 三角化的方法就是在大的环中添加额外边</p><h5 id="Clique-Tree"><a href="#Clique-Tree" class="headerlink" title="Clique Tree"></a>Clique Tree</h5><p><img src="/2018/08/14/PGM-2/pgm2img6.jpg" align="justify"></p><p>下面的推断可以知道，有向图条件概率乘积的表达形式，其实就是 clique tree 表达形式的一种特殊情况</p><script type="math/tex; mode=display">\begin{align}&P(X_1,X_2,X_3,X_4,X_5,X_6)\\& = P(X_1)P(X_2)P(X_3 | X_1,X_2)P(X_4 | X_3)P(X_5 | X_3)P(X_6 | X_4,X_5) \\& = P(X_1,X_2,X_3) \frac{P(X_3,X_4,X_5)}{P(X_3)} \frac{P(X_4,X_5,X_6)}{P(X_4,X_5)} \\& = \psi(X_1,X_2,X_3) \frac{\psi(X_3,X_4,X_5)}{\phi(X_3)} \frac{\psi(X_4,X_5,X_6)}{\phi(X_4,X_5)}\end{align}</script><p><strong>General Form :</strong> 之所以下面是要除以 cliques 之间的交集 S ，是因为交集的信息可能出现了多次</p><script type="math/tex; mode=display">P(\mathbf{X}) = \frac{\prod_{c} \psi_c(\mathbf{X_c})}{\prod_{s} \phi_s(\mathbf{X_s})}</script><h5 id="Message-Passing"><a href="#Message-Passing" class="headerlink" title="Message Passing"></a>Message Passing</h5><p><br>传递方式有两种，这两种方法算出来的结果应该是一样的，这是我们做出的假设称为 <strong>Local Consistency</strong></p><script type="math/tex; mode=display">P(S) = \sum_{V\setminus S} \psi(V) \qquad \qquad P(S) = \sum_{W\setminus S} \psi(W)</script><p>下面的第一行是 forward update，第二行是 backward update，其中 $\frac{\phi_S^*}{\phi_S}$ 是通过 Local Consistency 得出的，是建立起矩形节点两边沟通的桥梁</p><p><img src="/2018/08/14/PGM-2/pgm2img7.jpg" align="justify"><br><img src="/2018/08/14/PGM-2/pgm2img11.jpg" align="justify"></p><p>上面是 clique tree 信息传递的方式，</p><p><strong>Shafer-Shenoy algorithm</strong><br><img src="/2018/08/14/PGM-2/pgm2img8.jpg" align="justify"></p><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><h3 id="General-Variable-Elimination"><a href="#General-Variable-Elimination" class="headerlink" title="General Variable Elimination"></a>General Variable Elimination</h3><p>为了让计算机能够自动的处理各种各样结构的概率图的 Elimination，我们可以设计一种更加 general 的形式，但是这个形式的设定，主要还是为了进行计算机的运算的。。</p><ul><li>Let $X$ be set of all random variables</li><li>Let $F$ denote the set of factors and then for each $\phi \in F$,$Scope[\phi] \in X$</li><li>There three type of variables in Elimination Model<ul><li>Let $Y\subset X$ be a set of <strong>query</strong> variables</li><li>Let $Z = X - Y$ would be the set of variables to be <strong>eliminated</strong></li><li>Let $\mathcal{E}$ be the <strong>known</strong> variables, and $\bar{e}_i$ is the assignment</li></ul></li></ul><p>The core operation can be view as the form of, we can extend it to general form by import evidence potential</p><script type="math/tex; mode=display">\tau(Y) =  \sum_z \prod_{\phi \in F} \phi</script><ul><li><p>The evidence potantial:</p><script type="math/tex; mode=display">\begin{align}  \delta(\mathcal{E}) = \left \{ \begin{array}{ll} 1& if\ \mathcal{E_i} \equiv \bar{e}_i \\ 0 & if\ \mathcal{E_i} \neq \bar{e}_i  \end{array}  \right .\end{align}</script></li><li><p>Total evidence potential:</p><script type="math/tex; mode=display">\begin{align}  \delta(\mathbf{\mathcal{E}},\mathbf{\bar{e}})= \prod_{i\in I_{\mathcal{E}}} \delta (\mathcal{E}_i,\bar{e}_i)\end{align}</script></li><li>Introducing evidence:<script type="math/tex; mode=display">\tau(\mathbf{Y},\mathbf{\bar{e}}) = \sum_{z,e}\prod_{\phi \in F} \phi \times \delta(\mathbf{\mathcal{E}},\bar{\mathbf{e}})</script></li></ul><h5 id="The-elimination-algorithm"><a href="#The-elimination-algorithm" class="headerlink" title="The elimination algorithm"></a>The elimination algorithm</h5><p>… …</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.jianshu.com/p/f90100680749" target="_blank" rel="noopener">https://www.jianshu.com/p/f90100680749</a></p><p>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;h1 id=&quot;Variable-Elimination&quot;&gt;&lt;a href=&quot;#Variable-Elimination&quot; class=&quot;headerlink&quot; title=&quot;Variable Elimination&quot;&gt;&lt;/a&gt;Variable Elimination&lt;
      
    
    </summary>
    
    
      <category term="MATH" scheme="http://yoursite.com/tags/MATH/"/>
    
  </entry>
  
</feed>
