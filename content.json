{"meta":{"title":"EyEular","subtitle":null,"description":null,"author":"Eulring","url":"http://yoursite.com"},"pages":[{"title":"links","date":"2018-07-22T14:54:06.000Z","updated":"2018-07-22T14:54:06.874Z","comments":true,"path":"links/index.html","permalink":"http://yoursite.com/links/index.html","excerpt":"","text":""},{"title":"","date":"2018-07-22T13:04:20.969Z","updated":"2018-07-22T13:04:20.969Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2018-07-22T13:03:46.410Z","updated":"2018-07-22T13:03:46.410Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Stochastic Process (Expectation & Variance)","slug":"Stochastic-Process-Expectation-Variance","date":"2018-07-22T02:30:26.000Z","updated":"2018-07-22T02:51:48.714Z","comments":true,"path":"2018/07/22/Stochastic-Process-Expectation-Variance/","link":"","permalink":"http://yoursite.com/2018/07/22/Stochastic-Process-Expectation-Variance/","excerpt":"","text":"","categories":[],"tags":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/tags/Math/"},{"name":"Probability","slug":"Probability","permalink":"http://yoursite.com/tags/Probability/"}]},{"title":"Neural Style","slug":"Neural-Style","date":"2018-07-19T02:25:16.000Z","updated":"2018-07-22T02:31:09.823Z","comments":true,"path":"2018/07/19/Neural-Style/","link":"","permalink":"http://yoursite.com/2018/07/19/Neural-Style/","excerpt":"","text":"Nerual StyleThere are two aspect for a image, one is the content of the image, which can be descriped as elements or object in the image, another is the style of the image, it might be abstract, and usually revealed by the painting skill or technique. Shortly, we have two image, one for style while the other for content. now, we want to combine the style in image1 and the content in image2 together, and it can be achieved from deep neural net work, and we call it Neural Style. Moreover we simply define the loss function care both style and content L_{total} = \\alpha L_{content}+\\beta L_{style}Now let’s have a look about what neural network can do here, and analysis the affect of $L_{content}$ and $L_{style}$ independently. Suppose we have the content image, and send it to the neural network, it will have the responses in each layer by filters, we also construct a white noisy image, filter it in the same way, and define a loss $L_{content}$ between filtered content and filtered noisy, we take the noisy image as input,and it can update iterativly. The image above show the reconstruction result between different layers, and reconstruction from lower layers(a,b,c) is alomost perfect, the style reconstruction may be more realistic in the deeper layer. Let’s get familiar with some notion of the formulation first( suppse we are in the $l^{th}$ level of the net ): $\\vec{p}$: Original content image (input) $P^l$: Content feature representation in layer $l$ respect to $\\vec{p}$ $\\vec{a}$: Original style image (input) $A^l$: Style feature representation in layer $l$ respect to $\\vec{a}$ $\\vec{x}$: Target image (output) $F^l$: Content feature representation in layer $l$ respect to $\\vec{x}$ $G^l$: Style feature representation in layer $l$ respect to $\\vec{x}$ $F_{ij}^l$: Element of $i^{th}$ filter at $j^{th}$ position in layer $l$ $N_l$: The number of the filters in the $l^{th}$ level $M_l$: The size of a feature map produced by a filter,usually it equals to $height \\times weight$ The squared-error loss between two content feature representations is: L_{content}(\\vec{p},\\vec{x},l) = \\frac{1}{2} \\sum_{i,j}(F_{ij}^l - P_{ij}^l)^2In each layer, build a style representation compute the correlations between the different filter responses, which is called Gram Matrix $G^l\\in R^{N_l \\times N_l}$, and $G_{ij}^l$ is the inner product between the vectorized feature map between $i$ and $j$ in layer $l$ G_{ij}^l = \\sum_k F_{ik}^l F_{jk}^lAlso we have A_{ij}^l = \\sum_k P_{ik}^l P_{jk}^lThe contribution of the layer to the total loss is E_l = \\frac{1}{4N_l^2 M_l^2 }\\sum_{i,j}(G_{ij}^l - A_{ij}^l)^2And the total loss is L_{style}(\\vec{a},\\vec{x}) = \\sum_{l=0}^L w_lE_lLet’s focus more on the detail about the gradient of the loss: The derivative of content loss respect to activations in layer l equals \\frac{\\partial L_{content}}{\\partial F_{ij}^l} = \\left \\{ \\begin{array}{ll} (F^l - P^l)_{ij} & if\\ F_{ij}^l > 0 \\\\ 0 & if\\ F_{ij}^l < 0 \\end{array} \\right .The derivative of style loss respect to activations in layer l equals \\frac{\\partial E_l}{\\partial F_{ij}^l} = \\left \\{ \\begin{array}{ll} \\frac{1}{N_l^2M_l^2}((F^l)^T(G^l - A^l))_{ij}& if\\ F_{ij}^l > 0 \\\\ 0 & if\\ F_{ij}^l < 0 \\end{array} \\right .The final loss function we want to minimize is L_{total}(\\vec{p},\\vec{a},\\vec{x}) = \\alpha L_{content}(\\vec{p},\\vec{x}) + \\beta L_{style}(\\vec{a},\\vec{x}) Fast Neural Style FastNet","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"Stochastic Process (Random Variable)","slug":"Stochastic-Process-Random-Variable","date":"2018-07-07T00:21:04.000Z","updated":"2018-07-22T02:55:04.070Z","comments":true,"path":"2018/07/07/Stochastic-Process-Random-Variable/","link":"","permalink":"http://yoursite.com/2018/07/07/Stochastic-Process-Random-Variable/","excerpt":"","text":"There are some notation occationals Definition (Discrete Random Variable) A variable $X$ is discrete if there is a finite list of value $a_1,a_2,…,a_n$ that $P(X=a_j) = 1$, $P(X=x)&gt;0$ is the support of $X$ Definition (Probability Mass Function) The probability mass function (PMF) of a discrete r.v. $X$ is the function $p_X$ given by $p_X(x) = P(X=x)$. Bernoulli &amp; BinomialDefinition (Bernoulli Distribution) shortly, $P(X=1)=p$ and $P(X=0) = 1 - p$, and write as $X\\sim Bern(p)$ Definition (Indicator Random Variable) The indicator random variable of an event $A$ is the r.v. equals 1 if $A$ occurs and 0 otherwise, We denote the indicator of $A$ by $I_A$ or $I(A)$. Note $I_A \\sim Bern(p)$ with p = P(A) Theorem (Binomial PMF) Binomial Distribution is the repeatation of Bernoulli Distribution. If $X\\sim Bin(n, p)$ then the PMF of X is P(X=k) = \\left( \\begin{array}{c} n \\\\ k \\end{array} \\right) p^k (1-p)^{n-k}Hypergeometricurn Model A box is fiiled with $w$ white and $b$ black balls, then drawing n balls With replacement: $Bin(n,w/(w+b))$ for the number of white balls Without replacement : Hypergeometric distribution $HGeom(w,b,n)$ Theorem (Hypergeometric PMF) If $X \\sim HGeom(w,b,n)$, then the PMF of $X$ is P(X=k) = \\frac {\\left ( \\begin{array}{c} w \\\\ k \\end{array} \\right ) \\left( \\begin{array}{c} b \\\\ n-k \\end{array} \\right)} {\\left( \\begin{array}{c} w+b \\\\ n \\end{array} \\right)}Zipf Distribution If $X\\sim Zipf(\\alpha &gt; 0)$, then PMF of $X$ is: P(X=k) = \\frac{\\frac{1}{k^{\\alpha + 1}}} {\\sum_{j=1}^{\\infty}(\\frac{1}{j})^{\\alpha + 1}} Zipf Distribution can measure the Word Frequency Cumulative Distribution FunctionsDefinition (Cumulative Distribution Function) The cumulative distribution function(CDF) os an r.v. $X$ is the function $F_X$ given by $F_X(x) = P(X\\leq x)$ Theorem (Valid CDFs) CDF has the following properties Increasing: If $x_1 &lt; x_2$, then $F(x_1) &lt; F(x_2)$ Right-Continuous: $F(a) = lim_{x\\rightarrow a^+} F(x)$ Convergence to $0$ and $1$: $lim_{x\\rightarrow - \\infty} F(x) = 0$ and $lim_{x \\rightarrow \\infty} F(x) = 1$ Functions of Random Variable:Definition (Function of an r.v.) An experiment with sample space S, an r.v. $X$, and a function $g$, also the $g(X)$ is the variable that maps $s$ to $g(X(s))$, for all $s\\in S$ Theorem (PMF of $g(X)$) for all y in the support of $g(X)$ P(g(X) = y) = \\sum_{x:g(x)=y} P(X=x)The function of r.v. map the sample space into real number, which is easy for us calculate in mathematic. Independence of R.V.sDefinition (Independence of two R.V.s) Random variables $X$ and $Y$ are said to be independent P(X\\leq x,Y\\leq y) = P(X\\leq x)P(Y\\leq y)for all $x,y\\in R$,In the discrete case, equivalent to : P(X=x,Y=y) = P(X=x)P(Y=y)Definition (Independence of many R.V.s) Random variables $X_1,…,X_n$ are independent if P(X_1 \\leq x_1,\\dotsb , X_n \\leq x_n) = P(X_1 \\leq x_1) \\dotsb P(X_n \\leq x_n)for all $x_1,\\dotsb,x_n \\in R$ Definition (i.i.d) We call some r.v. that are independent and have the same distribution independent and identicallly distributed or i.i.d for short Independent: r.v.s provide no information about each others Identically distributed: r.v.s have the same PMF Theorem If $X\\sim Bin(n,p)$ , $Y \\sim Bin(m,p)$, and $X$ is independent of $Y$, then $X+Y \\sim Bin(n+m,p)$ Definition (Conditional Independence of two R.V.s) P(X\\leq x, Y \\leq y| Z= z) = P(X\\leq x |Z =z) P(Y\\leq y|Z=z)w","categories":[],"tags":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/tags/Math/"},{"name":"Probability","slug":"Probability","permalink":"http://yoursite.com/tags/Probability/"}]},{"title":"Stochastic Process (Conditional Probability)","slug":"Stochastic-Process-Conditional-Probability","date":"2018-07-06T00:24:34.000Z","updated":"2018-07-19T02:27:09.257Z","comments":true,"path":"2018/07/06/Stochastic-Process-Conditional-Probability/","link":"","permalink":"http://yoursite.com/2018/07/06/Stochastic-Process-Conditional-Probability/","excerpt":"","text":"Defination of Conditonal ProbabilityDefination Two events $A$ and $B$, with $P(B)&gt;0$, the conditional probability of $A$ given $B$ , denoted by $P(A|B)$, is defined as : P(A|B)=\\frac{P(AB)}{P(B)} $P(A)$: prior probability $P(A|B)$: posterior probability Bayes’ Rule &amp; LOTPChain Rule chain rule P(A_1,...,A_n) = P(A_1)P(A_2|A_1)P(A_3|A_1A_2)...P(A_n|A_1,...,A_{n-1})Bayes’ RuleP(A|B) = \\frac{P(B|A)P(A)}{P(B)}LOTP (Law of Total Probability) Theorem: Let $A_1,A_2,…,A_n$ be the partition of the sample space $S$, with $P(A_1)&gt;0$, Then : P(B) = \\sum_i^n P(B|A_i)P(A_i)Theorem: Let $A_1,A_2,…,A_n$ be the partition of the sample space $S$, for any event $B$ such that $P(B) &gt; 0$, we have : P(A_i|B) = \\frac{P(A_i)P(B|A_i)}{P(A_1)P(B|A_1)+\\dotsb+P(A_n)P(B|A_n)} Conditional ProbabilitiyConditional Probability is also the probability, so it inherent the property of probability (suppose the sample space is $S$): $P(S|E) = 1$ and $P(\\emptyset|E) = 0$ if events $A_1,…$ are disjoint, then $P(\\cup_{j=1}^{\\infty}A_j|E) = \\sum_{j=1}^{\\infty}P(A_j|E)$ $P(A^c|E) = 1 - P(A|E)$ Inclusion-Exclusion : $P(A\\cup B|E) = P(A|E) + P(B|E) - P(A\\cap B|E)$ Bayes’ Rule with Extra Condition:Theorem: Provided that $P(A\\cap E)&gt;0$ and $P(B\\cap E)&gt;0$, we have: P(A|B,E) = \\frac{P(B|A,E)P(A|E)}{P(B|E)}LOTP with Extra Condition:Theorem: Let $A_1,A_2,…,A_n$ be the partition of the sample space $S$, with $P(A_i \\cap E) &gt;0$, Then: P(B|E) = \\sum_{i=1}^n P(B|A_i,E)P(A_i|E)Approaches for $P(A|B,C)$ P(A|B,C) = \\frac{P(A,B,C)}{P(B,C)} P(A|B,C) = \\frac{P(B|A,C)P(A|C)}{P(B|C)} P(A|B,C) = \\frac{P(C|A,B)P(A|B)}{P(A|C)} Independence of EventsIndependence of Two EventsDefination: Events $A$ and $B$ are independent if P(A\\cap B) = P(A) P(B) \\Leftrightarrow P(A|B) = P(A) , P(B|A) = P(B)Independence vs Disjointness $A,B$ is disjoint : $P(A\\cap B) = 0$ $A,B$ is independent : $P(A) = 0, P(B) = 0$ Conditional IndependenceDefination: Events $A$ and $B$ are conditionally independent given E if: P(A\\cap B|E) = P(A|E)P(B|E)Contitional\\ Independence \\nRightarrow IndependenceIndependence \\nRightarrow Contitional\\ Independencew","categories":[],"tags":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/tags/Math/"},{"name":"Probability","slug":"Probability","permalink":"http://yoursite.com/tags/Probability/"}]},{"title":"Robust PCA","slug":"Robust-PCA","date":"2018-07-04T14:47:11.000Z","updated":"2018-07-06T02:58:06.587Z","comments":true,"path":"2018/07/04/Robust-PCA/","link":"","permalink":"http://yoursite.com/2018/07/04/Robust-PCA/","excerpt":"","text":"Introduction to RPCAThe data we collect usually have the low rank property, but the property will vanished when the data is collected causing the noisy, but we can still decomposite the matrix into low-rank matrix and spares error matrix from the corruped data. D=\\underbrace{A}_{\\text{low rank matrix}}+\\underbrace{E}_{\\text{sparse matrix}} \\notagTraditional approach for solving this problem is using PCA (Principal Components Analysis), there are many interpretation to PCA, one relate to rank is despiting the low value singular value as this componets contribute less to the data. Thus, it can be considered as the noisy. So we take the $k^{th}$ largest singular value and drop the rest , this can be represnt as the following formulation : \\mathop{min}_{A,E} \\|E \\|_F, \\ \\ \\ \\ \\text{subject to } \\ rank(A)\\leq r, D = A + E \\notagPCA \bhas a shortage that it is not robust to the outliers, then the RPCA (Robust Principal Components Analysis) came out, RPCA could making the matrix recovery whether the noisy is large or not only if the sparse property is confirmed, the original form of the RPCA can be written as : \\mathop{min}_{A,E} rank(A) + \\|E\\|_0, \\ \\ \\ \\ \\text{subject to } \\ D = A + E \\notagThe optimization formulation above is non-convex and is hard to get the solution, we can use the convex relax technology apply on it, then it turn out into the most used and the most efficient from: \\mathop{min}_{A,E} \\|A\\|_* + \\|E\\|_1, \\ \\ \\ \\ \\text{subject to } \\ D = A + E \\notag$| \\cdot |_*$ is the unclear norm, which is the sum of the all singular values : $\\sum_i^n\\sigma_i$, $l_1$ norm of matrix $| \\cdot |_1$ is the sum of absolute value of all the element : $\\sum_i^n \\sum_j^n |D_{ij}|$ . Algorithm of RPCABefore introducting the Algorithm, we first introducing the two operators Singular Value ThresholdingThe optimal solution to the optimization problem : $\\frac{1}{2} | X- Y |_F^2 + \\tau |X|_*$ with the variable $X$ is thresholing the singular value of $X$ \\begin{align} \\mathcal{D}_{\\tau}(X) := U \\mathcal{D}_{\\tau} (\\Sigma) V^{\\prime} , \\ \\ \\mathcal{D}_{\\tau}(\\Sigma) = diag ( \\{ \\sigma_i - \\tau \\} ) \\notag \\\\ \\mathcal{D}_{\\tau}(Y) = \\mathop{arg} \\mathop{min}_{X} \\left \\{ \\frac{1}{2} \\| X- Y \\|_F^2 + \\tau \\|X\\|_* \\right \\} \\notag \\end{align}Soft ThresholdingAs same as the $l_1$ norm in vector, thresholding the absolute value of all the element in $X$. \\begin{align} \\psi_{st}(Y) = \\mathop{arg} \\mathop{min}_{X} \\left \\{ \\frac{1}{2} \\| X- Y \\|_F^2 + \\tau \\|X\\|_1 \\right \\} \\notag \\end{align}There are various methods to solving the RPCA problem, the most successful one is slove the Augmented Lagrangian function of the original problem which we called ALM algorithm, the Augmented Lagrangian function is: \\begin{align} L(A,E,Y,\\mu) = \\|A\\|_* + \\lambda\\|E\\|_1+ \\langle Y,D-A-E \\rangle + \\frac{\\mu}{2} \\| D- A -E \\|_F^2 \\notag \\end{align}Usually, we use ADMM to slove the ALM problems : \\begin{align} A_{k+1} &= SVT_{1/\\mu_k}(D-E_k + \\mu_k^{-1} Y_k) \\notag \\\\ E_{k+1} &= ST_{\\lambda/\\mu_k} (D - A_{k+1} + \\mu_k^{-1} Y_k) \\notag \\\\ Y_{k+1} &= Y_k + \\mu_k ( D - A_{k+1} - E_{k+1} ) \\notag \\end{align}","categories":[],"tags":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/tags/Math/"},{"name":"Optimization","slug":"Optimization","permalink":"http://yoursite.com/tags/Optimization/"},{"name":"Low-Rank","slug":"Low-Rank","permalink":"http://yoursite.com/tags/Low-Rank/"}]}]}